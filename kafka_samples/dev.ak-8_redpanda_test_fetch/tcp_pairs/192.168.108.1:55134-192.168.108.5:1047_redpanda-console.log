atf_snf.frame_stats  direction:"c->b"  tcp_short:108.1-108.5  tcp_pair_key:192.168.108.1:55134-192.168.108.5:1047  frame_count:104  syn_count:1  fin_count:0  rst_count:0  isn:002262219927  tcp_payload_len_tot:000000003011
atf_snf.frame_err  !!seq_gap_pos_count:2
atf_snf.kafka_stats  client_id_key:redpanda-console  kafka_count:64  kafka_req_ack_count:64  kafka_count_in_bh:64  pct_non_ack!!!:0  kafka_len_tot:000000003011


iframe:000000000014  ts_ns:1633356013503641  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:0  client_id:redpanda-console  client_software_name:kgo  client_software_version:v1.18.0
iframe:000000000016  ts_ns:1633356016287744  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:0  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000018  ts_ns:1633356016499929  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:1  client_id:redpanda-console  client_software_name:kgo  client_software_version:v1.18.0
iframe:000000000019  ts_ns:1633356018258259  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:1  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000106  ts_ns:1633395708136876  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:2  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000110  ts_ns:1633395709596480  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:2  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000108  ts_ns:1633395708276262  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:3  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000116  ts_ns:1633395710907513  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:3  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000114  ts_ns:1633395709997772  c_port:55134 kafka2.DescribeConfigsRequest  request_api_version:3  correlation_id:4  client_id:redpanda-console  resources.0:"kafka2.DescribeConfigsResource32q  resource_type:4  resource_name:4"  include_synonyms:Y  include_documentation:Y
iframe:000000000187  ts_ns:1633395726882502  c_port:55134 kafka2.DescribeConfigsResponse  request_api_version:3  correlation_id:4  throttle_time_ms:0  results.0:'kafka2.DescribeConfigsResult32a  error_code:0  error_message:""  resource_type:4  resource_name:4  configs.0:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.min.compaction.lag.ms  value:0  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.compaction.lag.ms  value:0  source:5"  config_type:5  documentation:"The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted."\'  configs.1:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.num.partitions  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.num.partitions  value:50  source:5"  config_type:3  documentation:"The number of partitions for the offset commit topic (should not change after deployment)."\'  configs.2:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.refresh.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.refresh.ms  value:3600000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the broker to wait between refreshing its JWKS (JSON Web Key Set) cache that contains the keys to verify the signature of the JWT."\'  configs.3:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.listener.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Listener name of the local broker to which it should get connected if needed by RemoteLogMetadataManager implementation."\'  configs.4:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.interval.messages  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.interval.messages  value:9223372036854775807  source:5"  config_type:5  documentation:"The number of messages accumulated on a log partition before messages are flushed to disk."\'  configs.5:\'kafka2.DescribeConfigsResourceResult32a  name:controller.socket.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.socket.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The socket timeout for controller-to-broker channels."\'  configs.6:\'kafka2.DescribeConfigsResourceResult32a  name:principal.builder.class  value:org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:principal.builder.class  value:org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder  source:5"  config_type:8  documentation:"The fully qualified name of a class that implements the KafkaPrincipalBuilder interface, which is used to build the KafkaPrincipal object used during authorization. If no principal builder is defined, the default behavior depends on the security protocol in use. For SSL authentication,  the principal will be derived using the rules defined by <code>ssl.principal.mapping.rules</code> applied on the distinguished name from the client certificate if one is provided; otherwise, if client authentication is not required, the principal name will be ANONYMOUS. For SASL authentication, the principal will be derived using the rules defined by <code>sasl.kerberos.principal.to.local.rules</code> if GSSAPI is in use, and the SASL authentication ID for other mechanisms. For PLAINTEXT, the principal will be ANONYMOUS."\'  configs.7:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.interval.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used"\'  configs.8:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.request.timeout.ms  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.request.timeout.ms  value:2000  source:5"  config_type:3  documentation:"The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."\'  configs.9:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.expected.audience  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:\\\'The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences. The JWT will be inspected for the standard OAuth "aud" claim and if this value is set, the broker will match the value from JWT\\\\\\\'s "aud" claim  to see if there is an exact match. If there is no match, the broker will reject the JWT and authentication will fail.\\\'\'  configs.10:\'kafka2.DescribeConfigsResourceResult32a  name:min.insync.replicas  value:1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:min.insync.replicas  value:1  source:5"  config_type:3  documentation:\\\'When a producer sets acks to "all" (or "-1"), <code>min.insync.replicas</code> specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either <code>NotEnoughReplicas</code> or <code>NotEnoughReplicasAfterAppend</code>).<br>When used together, <code>min.insync.replicas</code> and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set <code>min.insync.replicas</code> to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.\\\'\'  configs.11:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.thread.pool.size  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.thread.pool.size  value:10  source:5"  config_type:3  documentation:"Deprecated. Size of the thread pool used in scheduling tasks to copy segments, fetch remote log indexes and clean up remote log segments."\'  configs.12:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.session.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.session.timeout.ms  value:60000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for registered consumers."\'  configs.13:\'kafka2.DescribeConfigsResourceResult32a  name:num.recovery.threads.per.data.dir  value:1  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.recovery.threads.per.data.dir  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.recovery.threads.per.data.dir  value:1  source:5"  config_type:3  documentation:"The number of threads per data directory to be used for log recovery at startup and flushing at shutdown"\'  configs.14:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.type  value:JKS  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.keystore.type  value:JKS  source:5"  config_type:2  documentation:"The file format of the key store file. This is optional for client. The values currently supported by the default `ssl.engine.factory.class` are [JKS, PKCS12, PEM]."\'  configs.15:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.protocol  value:TLSv1.2  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.protocol  value:TLSv1.2  source:5"  config_type:2  documentation:"Specifies the protocol to be used in ZooKeeper TLS negotiation. An explicit value overrides any value set via the same-named <code>zookeeper.ssl.protocol</code> system property."\'  configs.16:\'kafka2.DescribeConfigsResourceResult32a  name:super.users  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:super.users  source:4"  config_type:0\'  configs.17:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.bootstrap.servers  value:""  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:controller.quorum.bootstrap.servers  value:""  source:5\\\'  config_type:7  documentation:"List of endpoints to use for bootstrapping the cluster metadata. The endpoints are specified in comma-separated list of <code>{host}:{port}</code> entries. For example: <code>localhost:9092,localhost:9093,localhost:9094</code>."\'  configs.18:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.mechanism.inter.broker.protocol  value:GSSAPI  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.mechanism.inter.broker.protocol  value:GSSAPI  source:5"  config_type:2  documentation:"SASL mechanism used for inter-broker communication. Default is GSSAPI."\'  configs.19:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.record.lock.duration.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.record.lock.duration.ms  value:30000  source:5"  config_type:3  documentation:"The record acquisition lock duration in milliseconds for share groups."\'  configs.20:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.segment.bytes  value:1073741824  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.segment.bytes  value:1073741824  source:5"  config_type:3  documentation:"The maximum size of a single metadata log file."\'  configs.21:\'kafka2.DescribeConfigsResourceResult32a  name:fetch.purgatory.purge.interval.requests  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:fetch.purgatory.purge.interval.requests  value:1000  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the fetch request purgatory"\'  configs.22:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.endpoint.identification.algorithm  value:https  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.endpoint.identification.algorithm  value:https  source:5"  config_type:2  documentation:"The endpoint identification algorithm to validate server hostname using server certificate. "\'  configs.23:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.location  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Keystore location when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.location</code> system property (note the camelCase)."\'  configs.24:\'kafka2.DescribeConfigsResourceResult32a  name:replica.socket.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.socket.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The socket timeout for network requests. Its value should be at least replica.fetch.wait.max.ms"\'  configs.25:\'kafka2.DescribeConfigsResourceResult32a  name:message.max.bytes  value:10485760  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:10485760  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:1048588  source:5"  config_type:3  documentation:"The largest record batch size allowed by Kafka (after compression if compression is enabled). If this is increased and there are consumers older than 0.10.2, the consumers\\\' fetch size must also be increased so that they can fetch record batches this large. In the latest message format version, records are always grouped into batches for efficiency. In previous message format versions, uncompressed records are not grouped into batches and this limit only applies to a single record in that case.This can be set per topic with the topic level <code>max.message.bytes</code> config."\'  configs.26:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.max.bytes.per.second  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.max.bytes.per.second  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum number of bytes that can be fetched from remote storage to local storage per second. This is a global limit for all the partitions that are being fetched from remote storage to local storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be fetched per second."\'  configs.27:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The timeout to detect client failures when using the share group protocol."\'  configs.28:\'kafka2.DescribeConfigsResourceResult32a  name:max.connection.creation.rate  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connection.creation.rate  value:2147483647  source:5"  config_type:3  documentation:"The maximum connection creation rate we allow in the broker at any time. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, <code>listener.name.internal.max.connection.creation.rate</code>.Broker-wide connection rate limit should be configured based on broker capacity while listener limits should be configured based on application requirements. New connections will be throttled if either the listener or the broker limit is reached, with the exception of inter-broker listener. Connections on the inter-broker listener will be throttled only when the listener-level rate limit is reached."\'  configs.29:\'kafka2.DescribeConfigsResourceResult32a  name:connections.max.reauth.ms  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connections.max.reauth.ms  value:0  source:5"  config_type:5  documentation:"When explicitly set to a positive number (the default is 0, not a positive number), a session lifetime that will not exceed the configured value will be communicated to v2.2.0 or later clients when they authenticate. The broker will disconnect any such connection that is not re-authenticated within the session lifetime and that is then subsequently used for any purpose other than re-authentication. Configuration names can optionally be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.oauthbearer.connections.max.reauth.ms=3600000"\'  configs.30:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for remote copy quota management. The default value is 1 second."\'  configs.31:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.offset.checkpoint.interval.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.offset.checkpoint.interval.ms  value:60000  source:5"  config_type:3  documentation:"The frequency with which we update the persistent record of the last flush which acts as the log recovery point."\'  configs.32:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.clientCnxnSocket  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Typically set to <code>org.apache.zookeeper.ClientCnxnSocketNetty</code> when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the same-named <code>zookeeper.clientCnxnSocket</code> system property."\'  configs.33:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.client.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.client.enable  value:false  source:5"  config_type:1  documentation:"Set client to use TLS when connecting to ZooKeeper. An explicit value overrides any value set via the <code>zookeeper.client.secure</code> system property (note the different name). Defaults to false if neither is set; when true, <code>zookeeper.clientCnxnSocket</code> must be set (typically to <code>org.apache.zookeeper.ClientCnxnSocketNetty</code>); other values to set may include <code>zookeeper.ssl.cipher.suites</code>, <code>zookeeper.ssl.crl.enable</code>, <code>zookeeper.ssl.enabled.protocols</code>, <code>zookeeper.ssl.endpoint.identification.algorithm</code>, <code>zookeeper.ssl.keystore.location</code>, <code>zookeeper.ssl.keystore.password</code>, <code>zookeeper.ssl.keystore.type</code>, <code>zookeeper.ssl.ocsp.enable</code>, <code>zookeeper.ssl.protocol</code>, <code>zookeeper.ssl.truststore.location</code>, <code>zookeeper.ssl.truststore.password</code>, <code>zookeeper.ssl.truststore.type</code>"\'  configs.34:\'kafka2.DescribeConfigsResourceResult32a  name:quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for client quotas"\'  configs.35:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.clock.skew.seconds  value:30  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.clock.skew.seconds  value:30  source:5"  config_type:3  documentation:"The (optional) value in seconds to allow for differences between the time of the OAuth/OIDC identity provider and the broker."\'  configs.36:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.min.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.min.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for registered consumers."\'  configs.37:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.connect  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Specifies the ZooKeeper connection string in the form <code>hostname:port</code> where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form <code>hostname1:port1,hostname2:port2,hostname3:port3</code>.\\\\nThe server can also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. For example to give a chroot path of <code>/chroot/path</code> you would give the connection string as <code>hostname1:port1,hostname2:port2,hostname3:port3/chroot/path</code>."\'  configs.38:\'kafka2.DescribeConfigsResourceResult32a  name:authorizer.class.name  value:org.apache.kafka.metadata.authorizer.StandardAuthorizer  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:authorizer.class.name  value:org.apache.kafka.metadata.authorizer.StandardAuthorizer  source:4"  synonyms.1:\\\'kafka2.DescribeConfigsSynonym32a  name:authorizer.class.name  value:""  source:5\\\'  config_type:2  documentation:"The fully qualified name of a class that implements <code>org.apache.kafka.server.authorizer.Authorizer</code> interface, which is used by the broker for authorization."\'  configs.39:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.secret  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"The secret used for encoding dynamically configured passwords for this broker."\'  configs.40:\'kafka2.DescribeConfigsResourceResult32a  name:num.replica.fetchers  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.replica.fetchers  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.replica.fetchers  value:1  source:5"  config_type:3  documentation:"Number of fetcher threads used to replicate records from each source broker. The total number of fetchers on each broker is bound by <code>num.replica.fetchers</code> multiplied by the number of brokers in the cluster.Increasing this value can increase the degree of I/O parallelism in the follower and leader broker at the cost of higher CPU and memory utilization."\'  configs.41:\'kafka2.DescribeConfigsResourceResult32a  name:alter.log.dirs.replication.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:alter.log.dirs.replication.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for alter log dirs replication quotas"\'  configs.42:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.url  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'The OAuth/OIDC provider URL from which the provider\\\\\\\'s <a href="https://datatracker.ietf.org/doc/html/rfc7517#section-5">JWKS (JSON Web Key Set)</a> can be retrieved. The URL can be HTTP(S)-based or file-based. If the URL is HTTP(S)-based, the JWKS data will be retrieved from the OAuth/OIDC provider via the configured URL on broker startup. All then-current keys will be cached on the broker for incoming requests. If an authentication request is received for a JWT that includes a "kid" header claim value that isn\\\\\\\'t yet in the cache, the JWKS endpoint will be queried again on demand. However, the broker polls the URL every sasl.oauthbearer.jwks.endpoint.refresh.ms milliseconds to refresh the cache with any forthcoming keys before any JWT requests that include them are received. If the URL is file-based, the broker will load the JWKS file from a configured location on startup. In the event that the JWT includes a "kid" header value that isn\\\\\\\'t in the JWKS file, the broker will reject the JWT and authentication will fail.\\\'\'  configs.43:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.custom.metadata.max.bytes  value:128  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.custom.metadata.max.bytes  value:128  source:5"  config_type:3  documentation:"The maximum size of custom metadata in bytes that the broker should accept from a remote storage plugin. If custom  metadata exceeds this limit, the updated segment metadata will not be stored, the copied data will be attempted to delete, and the remote copying task for this topic-partition will stop with an error."\'  configs.44:\'kafka2.DescribeConfigsResourceResult32a  name:auto.include.jmx.reporter  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.include.jmx.reporter  value:true  source:5"  config_type:1  documentation:"Deprecated. Whether to automatically include JmxReporter even if it\\\'s not listed in <code>metric.reporters</code>. This configuration will be removed in Kafka 4.0, users should instead include <code>org.apache.kafka.common.metrics.JmxReporter</code> in <code>metric.reporters</code> in order to enable the JmxReporter."\'  configs.45:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.jitter.hours  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.roll.jitter.hours  value:0  source:5"  config_type:3  documentation:"The maximum jitter to subtract from logRollTimeMillis (in hours), secondary to log.roll.jitter.ms property"\'  configs.46:\'kafka2.DescribeConfigsResourceResult32a  name:telemetry.max.bytes  value:1048576  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:telemetry.max.bytes  value:1048576  source:5"  config_type:3  documentation:"The maximum size (after compression if compression is used) of telemetry metrics pushed from a client to the broker. The default value is 1048576 (1 MB)."\'  configs.47:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.old.secret  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"The old secret that was used for encoding dynamically configured passwords. This is required only when the secret is updated. If specified, all dynamically encoded passwords are decoded using this old secret and re-encoded using password.encoder.secret when broker starts up."\'  configs.48:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.delete.retention.ms  value:86400000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.delete.retention.ms  value:86400000  source:5"  config_type:5  documentation:"The amount of time to retain tombstone message markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise  tombstones messages may be collected before a consumer completes their scan)."\'  configs.49:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.retry.backoff.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.retry.backoff.ms  value:100  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the initial wait between login attempts to the external authentication provider. Login uses an exponential backoff algorithm with an initial wait based on the sasl.login.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.login.retry.backoff.max.ms setting. Currently applies only to OAUTHBEARER."\'  configs.50:\'kafka2.DescribeConfigsResourceResult32a  name:queued.max.requests  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:queued.max.requests  value:500  source:5"  config_type:3  documentation:"The number of queued requests allowed for data-plane, before blocking the network threads"\'  configs.51:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.threads  value:1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.threads  value:1  source:5"  config_type:3  documentation:"The number of background threads to use for log cleaning"\'  configs.52:"kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.service.name  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:\\"The Kerberos principal name that Kafka runs as. This can be defined either in Kafka\'s JAAS config or in Kafka\'s config.\\""  configs.53:\'kafka2.DescribeConfigsResourceResult32a  name:socket.request.max.bytes  value:104857600  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.request.max.bytes  value:104857600  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.request.max.bytes  value:104857600  source:5"  config_type:3  documentation:"The maximum number of bytes in a socket request"\'  configs.54:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.size  value:2147483647  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.size  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of consumers that a single consumer group can accommodate. This value will only impact the new consumer coordinator. To configure the classic consumer coordinator check group.max.size instead."\'  configs.55:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.assignors  value:org.apache.kafka.coordinator.group.assignor.UniformAssignor,org.apache.kafka.coordinator.group.assignor.RangeAssignor  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.assignors  value:org.apache.kafka.coordinator.group.assignor.UniformAssignor,org.apache.kafka.coordinator.group.assignor.RangeAssignor  source:5"  config_type:7  documentation:"The server side assignors as a list of full class names. The first one in the list is considered as the default assignor to be used in the case where the consumer does not specify an assignor."\'  configs.56:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.system.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.storage.system.enable  value:false  source:5"  config_type:1  documentation:"Whether to enable tiered storage functionality in a broker or not. Valid values are `true` or `false` and the default value is false. When it is true broker starts all the services required for the tiered storage functionality."\'  configs.57:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.type  value:CreateTime  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.type  value:CreateTime  source:5"  config_type:2  documentation:"Define whether the timestamp in the message is message create time or log append time. The value should be either <code>CreateTime</code> or <code>LogAppendTime</code>."\'  configs.58:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.type  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Keystore type when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.type</code> system property (note the camelCase). The default value of <code>null</code> means the type will be auto-detected based on the filename extension of the keystore."\'  configs.59:\'kafka2.DescribeConfigsResourceResult32a  name:connections.max.idle.ms  value:600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connections.max.idle.ms  value:600000  source:5"  config_type:5  documentation:"Idle connections timeout: the server socket processor threads close the connections that idle more than this"\'  configs.60:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.set.acl  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.set.acl  value:false  source:5"  config_type:1  documentation:"Set client to use secure ACLs"\'  configs.61:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.expiry.time.ms  value:86400000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.expiry.time.ms  value:86400000  source:5"  config_type:5  documentation:"The token validity time in milliseconds before the token needs to be renewed. Default value 1 day."\'  configs.62:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connections  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of connections we allow in the broker at any time. This limit is applied in addition to any per-ip limits configured using max.connections.per.ip. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, <code>listener.name.internal.max.connections.per.ip</code>. Broker-wide limit should be configured based on broker capacity while listener limits should be configured based on application requirements. New connections are blocked if either the listener or broker limit is reached. Connections on the inter-broker listener are permitted even if broker-wide limit is reached. The least recently used connection on another listener will be closed in this case."\'  configs.63:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.num.partitions  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.num.partitions  value:50  source:5"  config_type:3  documentation:"The number of partitions for the transaction topic (should not change after deployment)."\'  configs.64:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.election.timeout.ms  value:20000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.timeout.ms  value:20000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.timeout.ms  value:1000  source:5"  config_type:3  documentation:"Maximum time in milliseconds to wait without being able to fetch from the leader before triggering a new election"\'  configs.65:\'kafka2.DescribeConfigsResourceResult32a  name:listener.security.protocol.map  value:CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:listener.security.protocol.map  value:CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:listener.security.protocol.map  value:SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT  source:5"  config_type:2  documentation:"Map between listener names and security protocols. This must be defined for the same security protocol to be usable in more than one port or IP. For example, internal and external traffic can be separated even if SSL is required for both. Concretely, the user could define listeners with names INTERNAL and EXTERNAL and this property as: <code>INTERNAL:SSL,EXTERNAL:SSL</code>. As shown, key and value are separated by a colon and map entries are separated by commas. Each listener name should only appear once in the map. Different security (SSL and SASL) settings can be configured for each listener by adding a normalised prefix (the listener name is lowercased) to the config name. For example, to set a different keystore for the INTERNAL listener, a config with name <code>listener.name.internal.ssl.keystore.location</code> would be set. If the config for the listener name is not set, the config will fallback to the generic config (i.e. <code>ssl.keystore.location</code>). Note that in KRaft a default mapping from the listener names defined by <code>controller.listener.names</code> to PLAINTEXT is assumed if no explicit mapping is provided and no other security protocol is in use."\'  configs.66:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.hours  value:168  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.hours  value:168  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.retention.hours  value:168  source:5"  config_type:3  documentation:"The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property"\'  configs.67:\'kafka2.DescribeConfigsResourceResult32a  name:client.quota.callback.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a class that implements the ClientQuotaCallback interface, which is used to determine quota limits applied to client requests. By default, the &lt;user&gt; and &lt;client-id&gt; quotas that are stored in ZooKeeper are applied. For any given request, the most specific quota that matches the user principal of the session and the client-id of the request is applied."\'  configs.68:\'kafka2.DescribeConfigsResourceResult32a  name:audit.log.enabled  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:audit.log.enabled  source:4"  config_type:0\'  configs.69:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.impl.prefix  value:rsm.config.  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.storage.manager.impl.prefix  value:rsm.config.  source:5"  config_type:2  documentation:"Prefix used for properties to be passed to RemoteStorageManager implementation. For example this value can be `rsm.config.`."\'  configs.70:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.provider  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The name of the security provider used for SSL connections. Default value is the default security provider of the JVM."\'  configs.71:\'kafka2.DescribeConfigsResourceResult32a  name:delete.records.purgatory.purge.interval.requests  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delete.records.purgatory.purge.interval.requests  value:1  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the delete records request purgatory"\'  configs.72:\'kafka2.DescribeConfigsResourceResult32a  name:producer.id.expiration.ms  value:86400000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:producer.id.expiration.ms  value:86400000  source:5"  config_type:3  documentation:"The time in ms that a topic partition leader will wait before expiring producer IDs. Producer IDs will not expire while a transaction associated to them is still ongoing. Note that producer IDs may expire sooner if the last write from the producer ID is deleted due to the topic\\\'s retention settings. Setting this value the same or higher than <code>delivery.timeout.ms</code> can help prevent expiration during retries and protect against message duplication, but the default should be reasonable for most use cases."\'  configs.73:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum time before a new log segment is rolled out (in milliseconds). If not set, the value in log.roll.hours is used"\'  configs.74:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.cipher.suites  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:ssl.cipher.suites  value:""  source:5\\\'  config_type:7  documentation:"A list of cipher suites. This is a named combination of authentication, encryption, MAC and key exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL network protocol. By default all the available cipher suites are supported."\'  configs.75:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.retry.backoff.ms  value:20  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.retry.backoff.ms  value:20  source:5"  config_type:3  documentation:"The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios. This value is the initial backoff value and will increase exponentially for each failed request, up to the <code>retry.backoff.max.ms</code> value."\'  configs.76:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.max.bytes.per.second  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.max.bytes.per.second  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum number of bytes that can be copied from local storage to remote storage per second. This is a global limit for all the partitions that are being copied from local storage to remote storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be copied per second."\'  configs.77:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.password  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Keystore password when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.password</code> system property (note the camelCase). Note that ZooKeeper does not support a key password different from the keystore password, so be sure to set the key password in the keystore to be identical to the keystore password; otherwise the connection attempt to Zookeeper will fail."\'  configs.78:\'kafka2.DescribeConfigsResourceResult32a  name:broker.session.timeout.ms  value:9000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.session.timeout.ms  value:9000  source:5"  config_type:3  documentation:"The length of time in milliseconds that a broker lease lasts if no heartbeats are made. Used when running in KRaft mode."\'  configs.79:\'kafka2.DescribeConfigsResourceResult32a  name:security.inter.broker.protocol  value:PLAINTEXT  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:security.inter.broker.protocol  value:PLAINTEXT  source:5"  config_type:2  documentation:"Security protocol used to communicate between brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. It is an error to set this and inter.broker.listener.name properties at the same time."\'  configs.80:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The heartbeat interval given to the members of a share group."\'  configs.81:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.secret.key  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Secret key to generate and verify delegation tokens. The same key must be configured across all the brokers.  If using Kafka with KRaft, the key must also be set across all controllers.  If the key is not set or set to empty string, brokers will disable the delegation token support."\'  configs.82:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for remote fetch quota management. The default value is 11, which means there are 10 whole windows + 1 current window."\'  configs.83:\'kafka2.DescribeConfigsResourceResult32a  name:remote.fetch.max.wait.ms  value:500  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.fetch.max.wait.ms  value:500  source:5"  config_type:3  documentation:"The maximum amount of time the server will wait before answering the remote fetch request"\'  configs.84:\'kafka2.DescribeConfigsResourceResult32a  name:node.id  value:4  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:node.id  value:4  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:node.id  value:-1  source:5"  config_type:3  documentation:"The node ID associated with the roles this process is playing when <code>process.roles</code> is non-empty. This is required configuration when running in KRaft mode."\'  configs.85:\'kafka2.DescribeConfigsResourceResult32a  name:replica.high.watermark.checkpoint.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.high.watermark.checkpoint.interval.ms  value:5000  source:5"  config_type:5  documentation:"The frequency with which the high watermark is saved out to disk"\'  configs.86:\'kafka2.DescribeConfigsResourceResult32a  name:replication.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replication.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for replication quotas"\'  configs.87:\'kafka2.DescribeConfigsResourceResult32a  name:eligible.leader.replicas.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:eligible.leader.replicas.enable  value:false  source:5"  config_type:1  documentation:"Enable the Eligible leader replicas"\'  configs.88:\'kafka2.DescribeConfigsResourceResult32a  name:log.local.retention.ms  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.ms  value:-2  source:5"  config_type:5  documentation:"The number of milliseconds to keep the local log segments before it gets eligible for deletion. Default value is -2, it represents `log.retention.ms` value is to be used. The effective value should always be less than or equal to `log.retention.ms` value."\'  configs.89:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.reader.threads  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.reader.threads  value:10  source:5"  config_type:3  documentation:"Size of the thread pool that is allocated for handling remote log reads."\'  configs.90:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.ticket.renew.window.factor  value:0.8  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.ticket.renew.window.factor  value:0.8  source:5"  config_type:6  documentation:"Login thread will sleep until the specified window factor of time from last refresh to ticket\\\'s expiry has been reached, at which time it will try to renew the ticket."\'  configs.91:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.threads  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.threads  value:1  source:5"  config_type:3  documentation:"The number of threads used by the group coordinator."\'  configs.92:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.connection.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The max time that the client waits to establish a connection to ZooKeeper. If not set, the value in zookeeper.session.timeout.ms is used"\'  configs.93:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.recording.level  value:INFO  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.recording.level  value:INFO  source:5"  config_type:2  documentation:"The highest recording level for metrics."\'  configs.94:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.cipher.algorithm  value:AES/CBC/PKCS5Padding  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.cipher.algorithm  value:AES/CBC/PKCS5Padding  source:5"  config_type:2  documentation:"The Cipher algorithm used for encoding dynamically configured passwords."\'  configs.95:\'kafka2.DescribeConfigsResourceResult32a  name:log.dir.failure.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dir.failure.timeout.ms  value:30000  source:5"  config_type:5  documentation:"If the broker is unable to successfully communicate to the controller that some log directory has failed for longer than this time, the broker will fail and shut down."\'  configs.96:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.partition.verification.enable  value:true  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.partition.verification.enable  value:true  source:5"  config_type:1  documentation:"Enable verification that checks that the partition has been added to the transaction before writing transactional records to the partition"\'  configs.97:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The minimum heartbeat interval for share group members."\'  configs.98:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.principal.mapping.rules  value:DEFAULT  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.principal.mapping.rules  value:DEFAULT  source:5"  config_type:2  documentation:\\\'A list of rules for mapping from distinguished name from the client certificate to short name. The rules are evaluated in order and the first rule that matches a principal name is used to map it to a short name. Any later rules in the list are ignored. By default, distinguished name of the X.500 certificate will be the principal. For more details on the format please see <a href="#security_authz"> security authorization and acls</a>. Note that this configuration is ignored if an extension of KafkaPrincipalBuilder is provided by the <code>principal.builder.class</code> configuration.\\\'\'  configs.99:\'kafka2.DescribeConfigsResourceResult32a  name:replica.selector.class  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The fully qualified class name that implements ReplicaSelector. This is used by the broker to find the preferred read replica. By default, we use an implementation that returns the leader."\'  configs.100:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for remote fetch quota management. The default value is 1 second."\'  configs.101:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections.per.ip  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connections.per.ip  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of connections we allow from each ip address. This can be set to 0 if there are overrides configured using max.connections.per.ip.overrides property. New connections from the ip address are dropped if the limit is reached."\'  configs.102:\'kafka2.DescribeConfigsResourceResult32a  name:background.threads  value:10  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:background.threads  value:10  source:5"  config_type:3  documentation:"The number of threads to use for various background processing tasks"\'  configs.103:\'kafka2.DescribeConfigsResourceResult32a  name:request.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:request.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."\'  configs.104:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.format.version  value:3.0-IV1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.format.version  value:3.0-IV1  source:5"  config_type:2  documentation:"Specify the message format version the broker will use to append messages to the logs. The value should be a valid MetadataVersion. Some examples are: 0.8.2, 0.9.0.0, 0.10.0, check MetadataVersion for more details. By setting a particular message format version, the user is certifying that all the existing messages on disk are smaller or equal than the specified version. Setting this value incorrectly will cause consumers with older versions to break as they will receive messages with a format that they don\\\'t understand."\'  configs.105:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a class that implements the Login interface. For brokers, login config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.class=com.example.CustomScramLogin"\'  configs.106:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.index.file.cache.total.size.bytes  value:1073741824  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.index.file.cache.total.size.bytes  value:1073741824  source:5"  config_type:5  documentation:"The total size of the space allocated to store index files fetched from remote storage in the local storage."\'  configs.107:\'kafka2.DescribeConfigsResourceResult32a  name:log.dir  value:/tmp/kafka-logs  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dir  value:/tmp/kafka-logs  source:5"  config_type:2  documentation:"The directory in which the log data is kept (supplemental for log.dirs property)"\'  configs.108:\'kafka2.DescribeConfigsResourceResult32a  name:log.segment.bytes  value:1073741824  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:5"  config_type:3  documentation:"The maximum size of a single log file"\'  configs.109:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.response.max.bytes  value:10485760  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.response.max.bytes  value:10485760  source:5"  config_type:3  documentation:"Maximum bytes expected for the entire fetch response. Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum. The maximum record batch size accepted by the broker is defined via <code>message.max.bytes</code> (broker config) or <code>max.message.bytes</code> (topic config)."\'  configs.110:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The heartbeat interval given to the members of a consumer group."\'  configs.111:\'kafka2.DescribeConfigsResourceResult32a  name:group.max.session.timeout.ms  value:1800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.max.session.timeout.ms  value:1800000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures."\'  configs.112:\'kafka2.DescribeConfigsResourceResult32a  name:controller.listener.names  value:CONTROLLER  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.listener.names  value:CONTROLLER  source:4"  config_type:2  documentation:"A comma-separated list of the names of the listeners used by the controller. This is required if running in KRaft mode. When communicating with the controller quorum, the broker will always use the first listener in this list.\\\\n Note: The ZooKeeper-based controller should not set this configuration."\'  configs.113:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.after.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.after.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the message timestamp and the broker\\\'s timestamp. The message timestamp can be later than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If log.message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime."\'  configs.114:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.append.linger.ms  value:25  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.append.linger.ms  value:25  source:5"  config_type:3  documentation:"The duration in milliseconds that the leader will wait for writes to accumulate before flushing them to disk."\'  configs.115:\'kafka2.DescribeConfigsResourceResult32a  name:log.segment.delete.delay.ms  value:60000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.delete.delay.ms  value:60000  source:5"  config_type:5  documentation:"The amount of time to wait before deleting a file from the filesystem. If the value is 0 and there is no file to delete, the system will wait 1 millisecond. Low value will cause busy waiting"\'  configs.116:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.minutes  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The number of minutes to keep a log file before deleting it (in minutes), secondary to log.retention.ms property. If not set, the value in log.retention.hours is used"\'  configs.117:\'kafka2.DescribeConfigsResourceResult32a  name:log.dirs  value:/mnt/data-1/dev.ak-8,/mnt/data-2/dev.ak-8  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dirs  value:/mnt/data-1/dev.ak-8,/mnt/data-2/dev.ak-8  source:4"  config_type:2  documentation:"A comma-separated list of the directories where the log data is stored. If not set, the value in log.dir is used."\'  configs.118:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.enable  value:true  source:5"  config_type:1  documentation:"Enable controlled shutdown of the server."\'  configs.119:\'kafka2.DescribeConfigsResourceResult32a  name:early.start.listeners  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"A comma-separated list of listener names which may be started before the authorizer has finished initialization. This is useful when the authorizer is dependent on the cluster itself for bootstrapping, as is the case for the StandardAuthorizer (which stores ACLs in the metadata log.) By default, all listeners included in controller.listener.names will also be early start listeners. A listener should not appear in this list if it accepts external traffic."\'  configs.120:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.before.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.before.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the broker\\\'s timestamp and the message timestamp. The message timestamp can be earlier than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If log.message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime."\'  configs.121:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copier.thread.pool.size  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copier.thread.pool.size  value:-1  source:5"  config_type:3  documentation:"Size of the thread pool used in scheduling tasks to copy segments. The default value of -1 means that this will be set to the configured value of remote.log.manager.thread.pool.size, if available; otherwise, it defaults to 10."\'  configs.122:\'kafka2.DescribeConfigsResourceResult32a  name:socket.connection.setup.timeout.max.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.connection.setup.timeout.max.ms  value:30000  source:5"  config_type:5  documentation:"The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum. To avoid connection storms, a randomization factor of 0.2 will be applied to the timeout resulting in a random range between 20% below and 20% above the computed value."\'  configs.123:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.difference.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.difference.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"[DEPRECATED] The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message. If log.message.timestamp.type=CreateTime, a message will be rejected if the difference in timestamp exceeds this threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime.The maximum timestamp difference allowed should be no greater than log.retention.ms to avoid unnecessarily frequent log rolling."\'  configs.124:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.scope.claim.name  value:scope  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.scope.claim.name  value:scope  source:5"  config_type:2  documentation:\\\'The OAuth claim for the scope is often named "scope", but this (optional) setting can provide a different name to use for the scope included in the JWT payload\\\\\\\'s claims if the OAuth/OIDC provider uses a different name for that claim.\\\'\'  configs.125:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.key.length  value:128  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.key.length  value:128  source:5"  config_type:3  documentation:"The key length used for encoding dynamically configured passwords."\'  configs.126:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.min.period.seconds  value:60  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.min.period.seconds  value:60  source:5"  config_type:4  documentation:"The desired minimum time for the login refresh thread to wait before refreshing a credential, in seconds. Legal values are between 0 and 900 (15 minutes); a default value of 60 (1 minute) is used if no value is specified.  This value and  sasl.login.refresh.buffer.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER."\'  configs.127:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.expected.issuer  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'The (optional) setting for the broker to use to verify that the JWT was created by the expected issuer. The JWT will be inspected for the standard OAuth "iss" claim and if this value is set, the broker will match it exactly against what is in the JWT\\\\\\\'s "iss" claim. If there is no match, the broker will reject the JWT and authentication will fail.\\\'\'  configs.128:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.read.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The (optional) value in milliseconds for the external authentication provider read timeout. Currently applies only to OAUTHBEARER."\'  configs.129:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.abort.timed.out.transaction.cleanup.interval.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.abort.timed.out.transaction.cleanup.interval.ms  value:10000  source:5"  config_type:3  documentation:"The interval at which to rollback transactions that have timed out"\'  configs.130:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.kinit.cmd  value:/usr/bin/kinit  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.kinit.cmd  value:/usr/bin/kinit  source:5"  config_type:2  documentation:"Kerberos kinit command path."\'  configs.131:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.max.bytes.per.second  value:1.7976931348623157E308  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.max.bytes.per.second  value:1.7976931348623157E308  source:5"  config_type:6  documentation:"The log cleaner will be throttled so that the sum of its read and write i/o will be less than this value on average"\'  configs.132:\'kafka2.DescribeConfigsResourceResult32a  name:auto.leader.rebalance.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.leader.rebalance.enable  value:true  source:5"  config_type:1  documentation:"Enables auto leader balancing. A background thread checks the distribution of partition leaders at regular intervals, configurable by leader.imbalance.check.interval.seconds. If the leader imbalance exceeds leader.imbalance.per.broker.percentage, leader rebalance to the preferred leader for partitions is triggered."\'  configs.133:\'kafka2.DescribeConfigsResourceResult32a  name:leader.imbalance.check.interval.seconds  value:300  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:leader.imbalance.check.interval.seconds  value:300  source:5"  config_type:5  documentation:"The frequency with which the partition rebalance check is triggered by the controller"\'  configs.134:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.min.cleanable.ratio  value:0.5  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.cleanable.ratio  value:0.5  source:5"  config_type:6  documentation:"The minimum ratio of dirty log to total log for a log to eligible for cleaning. If the log.cleaner.max.compaction.lag.ms or the log.cleaner.min.compaction.lag.ms configurations are also specified, then the log compactor considers the log eligible for compaction as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) records for at least the log.cleaner.min.compaction.lag.ms duration, or (ii) if the log has had dirty (uncompacted) records for at most the log.cleaner.max.compaction.lag.ms period."\'  configs.135:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.record.lock.duration.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.record.lock.duration.ms  value:15000  source:5"  config_type:3  documentation:"The record acquisition lock minimum duration in milliseconds for share groups."\'  configs.136:\'kafka2.DescribeConfigsResourceResult32a  name:replica.lag.time.max.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.lag.time.max.ms  value:30000  source:5"  config_type:5  documentation:"If a follower hasn\\\'t sent any fetch requests or hasn\\\'t consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr"\'  configs.137:\'kafka2.DescribeConfigsResourceResult32a  name:num.network.threads  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.network.threads  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.network.threads  value:3  source:5"  config_type:3  documentation:"The number of threads that the server uses for receiving requests from the network and sending responses to the network. Noted: each listener (except for controller listener) creates its own thread pool."\'  configs.138:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for share group members."\'  configs.139:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.key  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Private key in the format specified by \'ssl.keystore.type\'. Default SSL engine factory supports only PEM format with PKCS#8 keys. If the key is encrypted, key password must be specified using \'ssl.key.password\'\\""  configs.140:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.client.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL client callback handler class that implements the AuthenticateCallbackHandler interface."\'  configs.141:\'kafka2.DescribeConfigsResourceResult32a  name:compression.gzip.level  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.gzip.level  value:-1  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'gzip\\\'."\'  configs.142:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.num.samples  value:2  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.num.samples  value:2  source:5"  config_type:3  documentation:"The number of samples maintained to compute metrics."\'  configs.143:\'kafka2.DescribeConfigsResourceResult32a  name:socket.send.buffer.bytes  value:102400  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.send.buffer.bytes  value:102400  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.send.buffer.bytes  value:102400  source:5"  config_type:3  documentation:"The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."\'  configs.144:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.rebalance.protocols  value:classic  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.rebalance.protocols  value:classic  source:5"  config_type:7  documentation:"The list of enabled rebalance protocols. Supported protocols: consumer,classic,share,unknown. The consumer rebalance protocol is in early access and therefore must not be used in production."\'  configs.145:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.keyfactory.algorithm  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The SecretKeyFactory algorithm used for encoding dynamically configured passwords. Default is PBKDF2WithHmacSHA512 if available and PBKDF2WithHmacSHA1 otherwise."\'  configs.146:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Fully qualified class name of `RemoteStorageManager` implementation."\'  configs.147:\'kafka2.DescribeConfigsResourceResult32a  name:socket.receive.buffer.bytes  value:102400  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.receive.buffer.bytes  value:102400  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.receive.buffer.bytes  value:102400  source:5"  config_type:3  documentation:"The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."\'  configs.148:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.sub.claim.name  value:sub  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.sub.claim.name  value:sub  source:5"  config_type:2  documentation:\\\'The OAuth claim for the subject is often named "sub", but this (optional) setting can provide a different name to use for the subject included in the JWT payload\\\\\\\'s claims if the OAuth/OIDC provider uses a different name for that claim.\\\'\'  configs.149:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.min.bytes  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.min.bytes  value:1  source:5"  config_type:3  documentation:"Minimum bytes expected for each fetch response. If not enough bytes, wait up to <code>replica.fetch.wait.max.ms</code> (broker config)."\'  configs.150:\'kafka2.DescribeConfigsResourceResult32a  name:broker.rack  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Rack of the broker. This will be used in rack aware replication assignment for fault tolerance. Examples: <code>RACK1</code>, <code>us-east-1d</code>"\'  configs.151:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.password  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Truststore password when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.password</code> system property (note the camelCase)."\'  configs.152:\'kafka2.DescribeConfigsResourceResult32a  name:unclean.leader.election.enable  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:unclean.leader.election.enable  value:false  source:5"  config_type:1  documentation:"Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss<p>Note: In KRaft mode, when enabling this config dynamically, it needs to wait for the unclean leader election thread to trigger election periodically (default is 5 minutes). Please run `kafka-leader-election.sh` with `unclean` option to trigger the unclean leader election immediately if needed.</p>"\'  configs.153:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.ms  value:100  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the initial wait between JWKS (JSON Web Key Set) retrieval attempts from the external authentication provider. JWKS retrieval uses an exponential backoff algorithm with an initial wait based on the sasl.oauthbearer.jwks.endpoint.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms setting."\'  configs.154:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.retention.check.interval.ms  value:600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.retention.check.interval.ms  value:600000  source:5"  config_type:5  documentation:"Frequency at which to check for stale offsets"\'  configs.155:\'kafka2.DescribeConfigsResourceResult32a  name:producer.purgatory.purge.interval.requests  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:producer.purgatory.purge.interval.requests  value:1000  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the producer request purgatory"\'  configs.156:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.voters  value:4@dev.ak-8.kafka-4.int-0:1055  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.voters  value:4@dev.ak-8.kafka-4.int-0:1055  source:4"  synonyms.1:\\\'kafka2.DescribeConfigsSynonym32a  name:controller.quorum.voters  value:""  source:5\\\'  config_type:7  documentation:"Map of id/endpoint information for the set of voters in a comma-separated list of <code>{id}@{host}:{port}</code> entries. For example: <code>1@localhost:9092,2@localhost:9093,3@localhost:9094</code>"\'  configs.157:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.sample.window.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.sample.window.ms  value:30000  source:5"  config_type:5  documentation:"The window of time a metrics sample is computed over."\'  configs.158:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.check.interval.ms  value:300000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.check.interval.ms  value:300000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.retention.check.interval.ms  value:300000  source:5"  config_type:5  documentation:"The frequency in milliseconds that the log cleaner checks whether any log is eligible for deletion"\'  configs.159:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The timeout to detect client failures when using the consumer group protocol."\'  configs.160:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.window.jitter  value:0.05  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.window.jitter  value:0.05  source:5"  config_type:6  documentation:"The maximum amount of random jitter relative to the credential\\\'s lifetime that is added to the login refresh thread\\\'s sleep time. Legal values are between 0 and 0.25 (25%) inclusive; a default value of 0.05 (5%) is used if no value is specified. Currently applies only to OAUTHBEARER."\'  configs.161:\'kafka2.DescribeConfigsResourceResult32a  name:leader.imbalance.per.broker.percentage  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:leader.imbalance.per.broker.percentage  value:10  source:5"  config_type:3  documentation:"The ratio of leader imbalance allowed per broker. The controller would trigger a leader balance if it goes above this value per broker. The value is specified in percentage."\'  configs.162:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for controller mutation quotas"\'  configs.163:\'kafka2.DescribeConfigsResourceResult32a  name:metric.reporters  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:metric.reporters  value:""  source:5\\\'  config_type:7  documentation:"A list of classes to use as metrics reporters. Implementing the <code>org.apache.kafka.common.metrics.MetricsReporter</code> interface allows plugging in classes that will be notified of new metric creation. The JmxReporter is always included to register JMX statistics."\'  configs.164:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.token.endpoint.url  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The URL for the OAuth/OIDC identity provider. If the URL is HTTP(S)-based, it is the issuer\\\'s token endpoint URL to which requests will be made to login based on the configuration in sasl.jaas.config. If the URL is file-based, it specifies a file containing an access token (in JWT serialized form) issued by the OAuth/OIDC identity provider to use for authorization."\'  configs.165:\'kafka2.DescribeConfigsResourceResult32a  name:auto.create.topics.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.create.topics.enable  value:true  source:5"  config_type:1  documentation:"Enable auto creation of topic on the server."\'  configs.166:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.partition.max.record.locks  value:200  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.partition.max.record.locks  value:200  source:5"  config_type:3  documentation:"Share-group record lock limit per share-partition."\'  configs.167:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.engine.factory.class  read_only:N  config_source:5  is_sensitive:N  config_type:8  documentation:"The class of type org.apache.kafka.common.security.auth.SslEngineFactory to provide SSLEngine objects. Default value is org.apache.kafka.common.security.ssl.DefaultSslEngineFactory. Alternatively, setting this to org.apache.kafka.common.security.ssl.CommonNameLoggingSslEngineFactory will log the common name of expired SSL certificates used by clients to authenticate at any of the brokers with log level INFO. Note that this will cause a tiny delay during establishment of new connections from mTLS clients to brokers due to the extra code for examining the certificate chain provided by the client. Note further that the implementation uses a custom truststore based on the standard Java truststore and thus might be considered a security risk due to not being as mature as the standard one."\'  configs.168:\'kafka2.DescribeConfigsResourceResult32a  name:replica.socket.receive.buffer.bytes  value:65536  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.socket.receive.buffer.bytes  value:65536  source:5"  config_type:3  documentation:"The socket receive buffer for network requests to the leader for replicating data"\'  configs.169:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.location  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Truststore location when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.location</code> system property (note the camelCase)."\'  configs.170:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.allow.dn.changes  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.allow.dn.changes  value:false  source:5"  config_type:1  documentation:"Indicates whether changes to the certificate distinguished name should be allowed during a dynamic reconfiguration of certificates or not."\'  configs.171:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.wait.max.ms  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.wait.max.ms  value:500  source:5"  config_type:3  documentation:"The maximum wait time for each fetcher request issued by follower replicas. This value should always be less than the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics"\'  configs.172:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.iterations  value:4096  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.iterations  value:4096  source:5"  config_type:3  documentation:"The iteration count used for encoding dynamically configured passwords."\'  configs.173:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.min.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.min.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The minimum heartbeat interval for registered consumers."\'  configs.174:\'kafka2.DescribeConfigsResourceResult32a  name:default.replication.factor  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:default.replication.factor  value:1  source:5"  config_type:3  documentation:"The replication factor for automatically created topics, and for topics created with -1 as the replication factor"\'  configs.175:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:"The password for the trust store file. If a password is not set, trust store file configured will still be used, but integrity checking is disabled. Trust store password is not supported for PEM format."\'  configs.176:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.principal.to.local.rules  value:DEFAULT  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.principal.to.local.rules  value:DEFAULT  source:5"  config_type:7  documentation:\\\'A list of rules for mapping from principal names to short names (typically operating system usernames). The rules are evaluated in order and the first rule that matches a principal name is used to map it to a short name. Any later rules in the list are ignored. By default, principal names of the form <code>{username}/{hostname}@{REALM}</code> are mapped to <code>{username}</code>. For more details on the format please see <a href="#security_authz"> security authorization and acls</a>. Note that this configuration is ignored if an extension of <code>KafkaPrincipalBuilder</code> is provided by the <code>principal.builder.class</code> configuration.\\\'\'  configs.177:\'kafka2.DescribeConfigsResourceResult32a  name:log.preallocate  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.preallocate  value:false  source:5"  config_type:1  documentation:"Should pre allocate file when create new segment? If you are using Kafka on Windows, you probably need to set it to true."\'  configs.178:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.reader.max.pending.tasks  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.reader.max.pending.tasks  value:100  source:5"  config_type:3  documentation:"Maximum remote log reader thread pool task queue size. If the task queue is full, fetch requests are served with an error."\'  configs.179:\'kafka2.DescribeConfigsResourceResult32a  name:transactional.id.expiration.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transactional.id.expiration.ms  value:604800000  source:5"  config_type:3  documentation:"The time in ms that the transaction coordinator will wait without receiving any transaction status updates for the current transaction before expiring its transactional id. Transactional IDs will not expire while a the transaction is still ongoing."\'  configs.180:\'kafka2.DescribeConfigsResourceResult32a  name:control.plane.listener.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'Name of listener used for communication between controller and brokers. A broker will use the <code>control.plane.listener.name</code> to locate the endpoint in listeners list, to listen for connections from the controller. For example, if a broker\\\\\\\'s config is:\\\\n<code>listeners = INTERNAL://192.1.1.8:9092, EXTERNAL://10.1.1.5:9093, CONTROLLER://192.1.1.8:9094listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER</code>\\\\nOn startup, the broker will start listening on "192.1.1.8:9094" with security protocol "SSL".\\\\nOn the controller side, when it discovers a broker\\\\\\\'s published endpoints through ZooKeeper, it will use the <code>control.plane.listener.name</code> to find the endpoint, which it will use to establish connection to the broker.\\\\nFor example, if the broker\\\\\\\'s published endpoints on ZooKeeper are:\\\\n <code>"endpoints" : ["INTERNAL://broker1.example.com:9092","EXTERNAL://broker1.example.com:9093","CONTROLLER://broker1.example.com:9094"]</code>\\\\n and the controller\\\\\\\'s config is:\\\\n<code>listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER</code>\\\\nthen the controller will use "broker1.example.com:9094" with security protocol "SSL" to connect to the broker.\\\\nIf not explicitly configured, the default value will be null and there will be no dedicated endpoints for controller connections.\\\\nIf explicitly configured, the value cannot be the same as the value of <code>inter.broker.listener.name</code>.\\\'\'  configs.181:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.replication.factor  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.replication.factor  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.replication.factor  value:3  source:5"  config_type:4  documentation:"The replication factor for the transaction topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."\'  configs.182:\'kafka2.DescribeConfigsResourceResult32a  name:num.io.threads  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.io.threads  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.io.threads  value:8  source:5"  config_type:3  documentation:"The number of threads that the server uses for processing requests, which may include disk I/O"\'  configs.183:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.buffer.seconds  value:300  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.buffer.seconds  value:300  source:5"  config_type:4  documentation:"The amount of buffer time before credential expiration to maintain when refreshing a credential, in seconds. If a refresh would otherwise occur closer to expiration than the number of buffer seconds then the refresh will be moved up to maintain as much of the buffer time as possible. Legal values are between 0 and 3600 (1 hour); a default value of  300 (5 minutes) is used if no value is specified. This value and sasl.login.refresh.min.period.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER."\'  configs.184:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.heartbeat.interval.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.heartbeat.interval.ms  value:15000  source:5"  config_type:3  documentation:"The maximum heartbeat interval for share group members."\'  configs.185:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.commit.required.acks  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.commit.required.acks  value:-1  source:5"  config_type:4  documentation:"DEPRECATED: The required acks before the commit can be accepted. In general, the default (-1) should not be overridden."\'  configs.186:\'kafka2.DescribeConfigsResourceResult32a  name:connection.failed.authentication.delay.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connection.failed.authentication.delay.ms  value:100  source:5"  config_type:3  documentation:"Connection close delay on failed authentication: this is the time (in milliseconds) by which connection close will be delayed on authentication failure. This must be configured to be less than connections.max.idle.ms to prevent connection timeout."\'  configs.187:\'kafka2.DescribeConfigsResourceResult32a  name:delete.topic.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delete.topic.enable  value:true  source:5"  config_type:1  documentation:"Enables delete topic. Delete topic through the admin tool will have no effect if this config is turned off"\'  configs.188:\'kafka2.DescribeConfigsResourceResult32a  name:quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for client quotas"\'  configs.189:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.type  value:JKS  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.truststore.type  value:JKS  source:5"  config_type:2  documentation:"The file format of the trust store file. The values currently supported by the default `ssl.engine.factory.class` are [JKS, PKCS12, PEM]."\'  configs.190:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.commit.timeout.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.commit.timeout.ms  value:5000  source:5"  config_type:3  documentation:"Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached. This is similar to the producer request timeout."\'  configs.191:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.ocsp.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.ocsp.enable  value:false  source:5"  config_type:1  documentation:"Specifies whether to enable Online Certificate Status Protocol in the ZooKeeper TLS protocols. Overrides any explicit value set via the <code>zookeeper.ssl.ocsp</code> system property (note the shorter name)."\'  configs.192:\'kafka2.DescribeConfigsResourceResult32a  name:broker.heartbeat.interval.ms  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.heartbeat.interval.ms  value:2000  source:5"  config_type:3  documentation:"The length of time in milliseconds between broker heartbeats. Used when running in KRaft mode."\'  configs.193:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.record.lock.duration.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.record.lock.duration.ms  value:60000  source:5"  config_type:3  documentation:"The record acquisition lock maximum duration in milliseconds for share groups."\'  configs.194:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.mechanism.controller.protocol  value:GSSAPI  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.mechanism.controller.protocol  value:GSSAPI  source:5"  config_type:2  documentation:"SASL mechanism used for communication with controllers. Default is GSSAPI."\'  configs.195:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.max.compaction.lag.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.max.compaction.lag.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum time a message will remain ineligible for compaction in the log. Only applicable for logs that are being compacted."\'  configs.196:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.enabled.protocols  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:"Specifies the enabled protocol(s) in ZooKeeper TLS negotiation (csv). Overrides any explicit value set via the <code>zookeeper.ssl.enabledProtocols</code> system property (note the camelCase). The default value of <code>null</code> means the enabled protocol will be the value of the <code>zookeeper.ssl.protocol</code> configuration property."\'  configs.197:\'kafka2.DescribeConfigsResourceResult32a  name:allow.everyone.if.no.acl.found  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:allow.everyone.if.no.acl.found  source:4"  config_type:0\'  configs.198:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.class.path  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Class path of the `RemoteStorageManager` implementation. If specified, the RemoteStorageManager implementation and its dependent libraries will be loaded by a dedicated classloader which searches this class path before the Kafka broker class path. The syntax of this parameter is same as the standard Java class path string."\'  configs.199:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied."\'  configs.200:\'kafka2.DescribeConfigsResourceResult32a  name:alter.log.dirs.replication.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:alter.log.dirs.replication.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for alter log dirs replication quotas"\'  configs.201:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.enable  value:true  source:5"  config_type:1  documentation:"Enable the log cleaner process to run on the server. Should be enabled if using any topics with a cleanup.policy=compact including the internal offsets topic. If disabled those topics will not be compacted and continually grow in size."\'  configs.202:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.fetch.timeout.ms  value:10000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.fetch.timeout.ms  value:10000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.fetch.timeout.ms  value:2000  source:5"  config_type:3  documentation:"Maximum time without a successful fetch from the current leader before becoming a candidate and triggering an election for voters; Maximum time a leader can go without receiving valid fetch or fetchSnapshot request from a majority of the quorum before resigning."\'  configs.203:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.load.buffer.size  value:5242880  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.load.buffer.size  value:5242880  source:5"  config_type:3  documentation:"Batch size for reading from the offsets segments when loading offsets into the cache (soft-limit, overridden if records are too large)."\'  configs.204:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.client.auth  value:none  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.client.auth  value:none  source:5"  config_type:2  documentation:"Configures kafka broker to request client authentication. The following settings are common:  <ul> <li><code>ssl.client.auth=required</code> If set to required client authentication is required. <li><code>ssl.client.auth=requested</code> This means client authentication is optional. unlike required, if this option is set client can choose not to provide authentication information about itself <li><code>ssl.client.auth=none</code> This means client authentication is not needed.</ul>"\'  configs.205:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.max.retries  value:3  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.max.retries  value:3  source:5"  config_type:3  documentation:"Controlled shutdown can fail for multiple reasons. This determines the number of retries when such failure happens"\'  configs.206:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.replication.factor  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.replication.factor  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.replication.factor  value:3  source:5"  config_type:4  documentation:"The replication factor for the offsets topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."\'  configs.207:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.type  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Truststore type when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.type</code> system property (note the camelCase). The default value of <code>null</code> means the type will be auto-detected based on the filename extension of the truststore."\'  configs.208:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.min.isr  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.min.isr  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.min.isr  value:2  source:5"  config_type:3  documentation:"The minimum number of replicas that must acknowledge a write to transaction topic in order to be considered successful."\'  configs.209:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.secure.random.implementation  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The SecureRandom PRNG implementation to use for SSL cryptography operations. "\'  configs.210:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.ticket.renew.jitter  value:0.05  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.ticket.renew.jitter  value:0.05  source:5"  config_type:6  documentation:"Percentage of random jitter added to the renewal time."\'  configs.211:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.trustmanager.algorithm  value:PKIX  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.trustmanager.algorithm  value:PKIX  source:5"  config_type:2  documentation:"The algorithm used by trust manager factory for SSL connections. Default value is the trust manager factory algorithm configured for the Java Virtual Machine."\'  configs.212:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.session.timeout.ms  value:18000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.session.timeout.ms  value:18000  source:5"  config_type:3  documentation:"Zookeeper session timeout"\'  configs.213:\'kafka2.DescribeConfigsResourceResult32a  name:log.local.retention.bytes  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.bytes  value:-2  source:5"  config_type:5  documentation:"The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. Default value is -2, it represents `log.retention.bytes` value to be used. The effective value should always be less than or equal to `log.retention.bytes` value."\'  configs.214:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.bytes  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.bytes  value:-1  source:5"  config_type:5  documentation:"The maximum size of the log before deleting it"\'  configs.215:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for controller mutations quotas"\'  configs.216:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.impl.prefix  value:rlmm.config.  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.manager.impl.prefix  value:rlmm.config.  source:5"  config_type:2  documentation:"Prefix used for properties to be passed to RemoteLogMetadataManager implementation. For example this value can be `rlmm.config.`."\'  configs.217:"kafka2.DescribeConfigsResourceResult32a  name:sasl.jaas.config  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\'JAAS login context parameters for SASL connections in the format used by JAAS configuration files. JAAS configuration file format is described <a href=\\"https://docs.oracle.com/javase/8/docs/technotes/guides/security/jgss/tutorials/LoginConfigFile.html\\">here</a>. The format for the value is: <code>loginModuleClass controlFlag (optionName=optionValue)*;</code>. For brokers, the config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=com.example.ScramLoginModule required;\'"  configs.218:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.min.time.before.relogin  value:60000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.min.time.before.relogin  value:60000  source:5"  config_type:5  documentation:"Login thread sleep time between refresh attempts."\'  configs.219:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.retention.minutes  value:10080  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.retention.minutes  value:10080  source:5"  config_type:3  documentation:"For subscribed consumers, committed offset of a specific partition will be expired and discarded when 1) this retention period has elapsed after the consumer group loses all its consumers (i.e. becomes empty); 2) this retention period has elapsed since the last time an offset is committed for the partition and the group is no longer subscribed to the corresponding topic. For standalone consumers (using manual assignment), offsets will be expired after this retention period has elapsed since the time of last commit. Note that when a group is deleted via the delete-group request, its committed offsets will also be deleted without extra retention period; also when a topic is deleted via the delete-topic request, upon propagated metadata update any group\\\'s committed offsets for that topic will also be deleted without extra retention period."\'  configs.220:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.backoff.ms  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.backoff.ms  value:1000  source:5"  config_type:3  documentation:"The amount of time to sleep when fetch partition error occurs."\'  configs.221:\'kafka2.DescribeConfigsResourceResult32a  name:inter.broker.protocol.version  value:3.9-IV0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:inter.broker.protocol.version  value:3.9-IV0  source:5"  config_type:2  documentation:"Specify which version of the inter-broker protocol will be used.\\\\n. This is typically bumped after all brokers were upgraded to a new version.\\\\n Example of some valid values are: 0.8.0, 0.8.1, 0.8.1.1, 0.8.2, 0.8.2.0, 0.8.2.1, 0.9.0.0, 0.9.0.1 Check MetadataVersion for the full list."\'  configs.222:\'kafka2.DescribeConfigsResourceResult32a  name:kafka.metrics.reporters  value:""  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:kafka.metrics.reporters  value:""  source:5\\\'  config_type:7  documentation:"A list of classes to use as Yammer metrics custom reporters. The reporters should implement <code>kafka.metrics.KafkaMetricsReporter</code> trait. If a client wants to expose JMX operations on a custom reporter, the custom reporter needs to additionally implement an MBean trait that extends <code>kafka.metrics.KafkaMetricsReporterMBean</code> trait so that the registered MBean is compliant with the standard MBean convention."\'  configs.223:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.delivery.count.limit  value:5  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.delivery.count.limit  value:5  source:5"  config_type:3  documentation:"The maximum number of delivery attempts for a record delivered to a share group."\'  configs.224:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.allow.san.changes  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.allow.san.changes  value:false  source:5"  config_type:1  documentation:"Indicates whether changes to the certificate subject alternative names should be allowed during a dynamic reconfiguration of certificates or not."\'  configs.225:\'kafka2.DescribeConfigsResourceResult32a  name:compression.zstd.level  value:3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.zstd.level  value:3  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'zstd\\\'."\'  configs.226:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for remote copy quota management. The default value is 11, which means there are 10 whole windows + 1 current window."\'  configs.227:\'kafka2.DescribeConfigsResourceResult32a  name:num.partitions  value:3  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.partitions  value:3  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.partitions  value:1  source:5"  config_type:3  documentation:"The default number of log partitions per topic"\'  configs.228:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.certificate.chain  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Certificate chain in the format specified by \'ssl.keystore.type\'. Default SSL engine factory supports only PEM format with a list of X.509 certificates\\""  configs.229:\'kafka2.DescribeConfigsResourceResult32a  name:socket.connection.setup.timeout.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.connection.setup.timeout.ms  value:10000  source:5"  config_type:5  documentation:"The amount of time the client will wait for the socket connection to be established. If the connection is not built before the timeout elapses, clients will close the socket channel. This value is the initial backoff value and will increase exponentially for each consecutive connection failure, up to the <code>socket.connection.setup.timeout.max.ms</code> value."\'  configs.230:\'kafka2.DescribeConfigsResourceResult32a  name:broker.id.generation.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.id.generation.enable  value:true  source:5"  config_type:1  documentation:"Enable automatic broker id generation on the server. When enabled the value configured for reserved.broker.max.id should be reviewed."\'  configs.231:\'kafka2.DescribeConfigsResourceResult32a  name:listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107,CONTROLLER://dev.ak-8.kafka-4.int-0:1055  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107,CONTROLLER://dev.ak-8.kafka-4.int-0:1055  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:listeners  value:PLAINTEXT://:9092  source:5"  config_type:2  documentation:"Listener List - Comma-separated list of URIs we will listen on and the listener names. If the listener name is not a security protocol, <code>listener.security.protocol.map</code> must also be set.\\\\n Listener names and port numbers must be unique unless %n one listener is an IPv4 address and the other listener is %n an IPv6 address (for the same port).%n Specify hostname as 0.0.0.0 to bind to all interfaces.%n Leave hostname empty to bind to default interface.%n Examples of legal listener lists:%n <code>PLAINTEXT://myhost:9092,SSL://:9091</code>%n <code>CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093</code>%n <code>PLAINTEXT://127.0.0.1:9092,SSL://[::1]:9092</code>%n"\'  configs.232:"kafka2.DescribeConfigsResourceResult32a  name:ssl.enabled.protocols  value:TLSv1.2,TLSv1.3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:ssl.enabled.protocols  value:TLSv1.2,TLSv1.3  source:5\\"  config_type:7  documentation:\\"The list of protocols enabled for SSL connections. The default is \'TLSv1.2,TLSv1.3\' when running with Java 11 or newer, \'TLSv1.2\' otherwise. With the default value for Java 11, clients and servers will prefer TLSv1.3 if both support it and fallback to TLSv1.2 otherwise (assuming both support at least TLSv1.2). This default should be fine for most cases. Also see the config documentation for `ssl.protocol`.\\""  configs.233:\'kafka2.DescribeConfigsResourceResult32a  name:inter.broker.listener.name  value:INTERNAL  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:inter.broker.listener.name  value:INTERNAL  source:4"  config_type:2  documentation:"Name of listener used for communication between brokers. If this is unset, the listener name is defined by security.inter.broker.protocolIt is an error to set this and security.inter.broker.protocol properties at the same time."\'  configs.234:\'kafka2.DescribeConfigsResourceResult32a  name:alter.config.policy.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The alter configs policy class that should be used for validation. The class should implement the <code>org.apache.kafka.server.policy.AlterConfigPolicy</code> interface."\'  configs.235:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.expiry.check.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.expiry.check.interval.ms  value:3600000  source:5"  config_type:5  documentation:"Scan interval to remove expired delegation tokens."\'  configs.236:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.scheduler.interval.ms  value:9223372036854775807  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.scheduler.interval.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"The frequency in ms that the log flusher checks whether any log needs to be flushed to disk"\'  configs.237:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.max.in.flight.requests  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.max.in.flight.requests  value:10  source:5"  config_type:3  documentation:"The maximum number of unacknowledged requests the client will send to ZooKeeper before blocking."\'  configs.238:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.expiration.thread.pool.size  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.expiration.thread.pool.size  value:-1  source:5"  config_type:3  documentation:"Size of the thread pool used in scheduling tasks to clean up remote log segments. The default value of -1 means that this will be set to the configured value of remote.log.manager.thread.pool.size, if available; otherwise, it defaults to 10."\'  configs.239:\'kafka2.DescribeConfigsResourceResult32a  name:log.index.size.max.bytes  value:10485760  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.size.max.bytes  value:10485760  source:5"  config_type:3  documentation:"The maximum size in bytes of the offset index"\'  configs.240:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keymanager.algorithm  value:SunX509  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.keymanager.algorithm  value:SunX509  source:5"  config_type:2  documentation:"The algorithm used by key manager factory for SSL connections. Default value is the key manager factory algorithm configured for the Java Virtual Machine."\'  configs.241:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL login callback handler class that implements the AuthenticateCallbackHandler interface. For brokers, login callback handler config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.callback.handler.class=com.example.CustomScramLoginCallbackHandler"\'  configs.242:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.max.bytes  value:10485760  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.max.bytes  value:10485760  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.max.bytes  value:1048576  source:5"  config_type:3  documentation:"The number of bytes of messages to attempt to fetch for each partition. This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. The maximum record batch size accepted by the broker is defined via <code>message.max.bytes</code> (broker config) or <code>max.message.bytes</code> (topic config)."\'  configs.243:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.crl.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.crl.enable  value:false  source:5"  config_type:1  documentation:"Specifies whether to enable Certificate Revocation List in the ZooKeeper TLS protocols. Overrides any explicit value set via the <code>zookeeper.ssl.crl</code> system property (note the shorter name)."\'  configs.244:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.server.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL server callback handler class that implements the AuthenticateCallbackHandler interface. Server callback handlers must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.plain.sasl.server.callback.handler.class=com.example.CustomPlainCallbackHandler."\'  configs.245:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.groups  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.groups  value:10  source:5"  config_type:4  documentation:"The maximum number of share groups."\'  configs.246:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.dedupe.buffer.size  value:134217728  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.dedupe.buffer.size  value:134217728  source:5"  config_type:5  documentation:"The total memory used for log deduplication across all cleaner threads"\'  configs.247:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.buffer.size  value:524288  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.buffer.size  value:524288  source:5"  config_type:3  documentation:"The total memory used for log cleaner I/O buffers across all cleaner threads"\'  configs.248:\'kafka2.DescribeConfigsResourceResult32a  name:create.topic.policy.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The create topic policy class that should be used for validation. The class should implement the <code>org.apache.kafka.server.policy.CreateTopicPolicy</code> interface."\'  configs.249:"kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.certificates  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Trusted certificates in the format specified by \'ssl.truststore.type\'. Default SSL engine factory supports only PEM format with X.509 certificates.\\""  configs.250:\'kafka2.DescribeConfigsResourceResult32a  name:socket.listen.backlog.size  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.listen.backlog.size  value:50  source:5"  config_type:3  documentation:"The maximum number of pending connections on the socket. In Linux, you may also need to configure <code>somaxconn</code> and <code>tcp_max_syn_backlog</code> kernel parameters accordingly to make the configuration takes effect."\'  configs.251:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.retry.backoff.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.retry.backoff.ms  value:5000  source:5"  config_type:5  documentation:"Before each retry, the system needs time to recover from the state that caused the previous failure (Controller fail over, replica lag etc). This config determines the amount of time to wait before retrying."\'  configs.252:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.server.max.receive.size  value:524288  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.server.max.receive.size  value:524288  source:5"  config_type:3  documentation:"The maximum receive size allowed before and during initial SASL authentication. Default receive size is 512KB. GSSAPI limits requests to 64K, but we allow upto 512KB by default for custom SASL mechanisms. In practice, PLAIN, SCRAM and OAUTH mechanisms can use much smaller limits."\'  configs.253:\'kafka2.DescribeConfigsResourceResult32a  name:security.providers  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"A list of configurable creator classes each returning a provider implementing security algorithms. These classes should implement the <code>org.apache.kafka.common.security.auth.SecurityProviderCreator</code> interface."\'  configs.254:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.max.snapshot.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.max.snapshot.interval.ms  value:3600000  source:5"  config_type:5  documentation:"This is the maximum number of milliseconds to wait to generate a snapshot if there are committed records in the log that are not included in the latest snapshot. A value of zero disables time based snapshot generation. The default value is 3600000. To generate snapshots based on the number of metadata bytes, see the <code>metadata.log.max.record.bytes.between.snapshots</code> configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached."\'  configs.255:\'kafka2.DescribeConfigsResourceResult32a  name:compression.lz4.level  value:9  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.lz4.level  value:9  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'lz4\\\'."\'  configs.256:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.hours  value:168  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.roll.hours  value:168  source:5"  config_type:3  documentation:"The maximum time before a new log segment is rolled out (in hours), secondary to log.roll.ms property"\'  configs.257:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleanup.policy  value:delete  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleanup.policy  value:delete  source:5"  config_type:7  documentation:\\\'The default cleanup policy for segments beyond the retention window. A comma separated list of valid policies. Valid policies are: "delete" and "compact"\\\'\'  configs.258:\'kafka2.DescribeConfigsResourceResult32a  name:initial.broker.registration.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:initial.broker.registration.timeout.ms  value:60000  source:5"  config_type:3  documentation:"When initially registering with the controller quorum, the number of milliseconds to wait before declaring failure and exiting the broker process."\'  configs.259:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.start.offset.checkpoint.interval.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.start.offset.checkpoint.interval.ms  value:60000  source:5"  config_type:3  documentation:"The frequency with which we update the persistent record of log start offset"\'  configs.260:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.jitter.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used"\'  configs.261:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.segment.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.segment.bytes  value:104857600  source:5"  config_type:3  documentation:"The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads"\'  configs.262:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.segment.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.segment.bytes  value:104857600  source:5"  config_type:3  documentation:"The offsets topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads."\'  configs.263:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.idle.interval.ms  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.idle.interval.ms  value:500  source:5"  config_type:3  documentation:"This configuration controls how often the active controller should write no-op records to the metadata partition. If the value is 0, no-op records are not appended to the metadata partition. The default value is 500"\'  configs.264:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.class.name  value:org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.manager.class.name  value:org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager  source:5"  config_type:2  documentation:"Fully qualified class name of `RemoteLogMetadataManager` implementation."\'  configs.265:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.retry.backoff.max.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.retry.backoff.max.ms  value:10000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the maximum wait between login attempts to the external authentication provider. Login uses an exponential backoff algorithm with an initial wait based on the sasl.login.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.login.retry.backoff.max.ms setting. Currently applies only to OAUTHBEARER."\'  configs.266:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.task.interval.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.task.interval.ms  value:30000  source:5"  config_type:5  documentation:"Interval at which remote log manager runs the scheduled tasks like copy segments, and clean up remote log segments."\'  configs.267:\'kafka2.DescribeConfigsResourceResult32a  name:group.initial.rebalance.delay.ms  value:3000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.initial.rebalance.delay.ms  value:3000  source:5"  config_type:3  documentation:"The amount of time the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins."\'  configs.268:\'kafka2.DescribeConfigsResourceResult32a  name:log.index.interval.bytes  value:4096  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.interval.bytes  value:4096  source:5"  config_type:3  documentation:"The interval with which we add an entry to the offset index."\'  configs.269:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.backoff.ms  value:15000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.backoff.ms  value:15000  source:5"  config_type:5  documentation:"The amount of time to sleep when there are no logs to clean"\'  configs.270:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.location  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The location of the trust store file."\'  configs.271:\'kafka2.DescribeConfigsResourceResult32a  name:offset.metadata.max.bytes  value:4096  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offset.metadata.max.bytes  value:4096  source:5"  config_type:3  documentation:"The maximum size for a metadata entry associated with an offset commit."\'  configs.272:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"The store password for the key store file. This is optional for client and only needed if \'ssl.keystore.location\' is configured. Key store password is not supported for PEM format.\\""  configs.273:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.metadata.migration.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.metadata.migration.enable  value:false  source:5"  config_type:1  documentation:"Enable ZK to KRaft migration"\'  configs.274:\'kafka2.DescribeConfigsResourceResult32a  name:fetch.max.bytes  value:57671680  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:fetch.max.bytes  value:57671680  source:5"  config_type:3  documentation:"The maximum number of bytes we will return for a fetch request. Must be at least 1024."\'  configs.275:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.retention.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.retention.bytes  value:104857600  source:5"  config_type:5  documentation:"The maximum combined size of the metadata log and snapshots before deleting old snapshots and log files. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit."\'  configs.276:"kafka2.DescribeConfigsResourceResult32a  name:compression.type  value:producer  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:compression.type  value:producer  source:5\\"  config_type:2  documentation:\\"Specify the final compression type for a given topic. This configuration accepts the standard compression codecs (\'gzip\', \'snappy\', \'lz4\', \'zstd\'). It additionally accepts \'uncompressed\' which is equivalent to no compression; and \'producer\' which means retain the original compression codec set by the producer.\\""  configs.277:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.connect.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The (optional) value in milliseconds for the external authentication provider connection timeout. Currently applies only to OAUTHBEARER."\'  configs.278:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections.per.ip.overrides  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:max.connections.per.ip.overrides  value:""  source:5\\\'  config_type:2  documentation:\\\'A comma-separated list of per-ip or hostname overrides to the default maximum number of connections. An example value is "hostName:100,127.0.0.1:200"\\\'\'  configs.279:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.heartbeat.interval.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.heartbeat.interval.ms  value:15000  source:5"  config_type:3  documentation:"The maximum heartbeat interval for registered consumers."\'  configs.280:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.window.factor  value:0.8  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.window.factor  value:0.8  source:5"  config_type:6  documentation:"Login refresh thread will sleep until the specified window factor relative to the credential\\\'s lifetime has been reached, at which time it will try to refresh the credential. Legal values are between 0.5 (50%) and 1.0 (100%) inclusive; a default value of 0.8 (80%) is used if no value is specified. Currently applies only to OAUTHBEARER."\'  configs.281:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.class.path  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Class path of the `RemoteLogMetadataManager` implementation. If specified, the RemoteLogMetadataManager implementation and its dependent libraries will be loaded by a dedicated classloader which searches this class path before the Kafka broker class path. The syntax of this parameter is same as the standard Java class path string."\'  configs.282:\'kafka2.DescribeConfigsResourceResult32a  name:kafka.metrics.polling.interval.secs  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:kafka.metrics.polling.interval.secs  value:10  source:5"  config_type:3  documentation:"The metrics polling interval (in seconds) which can be used in kafka.metrics.reporters implementations."\'  configs.283:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.max.record.bytes.between.snapshots  value:20971520  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.max.record.bytes.between.snapshots  value:20971520  source:5"  config_type:5  documentation:"This is the maximum number of bytes in the log between the latest snapshot and the high-watermark needed before generating a new snapshot. The default value is 20971520. To generate snapshots based on the time elapsed, see the <code>metadata.log.max.snapshot.interval.ms</code> configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached."\'  configs.284:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.retention.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.retention.ms  value:604800000  source:5"  config_type:5  documentation:"The number of milliseconds to keep a metadata log file or snapshot before deleting it. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit."\'  configs.285:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.election.backoff.max.ms  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.backoff.max.ms  value:1000  source:5"  config_type:3  documentation:"Maximum time in milliseconds before starting new elections. This is used in the binary exponential backoff mechanism that helps prevent gridlocked elections"\'  configs.286:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.size  value:200  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.size  value:200  source:5"  config_type:4  documentation:"The maximum number of members that a single share group can accommodate."\'  configs.287:\'kafka2.DescribeConfigsResourceResult32a  name:max.incremental.fetch.session.cache.slots  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.incremental.fetch.session.cache.slots  value:1000  source:5"  config_type:3  documentation:"The maximum number of total incremental fetch sessions that we will maintain. FetchSessionCache is sharded into 8 shards and the limit is equally divided among all shards. Sessions are allocated to each shard in round-robin. Only entries within a shard are considered eligible for eviction."\'  configs.288:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.master.key  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"DEPRECATED: An alias for delegation.token.secret.key, which should be used instead of this config."\'  configs.289:"kafka2.DescribeConfigsResourceResult32a  name:ssl.key.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"The password of the private key in the key store file or the PEM key specified in \'ssl.keystore.key\'.\\""  configs.290:\'kafka2.DescribeConfigsResourceResult32a  name:reserved.broker.max.id  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:reserved.broker.max.id  value:1000  source:5"  config_type:3  documentation:"Max number that can be used for a broker.id"\'  configs.291:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.remove.expired.transaction.cleanup.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.remove.expired.transaction.cleanup.interval.ms  value:3600000  source:5"  config_type:3  documentation:"The interval at which to remove transactions that have expired due to <code>transactional.id.expiration.ms</code> passing"\'  configs.292:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.downconversion.enable  value:true  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.downconversion.enable  value:true  source:5"  config_type:1  documentation:"This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. When set to <code>false</code>, broker will not perform down-conversion for consumers expecting an older message format. The broker responds with <code>UNSUPPORTED_VERSION</code> error for consume requests from such older clients. This configurationdoes not apply to any message format conversion that might be required for replication to followers."\'  configs.293:"kafka2.DescribeConfigsResourceResult32a  name:ssl.protocol  value:TLSv1.3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:ssl.protocol  value:TLSv1.3  source:5\\"  config_type:2  documentation:\\"The SSL protocol used to generate the SSLContext. The default is \'TLSv1.3\' when running with Java 11 or newer, \'TLSv1.2\' otherwise. This value should be fine for most use cases. Allowed values in recent JVMs are \'TLSv1.2\' and \'TLSv1.3\'. \'TLS\', \'TLSv1.1\', \'SSL\', \'SSLv2\' and \'SSLv3\' may be supported in older JVMs, but their usage is discouraged due to known security vulnerabilities. With the default value for this config and \'ssl.enabled.protocols\', clients will downgrade to \'TLSv1.2\' if the server does not support \'TLSv1.3\'. If this config is set to \'TLSv1.2\', clients will not use \'TLSv1.3\' even if it is one of the values in ssl.enabled.protocols and the server only supports \'TLSv1.3\'.\\""  configs.294:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.segment.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.segment.ms  value:604800000  source:5"  config_type:5  documentation:"The maximum time before a new metadata log file is rolled out (in milliseconds)."\'  configs.295:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.load.buffer.size  value:5242880  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.load.buffer.size  value:5242880  source:5"  config_type:3  documentation:"Batch size for reading from the transaction log segments when loading producer ids and transactions into the cache (soft-limit, overridden if records are too large)."\'  configs.296:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.location  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The location of the key store file. This is optional for client and can be used for two-way authentication for client."\'  configs.297:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.append.linger.ms  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.append.linger.ms  value:10  source:5"  config_type:3  documentation:"The duration in milliseconds that the coordinator will wait for writes to accumulate before flushing them to disk. Transactional writes are not accumulated."\'  configs.298:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.enabled.mechanisms  value:GSSAPI  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.enabled.mechanisms  value:GSSAPI  source:5"  config_type:7  documentation:"The list of SASL mechanisms enabled in the Kafka server. The list may contain any mechanism for which a security provider is available. Only GSSAPI is enabled by default."\'  configs.299:\'kafka2.DescribeConfigsResourceResult32a  name:num.replica.alter.log.dirs.threads  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The number of threads that can move replicas between log directories, which may include disk I/O"\'  configs.300:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.session.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.session.timeout.ms  value:60000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for share group members."\'  configs.301:"kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.cipher.suites  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:\'Specifies the enabled cipher suites to be used in ZooKeeper TLS negotiation (csv). Overrides any explicit value set via the <code>zookeeper.ssl.ciphersuites</code> system property (note the single word \\"ciphersuites\\"). The default value of <code>null</code> means the list of enabled cipher suites is determined by the Java runtime being used.\'"  configs.302:\'kafka2.DescribeConfigsResourceResult32a  name:group.min.session.timeout.ms  value:6000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.min.session.timeout.ms  value:6000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for registered consumers. Shorter timeouts result in quicker failure detection at the cost of more frequent consumer heartbeating, which can overwhelm broker resources."\'  configs.303:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.buffer.load.factor  value:0.9  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.buffer.load.factor  value:0.9  source:5"  config_type:6  documentation:"Log cleaner dedupe buffer load factor. The percentage full the dedupe buffer can become. A higher value will allow more log to be cleaned at once but will lead to more hash collisions"\'  configs.304:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.max.timeout.ms  value:900000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.max.timeout.ms  value:900000  source:5"  config_type:3  documentation:"The maximum allowed timeout for transactions. If a client\\\\342\\\\200\\\\231s requested transaction time exceed this, then the broker will return an error in InitProducerIdRequest. This prevents a client from too large of a timeout, which can stall consumers reading from topics included in the transaction."\'  configs.305:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.dir  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"This configuration determines where we put the metadata log for clusters in KRaft mode. If it is not set, the metadata log is placed in the first log directory from log.dirs."\'  configs.306:"kafka2.DescribeConfigsResourceResult32a  name:process.roles  value:broker,controller  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:process.roles  value:broker,controller  source:4\\"  synonyms.1:\'kafka2.DescribeConfigsSynonym32a  name:process.roles  value:\\"\\"  source:5\'  config_type:7  documentation:\\"The roles that this process plays: \'broker\', \'controller\', or \'broker,controller\' if it is both. This configuration is only applicable for clusters in KRaft (Kafka Raft) mode (instead of ZooKeeper). Leave this config undefined or empty for ZooKeeper clusters.\\""  configs.307:\'kafka2.DescribeConfigsResourceResult32a  name:group.max.size  value:2147483647  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.max.size  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of consumers that a single consumer group can accommodate."\'  configs.308:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms  value:10000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the maximum wait between attempts to retrieve the JWKS (JSON Web Key Set) from the external authentication provider. JWKS retrieval uses an exponential backoff algorithm with an initial wait based on the sasl.oauthbearer.jwks.endpoint.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms setting."\'  configs.309:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.max.lifetime.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.max.lifetime.ms  value:604800000  source:5"  config_type:5  documentation:"The token has a maximum lifetime beyond which it cannot be renewed anymore. Default value 7 days."\'  configs.310:\'kafka2.DescribeConfigsResourceResult32a  name:max.request.partition.size.limit  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.request.partition.size.limit  value:2000  source:5"  config_type:3  documentation:"The maximum number of partitions can be served in one request."\'  configs.311:\'kafka2.DescribeConfigsResourceResult32a  name:broker.id  value:4  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.id  value:4  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:broker.id  value:-1  source:5"  config_type:3  documentation:"The broker id for this server. If unset, a unique broker id will be generated.To avoid conflicts between ZooKeeper generated broker id\\\'s and user configured broker id\\\'s, generated broker ids start from reserved.broker.max.id + 1."\'  configs.312:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.compression.codec  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.compression.codec  value:0  source:5"  config_type:3  documentation:\\\'Compression codec for the offsets topic - compression may be used to achieve "atomic" commits.\\\'\'  configs.313:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.endpoint.identification.algorithm  value:HTTPS  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.endpoint.identification.algorithm  value:HTTPS  source:5"  config_type:2  documentation:\\\'Specifies whether to enable hostname verification in the ZooKeeper TLS negotiation process, with (case-insensitively) "https" meaning ZooKeeper hostname verification is enabled and an explicit blank value meaning it is disabled (disabling it is only recommended for testing purposes). An explicit value overrides any "true" or "false" value set via the <code>zookeeper.ssl.hostnameVerification</code> system property (note the different name and values; true implies https and false implies blank).\\\'\'  configs.314:\'kafka2.DescribeConfigsResourceResult32a  name:replication.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replication.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for replication quotas"\'  configs.315:\'kafka2.DescribeConfigsResourceResult32a  name:advertised.listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:advertised.listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107  source:4"  config_type:2  documentation:"Listeners to publish to ZooKeeper for clients to use, if different than the <code>listeners</code> config property. In IaaS environments, this may need to be different from the interface to which the broker binds. If this is not set, the value for <code>listeners</code> will be used. Unlike <code>listeners</code>, it is not valid to advertise the 0.0.0.0 meta-address.\\\\n Also unlike <code>listeners</code>, there can be duplicated ports in this property, so that one listener can be configured to advertise another listener\\\'s address. This can be useful in some cases where external load balancers are used."\'  configs.316:\'kafka2.DescribeConfigsResourceResult32a  name:queued.max.request.bytes  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:queued.max.request.bytes  value:-1  source:5"  config_type:5  documentation:"The number of queued bytes allowed before no more requests are read"\''
iframe:000000000118  ts_ns:1633395711120550  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:5  client_id:redpanda-console
iframe:000000000193  ts_ns:1633395728461158  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:5  throttle_time_ms:0  error_code:0  results.0:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  total_bytes:-1  usable_bytes:-1"  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  total_bytes:-1  usable_bytes:-1"
iframe:000000000192  ts_ns:1633395728086707  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:6  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000194  ts_ns:1633395729735897  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:6  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000196  ts_ns:1633395730000966  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:7  client_id:redpanda-console
iframe:000000000197  ts_ns:1633395731366508  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:7  throttle_time_ms:0  error_code:0  results.0:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  total_bytes:-1  usable_bytes:-1"  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  total_bytes:-1  usable_bytes:-1"
iframe:000000000199  ts_ns:1633395732453593  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:8  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000204  ts_ns:1633395737481152  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:8  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000212  ts_ns:1633398117975552  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:9  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000215  ts_ns:1633398118898822  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:9  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000214  ts_ns:1633398118018406  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:10  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000218  ts_ns:1633398120378828  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:10  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000220  ts_ns:1633398148142252  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:11  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000221  ts_ns:1633398149447635  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:11  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000222  ts_ns:1633398149709862  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:12  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000225  ts_ns:1633398150523520  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:12  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000226  ts_ns:1633398150692864  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:13  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000227  ts_ns:1633398151763891  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:13  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000228  ts_ns:1633398152018579  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:14  client_id:redpanda-console
iframe:000000000229  ts_ns:1633398153777152  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:14  throttle_time_ms:0  error_code:0  results.0:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  total_bytes:-1  usable_bytes:-1"  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  total_bytes:-1  usable_bytes:-1"
iframe:000000000240  ts_ns:1633405654142905  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:15  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000243  ts_ns:1633405654718348  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:15  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000242  ts_ns:1633405654187609  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:16  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000249  ts_ns:1633405656736627  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:16  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000247  ts_ns:1633405656698169  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:17  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000250  ts_ns:1633405658013734  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:17  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000252  ts_ns:1633405658210662  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:18  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000254  ts_ns:1633405659685587  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:18  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000255  ts_ns:1633405659952838  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:19  client_id:redpanda-console
iframe:000000000258  ts_ns:1633405666548665  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:19  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:0  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000261  ts_ns:1633417600025664  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:20  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000267  ts_ns:1633417601893817  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:20  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000263  ts_ns:1633417600571904  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:21  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000271  ts_ns:1633417603566713  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:21  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000266  ts_ns:1633417601231814  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:22  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000275  ts_ns:1633417605367596  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:22  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000273  ts_ns:1633417603871276  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:23  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000290  ts_ns:1633417607039648  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:23  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000287  ts_ns:1633417605740844  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:24  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000293  ts_ns:1633417608502892  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:24  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000288  ts_ns:1633417605783001  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:25  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000298  ts_ns:1633417610023545  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:25  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000291  ts_ns:1633417607302944  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:26  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000300  ts_ns:1633417611244908  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:26  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000294  ts_ns:1633417608702457  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:27  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-1"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-1"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-1"'  timeout_ms:0
iframe:000000000302  ts_ns:1633417622193913  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:27  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000297  ts_ns:1633417609228480  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:28  client_id:redpanda-console  topics.0:"kafka2.DescribableLogDirTopic35q  topic:ap1  partitions.0:2  partitions.1:1  partitions.2:0"
iframe:000000000303  ts_ns:1633417626228620  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:28  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:0  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000299  ts_ns:1633417610239187  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:29  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-2"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-2"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-2"'  timeout_ms:0
iframe:000000000305  ts_ns:1633417631961606  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:29  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000301  ts_ns:1633417611428230  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:30  client_id:redpanda-console
iframe:000000000306  ts_ns:1633417633941580  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:30  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:0  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000359  ts_ns:1633440316261190  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:31  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000364  ts_ns:1633440316844000  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:31  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000361  ts_ns:1633440316306617  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:32  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000368  ts_ns:1633440317961267  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:32  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000363  ts_ns:1633440316754835  c_port:55134 kafka2.DescribeConfigsRequest  request_api_version:3  correlation_id:33  client_id:redpanda-console  resources.0:"kafka2.DescribeConfigsResource32q  resource_type:2  resource_name:ap1"  include_synonyms:Y  include_documentation:Y
iframe:000000000384  ts_ns:1633440320794489  c_port:55134 kafka2.DescribeConfigsResponse  request_api_version:3  correlation_id:33  throttle_time_ms:0  results.0:'kafka2.DescribeConfigsResult32a  error_code:0  error_message:""  resource_type:2  resource_name:ap1  configs.0:"kafka2.DescribeConfigsResourceResult32a  name:compression.type  value:producer  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:compression.type  value:producer  source:5\\"  config_type:2  documentation:\\"Specify the final compression type for a given topic. This configuration accepts the standard compression codecs (\'gzip\', \'snappy\', \'lz4\', \'zstd\'). It additionally accepts \'uncompressed\' which is equivalent to no compression; and \'producer\' which means retain the original compression codec set by the producer.\\""  configs.1:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.delete.on.disable  value:false  read_only:N  config_source:5  is_sensitive:N  config_type:1  documentation:"Determines whether tiered data for a topic should be deleted after tiered storage is disabled on a topic. This configuration should be enabled when trying to set `remote.storage.enable` from true to false"\'  configs.2:\'kafka2.DescribeConfigsResourceResult32a  name:leader.replication.throttled.replicas  value:""  read_only:N  config_source:5  is_sensitive:N  config_type:7  documentation:"A list of replicas for which log replication should be throttled on the leader side. The list should describe a set of replicas in the form [PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard \\\'*\\\' can be used to throttle all replicas for this topic."\'  configs.3:\'kafka2.DescribeConfigsResourceResult32a  name:remote.storage.enable  value:false  read_only:N  config_source:5  is_sensitive:N  config_type:1  documentation:"To enable tiered storage for a topic, set this configuration as true. You can not disable this config once it is enabled. It will be provided in future versions."\'  configs.4:\'kafka2.DescribeConfigsResourceResult32a  name:message.downconversion.enable  value:true  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.downconversion.enable  value:true  source:5"  config_type:1  documentation:"This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. When set to <code>false</code>, broker will not perform down-conversion for consumers expecting an older message format. The broker responds with <code>UNSUPPORTED_VERSION</code> error for consume requests from such older clients. This configurationdoes not apply to any message format conversion that might be required for replication to followers."\'  configs.5:\'kafka2.DescribeConfigsResourceResult32a  name:min.insync.replicas  value:1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:min.insync.replicas  value:1  source:5"  config_type:3  documentation:\\\'When a producer sets acks to "all" (or "-1"), this configuration specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).<br>When used together, <code>min.insync.replicas</code> and <code>acks</code> allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set <code>min.insync.replicas</code> to 2, and produce with <code>acks</code> of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.\\\'\'  configs.6:\'kafka2.DescribeConfigsResourceResult32a  name:segment.jitter.ms  value:0  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum random jitter subtracted from the scheduled segment roll time to avoid thundering herds of segment rolling"\'  configs.7:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.copy.disable  value:false  read_only:N  config_source:5  is_sensitive:N  config_type:1  documentation:"Determines whether tiered data for a topic should become read only, and no more data uploading on a topic. Once this config is set to true, the local retention configuration (i.e. local.retention.ms/bytes) becomes irrelevant, and all data expiration follows the topic-wide retention configuration(i.e. retention.ms/bytes)."\'  configs.8:\'kafka2.DescribeConfigsResourceResult32a  name:local.retention.ms  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.ms  value:-2  source:5"  config_type:5  documentation:"The number of milliseconds to keep the local log segment before it gets deleted. Default value is -2, it represents `retention.ms` value is to be used. The effective value should always be less than or equal to `retention.ms` value."\'  configs.9:\'kafka2.DescribeConfigsResourceResult32a  name:cleanup.policy  value:delete  read_only:N  config_source:1  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:cleanup.policy  value:delete  source:1"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.cleanup.policy  value:delete  source:5"  config_type:7  documentation:\\\'This config designates the retention policy to use on log segments. The "delete" policy (which is the default) will discard old segments when their retention time or size limit has been reached. The "compact" policy will enable <a href="#compaction">log compaction</a>, which retains the latest value for each key. It is also possible to specify both policies in a comma-separated list (e.g. "delete,compact"). In this case, old segments will be discarded per the retention time and size configuration, while retained segments will be compacted.\\\'\'  configs.10:\'kafka2.DescribeConfigsResourceResult32a  name:flush.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"This setting allows specifying a time interval at which we will force an fsync of data written to the log. For example if this was set to 1000 we would fsync after 1000 ms had passed. In general we recommend you not set this and use replication for durability and allow the operating system\\\'s background flush capabilities as it is more efficient."\'  configs.11:\'kafka2.DescribeConfigsResourceResult32a  name:follower.replication.throttled.replicas  value:""  read_only:N  config_source:5  is_sensitive:N  config_type:7  documentation:"A list of replicas for which log replication should be throttled on the follower side. The list should describe a set of replicas in the form [PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard \\\'*\\\' can be used to throttle all replicas for this topic."\'  configs.12:\'kafka2.DescribeConfigsResourceResult32a  name:compression.lz4.level  value:9  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.lz4.level  value:9  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to <code>lz4</code>."\'  configs.13:\'kafka2.DescribeConfigsResourceResult32a  name:segment.bytes  value:1073741824  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:5"  config_type:3  documentation:"This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention."\'  configs.14:\'kafka2.DescribeConfigsResourceResult32a  name:retention.ms  value:604800000  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:\\\'This configuration controls the maximum time we will retain a log before we will discard old log segments to free up space if we are using the "delete" retention policy. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied. Additionally, retention.ms configuration operates independently of "segment.ms" and "segment.bytes" configurations. Moreover, it triggers the rolling of new segment if the retention.ms condition is satisfied.\\\'\'  configs.15:\'kafka2.DescribeConfigsResourceResult32a  name:compression.gzip.level  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.gzip.level  value:-1  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to <code>gzip</code>."\'  configs.16:\'kafka2.DescribeConfigsResourceResult32a  name:flush.messages  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.interval.messages  value:9223372036854775807  source:5"  config_type:5  documentation:\\\'This setting allows specifying an interval at which we will force an fsync of data written to the log. For example if this was set to 1 we would fsync after every message; if it were 5 we would fsync after every five messages. In general we recommend you not set this and use replication for durability and allow the operating system\\\\\\\'s background flush capabilities as it is more efficient. This setting can be overridden on a per-topic basis (see <a href="#topicconfigs">the per-topic configuration section</a>).\\\'\'  configs.17:\'kafka2.DescribeConfigsResourceResult32a  name:compression.zstd.level  value:3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.zstd.level  value:3  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to <code>zstd</code>."\'  configs.18:\'kafka2.DescribeConfigsResourceResult32a  name:message.format.version  value:3.0-IV1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.format.version  value:3.0-IV1  source:5"  config_type:2  documentation:"[DEPRECATED] Specify the message format version the broker will use to append messages to the logs. The value of this config is always assumed to be `3.0` if `inter.broker.protocol.version` is 3.0 or higher (the actual config value is ignored). Otherwise, the value should be a valid ApiVersion. Some examples are: 0.10.0, 1.1, 2.8, 3.0. By setting a particular message format version, the user is certifying that all the existing messages on disk are smaller or equal than the specified version. Setting this value incorrectly will cause consumers with older versions to break as they will receive messages with a format that they don\\\'t understand."\'  configs.19:\'kafka2.DescribeConfigsResourceResult32a  name:max.compaction.lag.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.max.compaction.lag.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum time a message will remain ineligible for compaction in the log. Only applicable for logs that are being compacted."\'  configs.20:\'kafka2.DescribeConfigsResourceResult32a  name:file.delete.delay.ms  value:60000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.delete.delay.ms  value:60000  source:5"  config_type:5  documentation:"The time to wait before deleting a file from the filesystem"\'  configs.21:\'kafka2.DescribeConfigsResourceResult32a  name:max.message.bytes  value:10485760  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:10485760  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:1048588  source:5"  config_type:3  documentation:"The largest record batch size allowed by Kafka (after compression if compression is enabled). If this is increased and there are consumers older than 0.10.2, the consumers\\\' fetch size must also be increased so that they can fetch record batches this large. In the latest message format version, records are always grouped into batches for efficiency. In previous message format versions, uncompressed records are not grouped into batches and this limit only applies to a single record in that case."\'  configs.22:\'kafka2.DescribeConfigsResourceResult32a  name:min.compaction.lag.ms  value:0  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.compaction.lag.ms  value:0  source:5"  config_type:5  documentation:"The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted."\'  configs.23:\'kafka2.DescribeConfigsResourceResult32a  name:message.timestamp.type  value:CreateTime  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.type  value:CreateTime  source:5"  config_type:2  documentation:"Define whether the timestamp in the message is message create time or log append time. The value should be either `CreateTime` or `LogAppendTime`"\'  configs.24:\'kafka2.DescribeConfigsResourceResult32a  name:local.retention.bytes  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.bytes  value:-2  source:5"  config_type:5  documentation:"The maximum size of local log segments that can grow for a partition before it deletes the old segments. Default value is -2, it represents `retention.bytes` value to be used. The effective value should always be less than or equal to `retention.bytes` value."\'  configs.25:\'kafka2.DescribeConfigsResourceResult32a  name:preallocate  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.preallocate  value:false  source:5"  config_type:1  documentation:"True if we should preallocate the file on disk when creating a new log segment."\'  configs.26:\'kafka2.DescribeConfigsResourceResult32a  name:min.cleanable.dirty.ratio  value:0.5  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.cleanable.ratio  value:0.5  source:5"  config_type:6  documentation:\\\'This configuration controls how frequently the log compactor will attempt to clean the log (assuming <a href="#compaction">log compaction</a> is enabled). By default we will avoid cleaning a log where more than 50% of the log has been compacted. This ratio bounds the maximum space wasted in the log by duplicates (at 50% at most 50% of the log could be duplicates). A higher ratio will mean fewer, more efficient cleanings but will mean more wasted space in the log. If the max.compaction.lag.ms or the min.compaction.lag.ms configurations are also specified, then the log compactor considers the log to be eligible for compaction as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) records for at least the min.compaction.lag.ms duration, or (ii) if the log has had dirty (uncompacted) records for at most the max.compaction.lag.ms period.\\\'\'  configs.27:\'kafka2.DescribeConfigsResourceResult32a  name:index.interval.bytes  value:4096  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.interval.bytes  value:4096  source:5"  config_type:3  documentation:"This setting controls how frequently Kafka adds an index entry to its offset index. The default setting ensures that we index a message roughly every 4096 bytes. More indexing allows reads to jump closer to the exact position in the log but makes the index larger. You probably don\\\'t need to change this."\'  configs.28:\'kafka2.DescribeConfigsResourceResult32a  name:unclean.leader.election.enable  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:unclean.leader.election.enable  value:false  source:5"  config_type:1  documentation:"Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss.<p>Note: In KRaft mode, when enabling this config dynamically, it needs to wait for the unclean leader electionthread to trigger election periodically (default is 5 minutes). Please run `kafka-leader-election.sh` with `unclean` option to trigger the unclean leader election immediately if needed.</p>"\'  configs.29:\'kafka2.DescribeConfigsResourceResult32a  name:retention.bytes  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.bytes  value:-1  source:5"  config_type:5  documentation:\\\'This configuration controls the maximum size a partition (which consists of log segments) can grow to before we will discard old log segments to free up space if we are using the "delete" retention policy. By default there is no size limit only a time limit. Since this limit is enforced at the partition level, multiply it by the number of partitions to compute the topic retention in bytes. Additionally, retention.bytes configuration operates independently of "segment.ms" and "segment.bytes" configurations. Moreover, it triggers the rolling of new segment if the retention.bytes is configured to zero.\\\'\'  configs.30:\'kafka2.DescribeConfigsResourceResult32a  name:delete.retention.ms  value:86400000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.delete.retention.ms  value:86400000  source:5"  config_type:5  documentation:\\\'The amount of time to retain delete tombstone markers for <a href="#compaction">log compacted</a> topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise delete tombstones may be collected before they complete their scan).\\\'\'  configs.31:\'kafka2.DescribeConfigsResourceResult32a  name:message.timestamp.after.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.after.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the message timestamp and the broker\\\'s timestamp. The message timestamp can be later than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if message.timestamp.type=LogAppendTime."\'  configs.32:\'kafka2.DescribeConfigsResourceResult32a  name:message.timestamp.before.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.before.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the broker\\\'s timestamp and the message timestamp. The message timestamp can be earlier than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if message.timestamp.type=LogAppendTime."\'  configs.33:\'kafka2.DescribeConfigsResourceResult32a  name:segment.ms  value:604800000  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"This configuration controls the period of time after which Kafka will force the log to roll even if the segment file isn\\\'t full to ensure that retention can delete or compact old data."\'  configs.34:\'kafka2.DescribeConfigsResourceResult32a  name:message.timestamp.difference.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.difference.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"[DEPRECATED] The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message. If message.timestamp.type=CreateTime, a message will be rejected if the difference in timestamp exceeds this threshold. This configuration is ignored if message.timestamp.type=LogAppendTime."\'  configs.35:\'kafka2.DescribeConfigsResourceResult32a  name:segment.index.bytes  value:10485760  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.size.max.bytes  value:10485760  source:5"  config_type:3  documentation:"This configuration controls the size of the index that maps offsets to file positions. We preallocate this index file and shrink it only after log rolls. You generally should not need to change this setting."\''
iframe:000000000366  ts_ns:1633440317780064  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:34  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000387  ts_ns:1633440322272364  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:34  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000372  ts_ns:1633440320308780  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:35  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000391  ts_ns:1633440323489753  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:35  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000373  ts_ns:1633440320361184  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:36  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000394  ts_ns:1633440324619820  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:36  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000388  ts_ns:1633440322482080  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:37  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000396  ts_ns:1633440325773318  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:37  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000392  ts_ns:1633440323607385  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:38  client_id:redpanda-console  topics.0:"kafka2.DescribableLogDirTopic35q  topic:ap1  partitions.0:2  partitions.1:1  partitions.2:0"
iframe:000000000398  ts_ns:1633440327713094  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:38  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000393  ts_ns:1633440323692748  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:39  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-1"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-1"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-1"'  timeout_ms:0
iframe:000000000399  ts_ns:1633440328975840  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:39  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:1  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000395  ts_ns:1633440324891372  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:40  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-2"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-2"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-2"'  timeout_ms:0
iframe:000000000401  ts_ns:1633440330068352  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:40  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000397  ts_ns:1633440326001830  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:41  client_id:redpanda-console
iframe:000000000402  ts_ns:1633440331941113  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:41  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000406  ts_ns:1633449878172441  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:42  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000408  ts_ns:1633449879442540  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:42  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000409  ts_ns:1633449879732550  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:43  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000411  ts_ns:1633449881374931  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:43  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000413  ts_ns:1633449881722304  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:44  client_id:redpanda-console
iframe:000000000422  ts_ns:1633449885002483  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:44  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000415  ts_ns:1633449881762816  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:45  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000425  ts_ns:1633449886501856  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:45  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000417  ts_ns:1633449882305568  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:46  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000429  ts_ns:1633449887062073  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:46  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000418  ts_ns:1633449882348902  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:47  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000432  ts_ns:1633449888151660  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:47  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000421  ts_ns:1633449884774310  c_port:55134 kafka2.DescribeConfigsRequest  request_api_version:3  correlation_id:48  client_id:redpanda-console  resources.0:"kafka2.DescribeConfigsResource32q  resource_type:4  resource_name:4"  include_synonyms:Y  include_documentation:Y
iframe:000000000498  ts_ns:1633449895154528  c_port:55134 kafka2.DescribeConfigsResponse  request_api_version:3  correlation_id:48  throttle_time_ms:0  results.0:'kafka2.DescribeConfigsResult32a  error_code:0  error_message:""  resource_type:4  resource_name:4  configs.0:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.min.compaction.lag.ms  value:0  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.compaction.lag.ms  value:0  source:5"  config_type:5  documentation:"The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted."\'  configs.1:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.num.partitions  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.num.partitions  value:50  source:5"  config_type:3  documentation:"The number of partitions for the offset commit topic (should not change after deployment)."\'  configs.2:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.refresh.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.refresh.ms  value:3600000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the broker to wait between refreshing its JWKS (JSON Web Key Set) cache that contains the keys to verify the signature of the JWT."\'  configs.3:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.listener.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Listener name of the local broker to which it should get connected if needed by RemoteLogMetadataManager implementation."\'  configs.4:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.interval.messages  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.interval.messages  value:9223372036854775807  source:5"  config_type:5  documentation:"The number of messages accumulated on a log partition before messages are flushed to disk."\'  configs.5:\'kafka2.DescribeConfigsResourceResult32a  name:controller.socket.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.socket.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The socket timeout for controller-to-broker channels."\'  configs.6:\'kafka2.DescribeConfigsResourceResult32a  name:principal.builder.class  value:org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:principal.builder.class  value:org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder  source:5"  config_type:8  documentation:"The fully qualified name of a class that implements the KafkaPrincipalBuilder interface, which is used to build the KafkaPrincipal object used during authorization. If no principal builder is defined, the default behavior depends on the security protocol in use. For SSL authentication,  the principal will be derived using the rules defined by <code>ssl.principal.mapping.rules</code> applied on the distinguished name from the client certificate if one is provided; otherwise, if client authentication is not required, the principal name will be ANONYMOUS. For SASL authentication, the principal will be derived using the rules defined by <code>sasl.kerberos.principal.to.local.rules</code> if GSSAPI is in use, and the SASL authentication ID for other mechanisms. For PLAINTEXT, the principal will be ANONYMOUS."\'  configs.7:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.interval.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used"\'  configs.8:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.request.timeout.ms  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.request.timeout.ms  value:2000  source:5"  config_type:3  documentation:"The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."\'  configs.9:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.expected.audience  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:\\\'The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences. The JWT will be inspected for the standard OAuth "aud" claim and if this value is set, the broker will match the value from JWT\\\\\\\'s "aud" claim  to see if there is an exact match. If there is no match, the broker will reject the JWT and authentication will fail.\\\'\'  configs.10:\'kafka2.DescribeConfigsResourceResult32a  name:min.insync.replicas  value:1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:min.insync.replicas  value:1  source:5"  config_type:3  documentation:\\\'When a producer sets acks to "all" (or "-1"), <code>min.insync.replicas</code> specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either <code>NotEnoughReplicas</code> or <code>NotEnoughReplicasAfterAppend</code>).<br>When used together, <code>min.insync.replicas</code> and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set <code>min.insync.replicas</code> to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.\\\'\'  configs.11:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.thread.pool.size  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.thread.pool.size  value:10  source:5"  config_type:3  documentation:"Deprecated. Size of the thread pool used in scheduling tasks to copy segments, fetch remote log indexes and clean up remote log segments."\'  configs.12:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.session.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.session.timeout.ms  value:60000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for registered consumers."\'  configs.13:\'kafka2.DescribeConfigsResourceResult32a  name:num.recovery.threads.per.data.dir  value:1  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.recovery.threads.per.data.dir  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.recovery.threads.per.data.dir  value:1  source:5"  config_type:3  documentation:"The number of threads per data directory to be used for log recovery at startup and flushing at shutdown"\'  configs.14:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.type  value:JKS  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.keystore.type  value:JKS  source:5"  config_type:2  documentation:"The file format of the key store file. This is optional for client. The values currently supported by the default `ssl.engine.factory.class` are [JKS, PKCS12, PEM]."\'  configs.15:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.protocol  value:TLSv1.2  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.protocol  value:TLSv1.2  source:5"  config_type:2  documentation:"Specifies the protocol to be used in ZooKeeper TLS negotiation. An explicit value overrides any value set via the same-named <code>zookeeper.ssl.protocol</code> system property."\'  configs.16:\'kafka2.DescribeConfigsResourceResult32a  name:super.users  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:super.users  source:4"  config_type:0\'  configs.17:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.bootstrap.servers  value:""  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:controller.quorum.bootstrap.servers  value:""  source:5\\\'  config_type:7  documentation:"List of endpoints to use for bootstrapping the cluster metadata. The endpoints are specified in comma-separated list of <code>{host}:{port}</code> entries. For example: <code>localhost:9092,localhost:9093,localhost:9094</code>."\'  configs.18:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.mechanism.inter.broker.protocol  value:GSSAPI  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.mechanism.inter.broker.protocol  value:GSSAPI  source:5"  config_type:2  documentation:"SASL mechanism used for inter-broker communication. Default is GSSAPI."\'  configs.19:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.record.lock.duration.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.record.lock.duration.ms  value:30000  source:5"  config_type:3  documentation:"The record acquisition lock duration in milliseconds for share groups."\'  configs.20:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.segment.bytes  value:1073741824  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.segment.bytes  value:1073741824  source:5"  config_type:3  documentation:"The maximum size of a single metadata log file."\'  configs.21:\'kafka2.DescribeConfigsResourceResult32a  name:fetch.purgatory.purge.interval.requests  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:fetch.purgatory.purge.interval.requests  value:1000  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the fetch request purgatory"\'  configs.22:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.endpoint.identification.algorithm  value:https  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.endpoint.identification.algorithm  value:https  source:5"  config_type:2  documentation:"The endpoint identification algorithm to validate server hostname using server certificate. "\'  configs.23:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.location  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Keystore location when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.location</code> system property (note the camelCase)."\'  configs.24:\'kafka2.DescribeConfigsResourceResult32a  name:replica.socket.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.socket.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The socket timeout for network requests. Its value should be at least replica.fetch.wait.max.ms"\'  configs.25:\'kafka2.DescribeConfigsResourceResult32a  name:message.max.bytes  value:10485760  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:10485760  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:message.max.bytes  value:1048588  source:5"  config_type:3  documentation:"The largest record batch size allowed by Kafka (after compression if compression is enabled). If this is increased and there are consumers older than 0.10.2, the consumers\\\' fetch size must also be increased so that they can fetch record batches this large. In the latest message format version, records are always grouped into batches for efficiency. In previous message format versions, uncompressed records are not grouped into batches and this limit only applies to a single record in that case.This can be set per topic with the topic level <code>max.message.bytes</code> config."\'  configs.26:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.max.bytes.per.second  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.max.bytes.per.second  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum number of bytes that can be fetched from remote storage to local storage per second. This is a global limit for all the partitions that are being fetched from remote storage to local storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be fetched per second."\'  configs.27:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The timeout to detect client failures when using the share group protocol."\'  configs.28:\'kafka2.DescribeConfigsResourceResult32a  name:max.connection.creation.rate  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connection.creation.rate  value:2147483647  source:5"  config_type:3  documentation:"The maximum connection creation rate we allow in the broker at any time. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, <code>listener.name.internal.max.connection.creation.rate</code>.Broker-wide connection rate limit should be configured based on broker capacity while listener limits should be configured based on application requirements. New connections will be throttled if either the listener or the broker limit is reached, with the exception of inter-broker listener. Connections on the inter-broker listener will be throttled only when the listener-level rate limit is reached."\'  configs.29:\'kafka2.DescribeConfigsResourceResult32a  name:connections.max.reauth.ms  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connections.max.reauth.ms  value:0  source:5"  config_type:5  documentation:"When explicitly set to a positive number (the default is 0, not a positive number), a session lifetime that will not exceed the configured value will be communicated to v2.2.0 or later clients when they authenticate. The broker will disconnect any such connection that is not re-authenticated within the session lifetime and that is then subsequently used for any purpose other than re-authentication. Configuration names can optionally be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.oauthbearer.connections.max.reauth.ms=3600000"\'  configs.30:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for remote copy quota management. The default value is 1 second."\'  configs.31:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.offset.checkpoint.interval.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.offset.checkpoint.interval.ms  value:60000  source:5"  config_type:3  documentation:"The frequency with which we update the persistent record of the last flush which acts as the log recovery point."\'  configs.32:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.clientCnxnSocket  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Typically set to <code>org.apache.zookeeper.ClientCnxnSocketNetty</code> when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the same-named <code>zookeeper.clientCnxnSocket</code> system property."\'  configs.33:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.client.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.client.enable  value:false  source:5"  config_type:1  documentation:"Set client to use TLS when connecting to ZooKeeper. An explicit value overrides any value set via the <code>zookeeper.client.secure</code> system property (note the different name). Defaults to false if neither is set; when true, <code>zookeeper.clientCnxnSocket</code> must be set (typically to <code>org.apache.zookeeper.ClientCnxnSocketNetty</code>); other values to set may include <code>zookeeper.ssl.cipher.suites</code>, <code>zookeeper.ssl.crl.enable</code>, <code>zookeeper.ssl.enabled.protocols</code>, <code>zookeeper.ssl.endpoint.identification.algorithm</code>, <code>zookeeper.ssl.keystore.location</code>, <code>zookeeper.ssl.keystore.password</code>, <code>zookeeper.ssl.keystore.type</code>, <code>zookeeper.ssl.ocsp.enable</code>, <code>zookeeper.ssl.protocol</code>, <code>zookeeper.ssl.truststore.location</code>, <code>zookeeper.ssl.truststore.password</code>, <code>zookeeper.ssl.truststore.type</code>"\'  configs.34:\'kafka2.DescribeConfigsResourceResult32a  name:quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for client quotas"\'  configs.35:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.clock.skew.seconds  value:30  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.clock.skew.seconds  value:30  source:5"  config_type:3  documentation:"The (optional) value in seconds to allow for differences between the time of the OAuth/OIDC identity provider and the broker."\'  configs.36:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.min.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.min.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for registered consumers."\'  configs.37:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.connect  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Specifies the ZooKeeper connection string in the form <code>hostname:port</code> where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form <code>hostname1:port1,hostname2:port2,hostname3:port3</code>.\\\\nThe server can also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. For example to give a chroot path of <code>/chroot/path</code> you would give the connection string as <code>hostname1:port1,hostname2:port2,hostname3:port3/chroot/path</code>."\'  configs.38:\'kafka2.DescribeConfigsResourceResult32a  name:authorizer.class.name  value:org.apache.kafka.metadata.authorizer.StandardAuthorizer  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:authorizer.class.name  value:org.apache.kafka.metadata.authorizer.StandardAuthorizer  source:4"  synonyms.1:\\\'kafka2.DescribeConfigsSynonym32a  name:authorizer.class.name  value:""  source:5\\\'  config_type:2  documentation:"The fully qualified name of a class that implements <code>org.apache.kafka.server.authorizer.Authorizer</code> interface, which is used by the broker for authorization."\'  configs.39:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.secret  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"The secret used for encoding dynamically configured passwords for this broker."\'  configs.40:\'kafka2.DescribeConfigsResourceResult32a  name:num.replica.fetchers  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.replica.fetchers  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.replica.fetchers  value:1  source:5"  config_type:3  documentation:"Number of fetcher threads used to replicate records from each source broker. The total number of fetchers on each broker is bound by <code>num.replica.fetchers</code> multiplied by the number of brokers in the cluster.Increasing this value can increase the degree of I/O parallelism in the follower and leader broker at the cost of higher CPU and memory utilization."\'  configs.41:\'kafka2.DescribeConfigsResourceResult32a  name:alter.log.dirs.replication.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:alter.log.dirs.replication.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for alter log dirs replication quotas"\'  configs.42:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.url  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'The OAuth/OIDC provider URL from which the provider\\\\\\\'s <a href="https://datatracker.ietf.org/doc/html/rfc7517#section-5">JWKS (JSON Web Key Set)</a> can be retrieved. The URL can be HTTP(S)-based or file-based. If the URL is HTTP(S)-based, the JWKS data will be retrieved from the OAuth/OIDC provider via the configured URL on broker startup. All then-current keys will be cached on the broker for incoming requests. If an authentication request is received for a JWT that includes a "kid" header claim value that isn\\\\\\\'t yet in the cache, the JWKS endpoint will be queried again on demand. However, the broker polls the URL every sasl.oauthbearer.jwks.endpoint.refresh.ms milliseconds to refresh the cache with any forthcoming keys before any JWT requests that include them are received. If the URL is file-based, the broker will load the JWKS file from a configured location on startup. In the event that the JWT includes a "kid" header value that isn\\\\\\\'t in the JWKS file, the broker will reject the JWT and authentication will fail.\\\'\'  configs.43:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.custom.metadata.max.bytes  value:128  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.custom.metadata.max.bytes  value:128  source:5"  config_type:3  documentation:"The maximum size of custom metadata in bytes that the broker should accept from a remote storage plugin. If custom  metadata exceeds this limit, the updated segment metadata will not be stored, the copied data will be attempted to delete, and the remote copying task for this topic-partition will stop with an error."\'  configs.44:\'kafka2.DescribeConfigsResourceResult32a  name:auto.include.jmx.reporter  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.include.jmx.reporter  value:true  source:5"  config_type:1  documentation:"Deprecated. Whether to automatically include JmxReporter even if it\\\'s not listed in <code>metric.reporters</code>. This configuration will be removed in Kafka 4.0, users should instead include <code>org.apache.kafka.common.metrics.JmxReporter</code> in <code>metric.reporters</code> in order to enable the JmxReporter."\'  configs.45:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.jitter.hours  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.roll.jitter.hours  value:0  source:5"  config_type:3  documentation:"The maximum jitter to subtract from logRollTimeMillis (in hours), secondary to log.roll.jitter.ms property"\'  configs.46:\'kafka2.DescribeConfigsResourceResult32a  name:telemetry.max.bytes  value:1048576  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:telemetry.max.bytes  value:1048576  source:5"  config_type:3  documentation:"The maximum size (after compression if compression is used) of telemetry metrics pushed from a client to the broker. The default value is 1048576 (1 MB)."\'  configs.47:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.old.secret  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"The old secret that was used for encoding dynamically configured passwords. This is required only when the secret is updated. If specified, all dynamically encoded passwords are decoded using this old secret and re-encoded using password.encoder.secret when broker starts up."\'  configs.48:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.delete.retention.ms  value:86400000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.delete.retention.ms  value:86400000  source:5"  config_type:5  documentation:"The amount of time to retain tombstone message markers for log compacted topics. This setting also gives a bound on the time in which a consumer must complete a read if they begin from offset 0 to ensure that they get a valid snapshot of the final stage (otherwise  tombstones messages may be collected before a consumer completes their scan)."\'  configs.49:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.retry.backoff.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.retry.backoff.ms  value:100  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the initial wait between login attempts to the external authentication provider. Login uses an exponential backoff algorithm with an initial wait based on the sasl.login.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.login.retry.backoff.max.ms setting. Currently applies only to OAUTHBEARER."\'  configs.50:\'kafka2.DescribeConfigsResourceResult32a  name:queued.max.requests  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:queued.max.requests  value:500  source:5"  config_type:3  documentation:"The number of queued requests allowed for data-plane, before blocking the network threads"\'  configs.51:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.threads  value:1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.threads  value:1  source:5"  config_type:3  documentation:"The number of background threads to use for log cleaning"\'  configs.52:"kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.service.name  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:\\"The Kerberos principal name that Kafka runs as. This can be defined either in Kafka\'s JAAS config or in Kafka\'s config.\\""  configs.53:\'kafka2.DescribeConfigsResourceResult32a  name:socket.request.max.bytes  value:104857600  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.request.max.bytes  value:104857600  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.request.max.bytes  value:104857600  source:5"  config_type:3  documentation:"The maximum number of bytes in a socket request"\'  configs.54:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.size  value:2147483647  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.size  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of consumers that a single consumer group can accommodate. This value will only impact the new consumer coordinator. To configure the classic consumer coordinator check group.max.size instead."\'  configs.55:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.assignors  value:org.apache.kafka.coordinator.group.assignor.UniformAssignor,org.apache.kafka.coordinator.group.assignor.RangeAssignor  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.assignors  value:org.apache.kafka.coordinator.group.assignor.UniformAssignor,org.apache.kafka.coordinator.group.assignor.RangeAssignor  source:5"  config_type:7  documentation:"The server side assignors as a list of full class names. The first one in the list is considered as the default assignor to be used in the case where the consumer does not specify an assignor."\'  configs.56:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.system.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.storage.system.enable  value:false  source:5"  config_type:1  documentation:"Whether to enable tiered storage functionality in a broker or not. Valid values are `true` or `false` and the default value is false. When it is true broker starts all the services required for the tiered storage functionality."\'  configs.57:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.type  value:CreateTime  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.type  value:CreateTime  source:5"  config_type:2  documentation:"Define whether the timestamp in the message is message create time or log append time. The value should be either <code>CreateTime</code> or <code>LogAppendTime</code>."\'  configs.58:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.type  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Keystore type when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.type</code> system property (note the camelCase). The default value of <code>null</code> means the type will be auto-detected based on the filename extension of the keystore."\'  configs.59:\'kafka2.DescribeConfigsResourceResult32a  name:connections.max.idle.ms  value:600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connections.max.idle.ms  value:600000  source:5"  config_type:5  documentation:"Idle connections timeout: the server socket processor threads close the connections that idle more than this"\'  configs.60:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.set.acl  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.set.acl  value:false  source:5"  config_type:1  documentation:"Set client to use secure ACLs"\'  configs.61:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.expiry.time.ms  value:86400000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.expiry.time.ms  value:86400000  source:5"  config_type:5  documentation:"The token validity time in milliseconds before the token needs to be renewed. Default value 1 day."\'  configs.62:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connections  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of connections we allow in the broker at any time. This limit is applied in addition to any per-ip limits configured using max.connections.per.ip. Listener-level limits may also be configured by prefixing the config name with the listener prefix, for example, <code>listener.name.internal.max.connections.per.ip</code>. Broker-wide limit should be configured based on broker capacity while listener limits should be configured based on application requirements. New connections are blocked if either the listener or broker limit is reached. Connections on the inter-broker listener are permitted even if broker-wide limit is reached. The least recently used connection on another listener will be closed in this case."\'  configs.63:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.num.partitions  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.num.partitions  value:50  source:5"  config_type:3  documentation:"The number of partitions for the transaction topic (should not change after deployment)."\'  configs.64:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.election.timeout.ms  value:20000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.timeout.ms  value:20000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.timeout.ms  value:1000  source:5"  config_type:3  documentation:"Maximum time in milliseconds to wait without being able to fetch from the leader before triggering a new election"\'  configs.65:\'kafka2.DescribeConfigsResourceResult32a  name:listener.security.protocol.map  value:CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:listener.security.protocol.map  value:CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:listener.security.protocol.map  value:SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT  source:5"  config_type:2  documentation:"Map between listener names and security protocols. This must be defined for the same security protocol to be usable in more than one port or IP. For example, internal and external traffic can be separated even if SSL is required for both. Concretely, the user could define listeners with names INTERNAL and EXTERNAL and this property as: <code>INTERNAL:SSL,EXTERNAL:SSL</code>. As shown, key and value are separated by a colon and map entries are separated by commas. Each listener name should only appear once in the map. Different security (SSL and SASL) settings can be configured for each listener by adding a normalised prefix (the listener name is lowercased) to the config name. For example, to set a different keystore for the INTERNAL listener, a config with name <code>listener.name.internal.ssl.keystore.location</code> would be set. If the config for the listener name is not set, the config will fallback to the generic config (i.e. <code>ssl.keystore.location</code>). Note that in KRaft a default mapping from the listener names defined by <code>controller.listener.names</code> to PLAINTEXT is assumed if no explicit mapping is provided and no other security protocol is in use."\'  configs.66:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.hours  value:168  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.hours  value:168  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.retention.hours  value:168  source:5"  config_type:3  documentation:"The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property"\'  configs.67:\'kafka2.DescribeConfigsResourceResult32a  name:client.quota.callback.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a class that implements the ClientQuotaCallback interface, which is used to determine quota limits applied to client requests. By default, the &lt;user&gt; and &lt;client-id&gt; quotas that are stored in ZooKeeper are applied. For any given request, the most specific quota that matches the user principal of the session and the client-id of the request is applied."\'  configs.68:\'kafka2.DescribeConfigsResourceResult32a  name:audit.log.enabled  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:audit.log.enabled  source:4"  config_type:0\'  configs.69:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.impl.prefix  value:rsm.config.  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.storage.manager.impl.prefix  value:rsm.config.  source:5"  config_type:2  documentation:"Prefix used for properties to be passed to RemoteStorageManager implementation. For example this value can be `rsm.config.`."\'  configs.70:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.provider  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The name of the security provider used for SSL connections. Default value is the default security provider of the JVM."\'  configs.71:\'kafka2.DescribeConfigsResourceResult32a  name:delete.records.purgatory.purge.interval.requests  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delete.records.purgatory.purge.interval.requests  value:1  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the delete records request purgatory"\'  configs.72:\'kafka2.DescribeConfigsResourceResult32a  name:producer.id.expiration.ms  value:86400000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:producer.id.expiration.ms  value:86400000  source:5"  config_type:3  documentation:"The time in ms that a topic partition leader will wait before expiring producer IDs. Producer IDs will not expire while a transaction associated to them is still ongoing. Note that producer IDs may expire sooner if the last write from the producer ID is deleted due to the topic\\\'s retention settings. Setting this value the same or higher than <code>delivery.timeout.ms</code> can help prevent expiration during retries and protect against message duplication, but the default should be reasonable for most use cases."\'  configs.73:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum time before a new log segment is rolled out (in milliseconds). If not set, the value in log.roll.hours is used"\'  configs.74:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.cipher.suites  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:ssl.cipher.suites  value:""  source:5\\\'  config_type:7  documentation:"A list of cipher suites. This is a named combination of authentication, encryption, MAC and key exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL network protocol. By default all the available cipher suites are supported."\'  configs.75:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.retry.backoff.ms  value:20  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.retry.backoff.ms  value:20  source:5"  config_type:3  documentation:"The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios. This value is the initial backoff value and will increase exponentially for each failed request, up to the <code>retry.backoff.max.ms</code> value."\'  configs.76:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.max.bytes.per.second  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.max.bytes.per.second  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum number of bytes that can be copied from local storage to remote storage per second. This is a global limit for all the partitions that are being copied from local storage to remote storage. The default value is Long.MAX_VALUE, which means there is no limit on the number of bytes that can be copied per second."\'  configs.77:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.keystore.password  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Keystore password when using a client-side certificate with TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.keyStore.password</code> system property (note the camelCase). Note that ZooKeeper does not support a key password different from the keystore password, so be sure to set the key password in the keystore to be identical to the keystore password; otherwise the connection attempt to Zookeeper will fail."\'  configs.78:\'kafka2.DescribeConfigsResourceResult32a  name:broker.session.timeout.ms  value:9000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.session.timeout.ms  value:9000  source:5"  config_type:3  documentation:"The length of time in milliseconds that a broker lease lasts if no heartbeats are made. Used when running in KRaft mode."\'  configs.79:\'kafka2.DescribeConfigsResourceResult32a  name:security.inter.broker.protocol  value:PLAINTEXT  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:security.inter.broker.protocol  value:PLAINTEXT  source:5"  config_type:2  documentation:"Security protocol used to communicate between brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. It is an error to set this and inter.broker.listener.name properties at the same time."\'  configs.80:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The heartbeat interval given to the members of a share group."\'  configs.81:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.secret.key  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Secret key to generate and verify delegation tokens. The same key must be configured across all the brokers.  If using Kafka with KRaft, the key must also be set across all controllers.  If the key is not set or set to empty string, brokers will disable the delegation token support."\'  configs.82:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for remote fetch quota management. The default value is 11, which means there are 10 whole windows + 1 current window."\'  configs.83:\'kafka2.DescribeConfigsResourceResult32a  name:remote.fetch.max.wait.ms  value:500  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.fetch.max.wait.ms  value:500  source:5"  config_type:3  documentation:"The maximum amount of time the server will wait before answering the remote fetch request"\'  configs.84:\'kafka2.DescribeConfigsResourceResult32a  name:node.id  value:4  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:node.id  value:4  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:node.id  value:-1  source:5"  config_type:3  documentation:"The node ID associated with the roles this process is playing when <code>process.roles</code> is non-empty. This is required configuration when running in KRaft mode."\'  configs.85:\'kafka2.DescribeConfigsResourceResult32a  name:replica.high.watermark.checkpoint.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.high.watermark.checkpoint.interval.ms  value:5000  source:5"  config_type:5  documentation:"The frequency with which the high watermark is saved out to disk"\'  configs.86:\'kafka2.DescribeConfigsResourceResult32a  name:replication.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replication.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for replication quotas"\'  configs.87:\'kafka2.DescribeConfigsResourceResult32a  name:eligible.leader.replicas.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:eligible.leader.replicas.enable  value:false  source:5"  config_type:1  documentation:"Enable the Eligible leader replicas"\'  configs.88:\'kafka2.DescribeConfigsResourceResult32a  name:log.local.retention.ms  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.ms  value:-2  source:5"  config_type:5  documentation:"The number of milliseconds to keep the local log segments before it gets eligible for deletion. Default value is -2, it represents `log.retention.ms` value is to be used. The effective value should always be less than or equal to `log.retention.ms` value."\'  configs.89:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.reader.threads  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.reader.threads  value:10  source:5"  config_type:3  documentation:"Size of the thread pool that is allocated for handling remote log reads."\'  configs.90:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.ticket.renew.window.factor  value:0.8  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.ticket.renew.window.factor  value:0.8  source:5"  config_type:6  documentation:"Login thread will sleep until the specified window factor of time from last refresh to ticket\\\'s expiry has been reached, at which time it will try to renew the ticket."\'  configs.91:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.threads  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.threads  value:1  source:5"  config_type:3  documentation:"The number of threads used by the group coordinator."\'  configs.92:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.connection.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The max time that the client waits to establish a connection to ZooKeeper. If not set, the value in zookeeper.session.timeout.ms is used"\'  configs.93:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.recording.level  value:INFO  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.recording.level  value:INFO  source:5"  config_type:2  documentation:"The highest recording level for metrics."\'  configs.94:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.cipher.algorithm  value:AES/CBC/PKCS5Padding  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.cipher.algorithm  value:AES/CBC/PKCS5Padding  source:5"  config_type:2  documentation:"The Cipher algorithm used for encoding dynamically configured passwords."\'  configs.95:\'kafka2.DescribeConfigsResourceResult32a  name:log.dir.failure.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dir.failure.timeout.ms  value:30000  source:5"  config_type:5  documentation:"If the broker is unable to successfully communicate to the controller that some log directory has failed for longer than this time, the broker will fail and shut down."\'  configs.96:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.partition.verification.enable  value:true  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.partition.verification.enable  value:true  source:5"  config_type:1  documentation:"Enable verification that checks that the partition has been added to the transaction before writing transactional records to the partition"\'  configs.97:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The minimum heartbeat interval for share group members."\'  configs.98:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.principal.mapping.rules  value:DEFAULT  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.principal.mapping.rules  value:DEFAULT  source:5"  config_type:2  documentation:\\\'A list of rules for mapping from distinguished name from the client certificate to short name. The rules are evaluated in order and the first rule that matches a principal name is used to map it to a short name. Any later rules in the list are ignored. By default, distinguished name of the X.500 certificate will be the principal. For more details on the format please see <a href="#security_authz"> security authorization and acls</a>. Note that this configuration is ignored if an extension of KafkaPrincipalBuilder is provided by the <code>principal.builder.class</code> configuration.\\\'\'  configs.99:\'kafka2.DescribeConfigsResourceResult32a  name:replica.selector.class  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The fully qualified class name that implements ReplicaSelector. This is used by the broker to find the preferred read replica. By default, we use an implementation that returns the leader."\'  configs.100:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.fetch.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.fetch.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for remote fetch quota management. The default value is 1 second."\'  configs.101:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections.per.ip  value:2147483647  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.connections.per.ip  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of connections we allow from each ip address. This can be set to 0 if there are overrides configured using max.connections.per.ip.overrides property. New connections from the ip address are dropped if the limit is reached."\'  configs.102:\'kafka2.DescribeConfigsResourceResult32a  name:background.threads  value:10  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:background.threads  value:10  source:5"  config_type:3  documentation:"The number of threads to use for various background processing tasks"\'  configs.103:\'kafka2.DescribeConfigsResourceResult32a  name:request.timeout.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:request.timeout.ms  value:30000  source:5"  config_type:3  documentation:"The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted."\'  configs.104:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.format.version  value:3.0-IV1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.format.version  value:3.0-IV1  source:5"  config_type:2  documentation:"Specify the message format version the broker will use to append messages to the logs. The value should be a valid MetadataVersion. Some examples are: 0.8.2, 0.9.0.0, 0.10.0, check MetadataVersion for more details. By setting a particular message format version, the user is certifying that all the existing messages on disk are smaller or equal than the specified version. Setting this value incorrectly will cause consumers with older versions to break as they will receive messages with a format that they don\\\'t understand."\'  configs.105:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a class that implements the Login interface. For brokers, login config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.class=com.example.CustomScramLogin"\'  configs.106:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.index.file.cache.total.size.bytes  value:1073741824  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.index.file.cache.total.size.bytes  value:1073741824  source:5"  config_type:5  documentation:"The total size of the space allocated to store index files fetched from remote storage in the local storage."\'  configs.107:\'kafka2.DescribeConfigsResourceResult32a  name:log.dir  value:/tmp/kafka-logs  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dir  value:/tmp/kafka-logs  source:5"  config_type:2  documentation:"The directory in which the log data is kept (supplemental for log.dirs property)"\'  configs.108:\'kafka2.DescribeConfigsResourceResult32a  name:log.segment.bytes  value:1073741824  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.segment.bytes  value:1073741824  source:5"  config_type:3  documentation:"The maximum size of a single log file"\'  configs.109:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.response.max.bytes  value:10485760  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.response.max.bytes  value:10485760  source:5"  config_type:3  documentation:"Maximum bytes expected for the entire fetch response. Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum. The maximum record batch size accepted by the broker is defined via <code>message.max.bytes</code> (broker config) or <code>max.message.bytes</code> (topic config)."\'  configs.110:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The heartbeat interval given to the members of a consumer group."\'  configs.111:\'kafka2.DescribeConfigsResourceResult32a  name:group.max.session.timeout.ms  value:1800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.max.session.timeout.ms  value:1800000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures."\'  configs.112:\'kafka2.DescribeConfigsResourceResult32a  name:controller.listener.names  value:CONTROLLER  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.listener.names  value:CONTROLLER  source:4"  config_type:2  documentation:"A comma-separated list of the names of the listeners used by the controller. This is required if running in KRaft mode. When communicating with the controller quorum, the broker will always use the first listener in this list.\\\\n Note: The ZooKeeper-based controller should not set this configuration."\'  configs.113:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.after.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.after.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the message timestamp and the broker\\\'s timestamp. The message timestamp can be later than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If log.message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime."\'  configs.114:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.append.linger.ms  value:25  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.append.linger.ms  value:25  source:5"  config_type:3  documentation:"The duration in milliseconds that the leader will wait for writes to accumulate before flushing them to disk."\'  configs.115:\'kafka2.DescribeConfigsResourceResult32a  name:log.segment.delete.delay.ms  value:60000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.segment.delete.delay.ms  value:60000  source:5"  config_type:5  documentation:"The amount of time to wait before deleting a file from the filesystem. If the value is 0 and there is no file to delete, the system will wait 1 millisecond. Low value will cause busy waiting"\'  configs.116:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.minutes  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The number of minutes to keep a log file before deleting it (in minutes), secondary to log.retention.ms property. If not set, the value in log.retention.hours is used"\'  configs.117:\'kafka2.DescribeConfigsResourceResult32a  name:log.dirs  value:/mnt/data-1/dev.ak-8,/mnt/data-2/dev.ak-8  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.dirs  value:/mnt/data-1/dev.ak-8,/mnt/data-2/dev.ak-8  source:4"  config_type:2  documentation:"A comma-separated list of the directories where the log data is stored. If not set, the value in log.dir is used."\'  configs.118:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.enable  value:true  source:5"  config_type:1  documentation:"Enable controlled shutdown of the server."\'  configs.119:\'kafka2.DescribeConfigsResourceResult32a  name:early.start.listeners  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"A comma-separated list of listener names which may be started before the authorizer has finished initialization. This is useful when the authorizer is dependent on the cluster itself for bootstrapping, as is the case for the StandardAuthorizer (which stores ACLs in the metadata log.) By default, all listeners included in controller.listener.names will also be early start listeners. A listener should not appear in this list if it accepts external traffic."\'  configs.120:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.before.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.before.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"This configuration sets the allowable timestamp difference between the broker\\\'s timestamp and the message timestamp. The message timestamp can be earlier than or equal to the broker\\\'s timestamp, with the maximum allowable difference determined by the value set in this configuration. If log.message.timestamp.type=CreateTime, the message will be rejected if the difference in timestamps exceeds this specified threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime."\'  configs.121:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copier.thread.pool.size  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copier.thread.pool.size  value:-1  source:5"  config_type:3  documentation:"Size of the thread pool used in scheduling tasks to copy segments. The default value of -1 means that this will be set to the configured value of remote.log.manager.thread.pool.size, if available; otherwise, it defaults to 10."\'  configs.122:\'kafka2.DescribeConfigsResourceResult32a  name:socket.connection.setup.timeout.max.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.connection.setup.timeout.max.ms  value:30000  source:5"  config_type:5  documentation:"The maximum amount of time the client will wait for the socket connection to be established. The connection setup timeout will increase exponentially for each consecutive connection failure up to this maximum. To avoid connection storms, a randomization factor of 0.2 will be applied to the timeout resulting in a random range between 20% below and 20% above the computed value."\'  configs.123:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.timestamp.difference.max.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.timestamp.difference.max.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"[DEPRECATED] The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message. If log.message.timestamp.type=CreateTime, a message will be rejected if the difference in timestamp exceeds this threshold. This configuration is ignored if log.message.timestamp.type=LogAppendTime.The maximum timestamp difference allowed should be no greater than log.retention.ms to avoid unnecessarily frequent log rolling."\'  configs.124:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.scope.claim.name  value:scope  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.scope.claim.name  value:scope  source:5"  config_type:2  documentation:\\\'The OAuth claim for the scope is often named "scope", but this (optional) setting can provide a different name to use for the scope included in the JWT payload\\\\\\\'s claims if the OAuth/OIDC provider uses a different name for that claim.\\\'\'  configs.125:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.key.length  value:128  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.key.length  value:128  source:5"  config_type:3  documentation:"The key length used for encoding dynamically configured passwords."\'  configs.126:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.min.period.seconds  value:60  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.min.period.seconds  value:60  source:5"  config_type:4  documentation:"The desired minimum time for the login refresh thread to wait before refreshing a credential, in seconds. Legal values are between 0 and 900 (15 minutes); a default value of 60 (1 minute) is used if no value is specified.  This value and  sasl.login.refresh.buffer.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER."\'  configs.127:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.expected.issuer  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'The (optional) setting for the broker to use to verify that the JWT was created by the expected issuer. The JWT will be inspected for the standard OAuth "iss" claim and if this value is set, the broker will match it exactly against what is in the JWT\\\\\\\'s "iss" claim. If there is no match, the broker will reject the JWT and authentication will fail.\\\'\'  configs.128:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.read.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The (optional) value in milliseconds for the external authentication provider read timeout. Currently applies only to OAUTHBEARER."\'  configs.129:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.abort.timed.out.transaction.cleanup.interval.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.abort.timed.out.transaction.cleanup.interval.ms  value:10000  source:5"  config_type:3  documentation:"The interval at which to rollback transactions that have timed out"\'  configs.130:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.kinit.cmd  value:/usr/bin/kinit  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.kinit.cmd  value:/usr/bin/kinit  source:5"  config_type:2  documentation:"Kerberos kinit command path."\'  configs.131:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.max.bytes.per.second  value:1.7976931348623157E308  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.max.bytes.per.second  value:1.7976931348623157E308  source:5"  config_type:6  documentation:"The log cleaner will be throttled so that the sum of its read and write i/o will be less than this value on average"\'  configs.132:\'kafka2.DescribeConfigsResourceResult32a  name:auto.leader.rebalance.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.leader.rebalance.enable  value:true  source:5"  config_type:1  documentation:"Enables auto leader balancing. A background thread checks the distribution of partition leaders at regular intervals, configurable by leader.imbalance.check.interval.seconds. If the leader imbalance exceeds leader.imbalance.per.broker.percentage, leader rebalance to the preferred leader for partitions is triggered."\'  configs.133:\'kafka2.DescribeConfigsResourceResult32a  name:leader.imbalance.check.interval.seconds  value:300  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:leader.imbalance.check.interval.seconds  value:300  source:5"  config_type:5  documentation:"The frequency with which the partition rebalance check is triggered by the controller"\'  configs.134:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.min.cleanable.ratio  value:0.5  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.min.cleanable.ratio  value:0.5  source:5"  config_type:6  documentation:"The minimum ratio of dirty log to total log for a log to eligible for cleaning. If the log.cleaner.max.compaction.lag.ms or the log.cleaner.min.compaction.lag.ms configurations are also specified, then the log compactor considers the log eligible for compaction as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) records for at least the log.cleaner.min.compaction.lag.ms duration, or (ii) if the log has had dirty (uncompacted) records for at most the log.cleaner.max.compaction.lag.ms period."\'  configs.135:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.record.lock.duration.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.record.lock.duration.ms  value:15000  source:5"  config_type:3  documentation:"The record acquisition lock minimum duration in milliseconds for share groups."\'  configs.136:\'kafka2.DescribeConfigsResourceResult32a  name:replica.lag.time.max.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.lag.time.max.ms  value:30000  source:5"  config_type:5  documentation:"If a follower hasn\\\'t sent any fetch requests or hasn\\\'t consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr"\'  configs.137:\'kafka2.DescribeConfigsResourceResult32a  name:num.network.threads  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.network.threads  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.network.threads  value:3  source:5"  config_type:3  documentation:"The number of threads that the server uses for receiving requests from the network and sending responses to the network. Noted: each listener (except for controller listener) creates its own thread pool."\'  configs.138:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.min.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.min.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for share group members."\'  configs.139:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.key  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Private key in the format specified by \'ssl.keystore.type\'. Default SSL engine factory supports only PEM format with PKCS#8 keys. If the key is encrypted, key password must be specified using \'ssl.key.password\'\\""  configs.140:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.client.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL client callback handler class that implements the AuthenticateCallbackHandler interface."\'  configs.141:\'kafka2.DescribeConfigsResourceResult32a  name:compression.gzip.level  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.gzip.level  value:-1  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'gzip\\\'."\'  configs.142:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.num.samples  value:2  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.num.samples  value:2  source:5"  config_type:3  documentation:"The number of samples maintained to compute metrics."\'  configs.143:\'kafka2.DescribeConfigsResourceResult32a  name:socket.send.buffer.bytes  value:102400  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.send.buffer.bytes  value:102400  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.send.buffer.bytes  value:102400  source:5"  config_type:3  documentation:"The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."\'  configs.144:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.rebalance.protocols  value:classic  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.rebalance.protocols  value:classic  source:5"  config_type:7  documentation:"The list of enabled rebalance protocols. Supported protocols: consumer,classic,share,unknown. The consumer rebalance protocol is in early access and therefore must not be used in production."\'  configs.145:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.keyfactory.algorithm  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The SecretKeyFactory algorithm used for encoding dynamically configured passwords. Default is PBKDF2WithHmacSHA512 if available and PBKDF2WithHmacSHA1 otherwise."\'  configs.146:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Fully qualified class name of `RemoteStorageManager` implementation."\'  configs.147:\'kafka2.DescribeConfigsResourceResult32a  name:socket.receive.buffer.bytes  value:102400  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.receive.buffer.bytes  value:102400  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:socket.receive.buffer.bytes  value:102400  source:5"  config_type:3  documentation:"The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used."\'  configs.148:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.sub.claim.name  value:sub  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.sub.claim.name  value:sub  source:5"  config_type:2  documentation:\\\'The OAuth claim for the subject is often named "sub", but this (optional) setting can provide a different name to use for the subject included in the JWT payload\\\\\\\'s claims if the OAuth/OIDC provider uses a different name for that claim.\\\'\'  configs.149:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.min.bytes  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.min.bytes  value:1  source:5"  config_type:3  documentation:"Minimum bytes expected for each fetch response. If not enough bytes, wait up to <code>replica.fetch.wait.max.ms</code> (broker config)."\'  configs.150:\'kafka2.DescribeConfigsResourceResult32a  name:broker.rack  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Rack of the broker. This will be used in rack aware replication assignment for fault tolerance. Examples: <code>RACK1</code>, <code>us-east-1d</code>"\'  configs.151:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.password  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"Truststore password when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.password</code> system property (note the camelCase)."\'  configs.152:\'kafka2.DescribeConfigsResourceResult32a  name:unclean.leader.election.enable  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:unclean.leader.election.enable  value:false  source:5"  config_type:1  documentation:"Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss<p>Note: In KRaft mode, when enabling this config dynamically, it needs to wait for the unclean leader election thread to trigger election periodically (default is 5 minutes). Please run `kafka-leader-election.sh` with `unclean` option to trigger the unclean leader election immediately if needed.</p>"\'  configs.153:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.ms  value:100  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the initial wait between JWKS (JSON Web Key Set) retrieval attempts from the external authentication provider. JWKS retrieval uses an exponential backoff algorithm with an initial wait based on the sasl.oauthbearer.jwks.endpoint.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms setting."\'  configs.154:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.retention.check.interval.ms  value:600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.retention.check.interval.ms  value:600000  source:5"  config_type:5  documentation:"Frequency at which to check for stale offsets"\'  configs.155:\'kafka2.DescribeConfigsResourceResult32a  name:producer.purgatory.purge.interval.requests  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:producer.purgatory.purge.interval.requests  value:1000  source:5"  config_type:3  documentation:"The purge interval (in number of requests) of the producer request purgatory"\'  configs.156:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.voters  value:4@dev.ak-8.kafka-4.int-0:1055  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.voters  value:4@dev.ak-8.kafka-4.int-0:1055  source:4"  synonyms.1:\\\'kafka2.DescribeConfigsSynonym32a  name:controller.quorum.voters  value:""  source:5\\\'  config_type:7  documentation:"Map of id/endpoint information for the set of voters in a comma-separated list of <code>{id}@{host}:{port}</code> entries. For example: <code>1@localhost:9092,2@localhost:9093,3@localhost:9094</code>"\'  configs.157:\'kafka2.DescribeConfigsResourceResult32a  name:metrics.sample.window.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metrics.sample.window.ms  value:30000  source:5"  config_type:5  documentation:"The window of time a metrics sample is computed over."\'  configs.158:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.check.interval.ms  value:300000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.check.interval.ms  value:300000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.retention.check.interval.ms  value:300000  source:5"  config_type:5  documentation:"The frequency in milliseconds that the log cleaner checks whether any log is eligible for deletion"\'  configs.159:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.session.timeout.ms  value:45000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.session.timeout.ms  value:45000  source:5"  config_type:3  documentation:"The timeout to detect client failures when using the consumer group protocol."\'  configs.160:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.window.jitter  value:0.05  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.window.jitter  value:0.05  source:5"  config_type:6  documentation:"The maximum amount of random jitter relative to the credential\\\'s lifetime that is added to the login refresh thread\\\'s sleep time. Legal values are between 0 and 0.25 (25%) inclusive; a default value of 0.05 (5%) is used if no value is specified. Currently applies only to OAUTHBEARER."\'  configs.161:\'kafka2.DescribeConfigsResourceResult32a  name:leader.imbalance.per.broker.percentage  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:leader.imbalance.per.broker.percentage  value:10  source:5"  config_type:3  documentation:"The ratio of leader imbalance allowed per broker. The controller would trigger a leader balance if it goes above this value per broker. The value is specified in percentage."\'  configs.162:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for controller mutation quotas"\'  configs.163:\'kafka2.DescribeConfigsResourceResult32a  name:metric.reporters  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:metric.reporters  value:""  source:5\\\'  config_type:7  documentation:"A list of classes to use as metrics reporters. Implementing the <code>org.apache.kafka.common.metrics.MetricsReporter</code> interface allows plugging in classes that will be notified of new metric creation. The JmxReporter is always included to register JMX statistics."\'  configs.164:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.token.endpoint.url  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"The URL for the OAuth/OIDC identity provider. If the URL is HTTP(S)-based, it is the issuer\\\'s token endpoint URL to which requests will be made to login based on the configuration in sasl.jaas.config. If the URL is file-based, it specifies a file containing an access token (in JWT serialized form) issued by the OAuth/OIDC identity provider to use for authorization."\'  configs.165:\'kafka2.DescribeConfigsResourceResult32a  name:auto.create.topics.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:auto.create.topics.enable  value:true  source:5"  config_type:1  documentation:"Enable auto creation of topic on the server."\'  configs.166:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.partition.max.record.locks  value:200  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.partition.max.record.locks  value:200  source:5"  config_type:3  documentation:"Share-group record lock limit per share-partition."\'  configs.167:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.engine.factory.class  read_only:N  config_source:5  is_sensitive:N  config_type:8  documentation:"The class of type org.apache.kafka.common.security.auth.SslEngineFactory to provide SSLEngine objects. Default value is org.apache.kafka.common.security.ssl.DefaultSslEngineFactory. Alternatively, setting this to org.apache.kafka.common.security.ssl.CommonNameLoggingSslEngineFactory will log the common name of expired SSL certificates used by clients to authenticate at any of the brokers with log level INFO. Note that this will cause a tiny delay during establishment of new connections from mTLS clients to brokers due to the extra code for examining the certificate chain provided by the client. Note further that the implementation uses a custom truststore based on the standard Java truststore and thus might be considered a security risk due to not being as mature as the standard one."\'  configs.168:\'kafka2.DescribeConfigsResourceResult32a  name:replica.socket.receive.buffer.bytes  value:65536  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.socket.receive.buffer.bytes  value:65536  source:5"  config_type:3  documentation:"The socket receive buffer for network requests to the leader for replicating data"\'  configs.169:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.location  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Truststore location when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.location</code> system property (note the camelCase)."\'  configs.170:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.allow.dn.changes  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.allow.dn.changes  value:false  source:5"  config_type:1  documentation:"Indicates whether changes to the certificate distinguished name should be allowed during a dynamic reconfiguration of certificates or not."\'  configs.171:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.wait.max.ms  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.wait.max.ms  value:500  source:5"  config_type:3  documentation:"The maximum wait time for each fetcher request issued by follower replicas. This value should always be less than the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics"\'  configs.172:\'kafka2.DescribeConfigsResourceResult32a  name:password.encoder.iterations  value:4096  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:password.encoder.iterations  value:4096  source:5"  config_type:3  documentation:"The iteration count used for encoding dynamically configured passwords."\'  configs.173:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.min.heartbeat.interval.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.min.heartbeat.interval.ms  value:5000  source:5"  config_type:3  documentation:"The minimum heartbeat interval for registered consumers."\'  configs.174:\'kafka2.DescribeConfigsResourceResult32a  name:default.replication.factor  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:default.replication.factor  value:1  source:5"  config_type:3  documentation:"The replication factor for automatically created topics, and for topics created with -1 as the replication factor"\'  configs.175:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:"The password for the trust store file. If a password is not set, trust store file configured will still be used, but integrity checking is disabled. Trust store password is not supported for PEM format."\'  configs.176:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.principal.to.local.rules  value:DEFAULT  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.principal.to.local.rules  value:DEFAULT  source:5"  config_type:7  documentation:\\\'A list of rules for mapping from principal names to short names (typically operating system usernames). The rules are evaluated in order and the first rule that matches a principal name is used to map it to a short name. Any later rules in the list are ignored. By default, principal names of the form <code>{username}/{hostname}@{REALM}</code> are mapped to <code>{username}</code>. For more details on the format please see <a href="#security_authz"> security authorization and acls</a>. Note that this configuration is ignored if an extension of <code>KafkaPrincipalBuilder</code> is provided by the <code>principal.builder.class</code> configuration.\\\'\'  configs.177:\'kafka2.DescribeConfigsResourceResult32a  name:log.preallocate  value:false  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.preallocate  value:false  source:5"  config_type:1  documentation:"Should pre allocate file when create new segment? If you are using Kafka on Windows, you probably need to set it to true."\'  configs.178:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.reader.max.pending.tasks  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.reader.max.pending.tasks  value:100  source:5"  config_type:3  documentation:"Maximum remote log reader thread pool task queue size. If the task queue is full, fetch requests are served with an error."\'  configs.179:\'kafka2.DescribeConfigsResourceResult32a  name:transactional.id.expiration.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transactional.id.expiration.ms  value:604800000  source:5"  config_type:3  documentation:"The time in ms that the transaction coordinator will wait without receiving any transaction status updates for the current transaction before expiring its transactional id. Transactional IDs will not expire while a the transaction is still ongoing."\'  configs.180:\'kafka2.DescribeConfigsResourceResult32a  name:control.plane.listener.name  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:\\\'Name of listener used for communication between controller and brokers. A broker will use the <code>control.plane.listener.name</code> to locate the endpoint in listeners list, to listen for connections from the controller. For example, if a broker\\\\\\\'s config is:\\\\n<code>listeners = INTERNAL://192.1.1.8:9092, EXTERNAL://10.1.1.5:9093, CONTROLLER://192.1.1.8:9094listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER</code>\\\\nOn startup, the broker will start listening on "192.1.1.8:9094" with security protocol "SSL".\\\\nOn the controller side, when it discovers a broker\\\\\\\'s published endpoints through ZooKeeper, it will use the <code>control.plane.listener.name</code> to find the endpoint, which it will use to establish connection to the broker.\\\\nFor example, if the broker\\\\\\\'s published endpoints on ZooKeeper are:\\\\n <code>"endpoints" : ["INTERNAL://broker1.example.com:9092","EXTERNAL://broker1.example.com:9093","CONTROLLER://broker1.example.com:9094"]</code>\\\\n and the controller\\\\\\\'s config is:\\\\n<code>listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER</code>\\\\nthen the controller will use "broker1.example.com:9094" with security protocol "SSL" to connect to the broker.\\\\nIf not explicitly configured, the default value will be null and there will be no dedicated endpoints for controller connections.\\\\nIf explicitly configured, the value cannot be the same as the value of <code>inter.broker.listener.name</code>.\\\'\'  configs.181:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.replication.factor  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.replication.factor  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.replication.factor  value:3  source:5"  config_type:4  documentation:"The replication factor for the transaction topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."\'  configs.182:\'kafka2.DescribeConfigsResourceResult32a  name:num.io.threads  value:8  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.io.threads  value:8  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.io.threads  value:8  source:5"  config_type:3  documentation:"The number of threads that the server uses for processing requests, which may include disk I/O"\'  configs.183:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.buffer.seconds  value:300  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.buffer.seconds  value:300  source:5"  config_type:4  documentation:"The amount of buffer time before credential expiration to maintain when refreshing a credential, in seconds. If a refresh would otherwise occur closer to expiration than the number of buffer seconds then the refresh will be moved up to maintain as much of the buffer time as possible. Legal values are between 0 and 3600 (1 hour); a default value of  300 (5 minutes) is used if no value is specified. This value and sasl.login.refresh.min.period.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER."\'  configs.184:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.heartbeat.interval.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.heartbeat.interval.ms  value:15000  source:5"  config_type:3  documentation:"The maximum heartbeat interval for share group members."\'  configs.185:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.commit.required.acks  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.commit.required.acks  value:-1  source:5"  config_type:4  documentation:"DEPRECATED: The required acks before the commit can be accepted. In general, the default (-1) should not be overridden."\'  configs.186:\'kafka2.DescribeConfigsResourceResult32a  name:connection.failed.authentication.delay.ms  value:100  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:connection.failed.authentication.delay.ms  value:100  source:5"  config_type:3  documentation:"Connection close delay on failed authentication: this is the time (in milliseconds) by which connection close will be delayed on authentication failure. This must be configured to be less than connections.max.idle.ms to prevent connection timeout."\'  configs.187:\'kafka2.DescribeConfigsResourceResult32a  name:delete.topic.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delete.topic.enable  value:true  source:5"  config_type:1  documentation:"Enables delete topic. Delete topic through the admin tool will have no effect if this config is turned off"\'  configs.188:\'kafka2.DescribeConfigsResourceResult32a  name:quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for client quotas"\'  configs.189:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.type  value:JKS  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.truststore.type  value:JKS  source:5"  config_type:2  documentation:"The file format of the trust store file. The values currently supported by the default `ssl.engine.factory.class` are [JKS, PKCS12, PEM]."\'  configs.190:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.commit.timeout.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.commit.timeout.ms  value:5000  source:5"  config_type:3  documentation:"Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached. This is similar to the producer request timeout."\'  configs.191:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.ocsp.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.ocsp.enable  value:false  source:5"  config_type:1  documentation:"Specifies whether to enable Online Certificate Status Protocol in the ZooKeeper TLS protocols. Overrides any explicit value set via the <code>zookeeper.ssl.ocsp</code> system property (note the shorter name)."\'  configs.192:\'kafka2.DescribeConfigsResourceResult32a  name:broker.heartbeat.interval.ms  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.heartbeat.interval.ms  value:2000  source:5"  config_type:3  documentation:"The length of time in milliseconds between broker heartbeats. Used when running in KRaft mode."\'  configs.193:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.record.lock.duration.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.record.lock.duration.ms  value:60000  source:5"  config_type:3  documentation:"The record acquisition lock maximum duration in milliseconds for share groups."\'  configs.194:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.mechanism.controller.protocol  value:GSSAPI  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.mechanism.controller.protocol  value:GSSAPI  source:5"  config_type:2  documentation:"SASL mechanism used for communication with controllers. Default is GSSAPI."\'  configs.195:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.max.compaction.lag.ms  value:9223372036854775807  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.max.compaction.lag.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"The maximum time a message will remain ineligible for compaction in the log. Only applicable for logs that are being compacted."\'  configs.196:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.enabled.protocols  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:"Specifies the enabled protocol(s) in ZooKeeper TLS negotiation (csv). Overrides any explicit value set via the <code>zookeeper.ssl.enabledProtocols</code> system property (note the camelCase). The default value of <code>null</code> means the enabled protocol will be the value of the <code>zookeeper.ssl.protocol</code> configuration property."\'  configs.197:\'kafka2.DescribeConfigsResourceResult32a  name:allow.everyone.if.no.acl.found  read_only:Y  config_source:4  is_sensitive:Y  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:allow.everyone.if.no.acl.found  source:4"  config_type:0\'  configs.198:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.storage.manager.class.path  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Class path of the `RemoteStorageManager` implementation. If specified, the RemoteStorageManager implementation and its dependent libraries will be loaded by a dedicated classloader which searches this class path before the Kafka broker class path. The syntax of this parameter is same as the standard Java class path string."\'  configs.199:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied."\'  configs.200:\'kafka2.DescribeConfigsResourceResult32a  name:alter.log.dirs.replication.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:alter.log.dirs.replication.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for alter log dirs replication quotas"\'  configs.201:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.enable  value:true  source:5"  config_type:1  documentation:"Enable the log cleaner process to run on the server. Should be enabled if using any topics with a cleanup.policy=compact including the internal offsets topic. If disabled those topics will not be compacted and continually grow in size."\'  configs.202:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.fetch.timeout.ms  value:10000  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.fetch.timeout.ms  value:10000  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.fetch.timeout.ms  value:2000  source:5"  config_type:3  documentation:"Maximum time without a successful fetch from the current leader before becoming a candidate and triggering an election for voters; Maximum time a leader can go without receiving valid fetch or fetchSnapshot request from a majority of the quorum before resigning."\'  configs.203:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.load.buffer.size  value:5242880  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.load.buffer.size  value:5242880  source:5"  config_type:3  documentation:"Batch size for reading from the offsets segments when loading offsets into the cache (soft-limit, overridden if records are too large)."\'  configs.204:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.client.auth  value:none  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.client.auth  value:none  source:5"  config_type:2  documentation:"Configures kafka broker to request client authentication. The following settings are common:  <ul> <li><code>ssl.client.auth=required</code> If set to required client authentication is required. <li><code>ssl.client.auth=requested</code> This means client authentication is optional. unlike required, if this option is set client can choose not to provide authentication information about itself <li><code>ssl.client.auth=none</code> This means client authentication is not needed.</ul>"\'  configs.205:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.max.retries  value:3  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.max.retries  value:3  source:5"  config_type:3  documentation:"Controlled shutdown can fail for multiple reasons. This determines the number of retries when such failure happens"\'  configs.206:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.replication.factor  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.replication.factor  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.replication.factor  value:3  source:5"  config_type:4  documentation:"The replication factor for the offsets topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement."\'  configs.207:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.truststore.type  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Truststore type when using TLS connectivity to ZooKeeper. Overrides any explicit value set via the <code>zookeeper.ssl.trustStore.type</code> system property (note the camelCase). The default value of <code>null</code> means the type will be auto-detected based on the filename extension of the truststore."\'  configs.208:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.min.isr  value:1  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.min.isr  value:1  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.min.isr  value:2  source:5"  config_type:3  documentation:"The minimum number of replicas that must acknowledge a write to transaction topic in order to be considered successful."\'  configs.209:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.secure.random.implementation  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The SecureRandom PRNG implementation to use for SSL cryptography operations. "\'  configs.210:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.ticket.renew.jitter  value:0.05  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.ticket.renew.jitter  value:0.05  source:5"  config_type:6  documentation:"Percentage of random jitter added to the renewal time."\'  configs.211:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.trustmanager.algorithm  value:PKIX  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.trustmanager.algorithm  value:PKIX  source:5"  config_type:2  documentation:"The algorithm used by trust manager factory for SSL connections. Default value is the trust manager factory algorithm configured for the Java Virtual Machine."\'  configs.212:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.session.timeout.ms  value:18000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.session.timeout.ms  value:18000  source:5"  config_type:3  documentation:"Zookeeper session timeout"\'  configs.213:\'kafka2.DescribeConfigsResourceResult32a  name:log.local.retention.bytes  value:-2  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.local.retention.bytes  value:-2  source:5"  config_type:5  documentation:"The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. Default value is -2, it represents `log.retention.bytes` value to be used. The effective value should always be less than or equal to `log.retention.bytes` value."\'  configs.214:\'kafka2.DescribeConfigsResourceResult32a  name:log.retention.bytes  value:-1  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.retention.bytes  value:-1  source:5"  config_type:5  documentation:"The maximum size of the log before deleting it"\'  configs.215:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quota.window.size.seconds  value:1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quota.window.size.seconds  value:1  source:5"  config_type:3  documentation:"The time span of each sample for controller mutations quotas"\'  configs.216:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.impl.prefix  value:rlmm.config.  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.manager.impl.prefix  value:rlmm.config.  source:5"  config_type:2  documentation:"Prefix used for properties to be passed to RemoteLogMetadataManager implementation. For example this value can be `rlmm.config.`."\'  configs.217:"kafka2.DescribeConfigsResourceResult32a  name:sasl.jaas.config  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\'JAAS login context parameters for SASL connections in the format used by JAAS configuration files. JAAS configuration file format is described <a href=\\"https://docs.oracle.com/javase/8/docs/technotes/guides/security/jgss/tutorials/LoginConfigFile.html\\">here</a>. The format for the value is: <code>loginModuleClass controlFlag (optionName=optionValue)*;</code>. For brokers, the config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=com.example.ScramLoginModule required;\'"  configs.218:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.kerberos.min.time.before.relogin  value:60000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.kerberos.min.time.before.relogin  value:60000  source:5"  config_type:5  documentation:"Login thread sleep time between refresh attempts."\'  configs.219:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.retention.minutes  value:10080  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.retention.minutes  value:10080  source:5"  config_type:3  documentation:"For subscribed consumers, committed offset of a specific partition will be expired and discarded when 1) this retention period has elapsed after the consumer group loses all its consumers (i.e. becomes empty); 2) this retention period has elapsed since the last time an offset is committed for the partition and the group is no longer subscribed to the corresponding topic. For standalone consumers (using manual assignment), offsets will be expired after this retention period has elapsed since the time of last commit. Note that when a group is deleted via the delete-group request, its committed offsets will also be deleted without extra retention period; also when a topic is deleted via the delete-topic request, upon propagated metadata update any group\\\'s committed offsets for that topic will also be deleted without extra retention period."\'  configs.220:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.backoff.ms  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.backoff.ms  value:1000  source:5"  config_type:3  documentation:"The amount of time to sleep when fetch partition error occurs."\'  configs.221:\'kafka2.DescribeConfigsResourceResult32a  name:inter.broker.protocol.version  value:3.9-IV0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:inter.broker.protocol.version  value:3.9-IV0  source:5"  config_type:2  documentation:"Specify which version of the inter-broker protocol will be used.\\\\n. This is typically bumped after all brokers were upgraded to a new version.\\\\n Example of some valid values are: 0.8.0, 0.8.1, 0.8.1.1, 0.8.2, 0.8.2.0, 0.8.2.1, 0.9.0.0, 0.9.0.1 Check MetadataVersion for the full list."\'  configs.222:\'kafka2.DescribeConfigsResourceResult32a  name:kafka.metrics.reporters  value:""  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:kafka.metrics.reporters  value:""  source:5\\\'  config_type:7  documentation:"A list of classes to use as Yammer metrics custom reporters. The reporters should implement <code>kafka.metrics.KafkaMetricsReporter</code> trait. If a client wants to expose JMX operations on a custom reporter, the custom reporter needs to additionally implement an MBean trait that extends <code>kafka.metrics.KafkaMetricsReporterMBean</code> trait so that the registered MBean is compliant with the standard MBean convention."\'  configs.223:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.delivery.count.limit  value:5  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.delivery.count.limit  value:5  source:5"  config_type:3  documentation:"The maximum number of delivery attempts for a record delivered to a share group."\'  configs.224:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.allow.san.changes  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.allow.san.changes  value:false  source:5"  config_type:1  documentation:"Indicates whether changes to the certificate subject alternative names should be allowed during a dynamic reconfiguration of certificates or not."\'  configs.225:\'kafka2.DescribeConfigsResourceResult32a  name:compression.zstd.level  value:3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.zstd.level  value:3  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'zstd\\\'."\'  configs.226:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.copy.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.copy.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for remote copy quota management. The default value is 11, which means there are 10 whole windows + 1 current window."\'  configs.227:\'kafka2.DescribeConfigsResourceResult32a  name:num.partitions  value:3  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:num.partitions  value:3  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:num.partitions  value:1  source:5"  config_type:3  documentation:"The default number of log partitions per topic"\'  configs.228:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.certificate.chain  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Certificate chain in the format specified by \'ssl.keystore.type\'. Default SSL engine factory supports only PEM format with a list of X.509 certificates\\""  configs.229:\'kafka2.DescribeConfigsResourceResult32a  name:socket.connection.setup.timeout.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.connection.setup.timeout.ms  value:10000  source:5"  config_type:5  documentation:"The amount of time the client will wait for the socket connection to be established. If the connection is not built before the timeout elapses, clients will close the socket channel. This value is the initial backoff value and will increase exponentially for each consecutive connection failure, up to the <code>socket.connection.setup.timeout.max.ms</code> value."\'  configs.230:\'kafka2.DescribeConfigsResourceResult32a  name:broker.id.generation.enable  value:true  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.id.generation.enable  value:true  source:5"  config_type:1  documentation:"Enable automatic broker id generation on the server. When enabled the value configured for reserved.broker.max.id should be reviewed."\'  configs.231:\'kafka2.DescribeConfigsResourceResult32a  name:listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107,CONTROLLER://dev.ak-8.kafka-4.int-0:1055  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107,CONTROLLER://dev.ak-8.kafka-4.int-0:1055  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:listeners  value:PLAINTEXT://:9092  source:5"  config_type:2  documentation:"Listener List - Comma-separated list of URIs we will listen on and the listener names. If the listener name is not a security protocol, <code>listener.security.protocol.map</code> must also be set.\\\\n Listener names and port numbers must be unique unless %n one listener is an IPv4 address and the other listener is %n an IPv6 address (for the same port).%n Specify hostname as 0.0.0.0 to bind to all interfaces.%n Leave hostname empty to bind to default interface.%n Examples of legal listener lists:%n <code>PLAINTEXT://myhost:9092,SSL://:9091</code>%n <code>CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093</code>%n <code>PLAINTEXT://127.0.0.1:9092,SSL://[::1]:9092</code>%n"\'  configs.232:"kafka2.DescribeConfigsResourceResult32a  name:ssl.enabled.protocols  value:TLSv1.2,TLSv1.3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:ssl.enabled.protocols  value:TLSv1.2,TLSv1.3  source:5\\"  config_type:7  documentation:\\"The list of protocols enabled for SSL connections. The default is \'TLSv1.2,TLSv1.3\' when running with Java 11 or newer, \'TLSv1.2\' otherwise. With the default value for Java 11, clients and servers will prefer TLSv1.3 if both support it and fallback to TLSv1.2 otherwise (assuming both support at least TLSv1.2). This default should be fine for most cases. Also see the config documentation for `ssl.protocol`.\\""  configs.233:\'kafka2.DescribeConfigsResourceResult32a  name:inter.broker.listener.name  value:INTERNAL  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:inter.broker.listener.name  value:INTERNAL  source:4"  config_type:2  documentation:"Name of listener used for communication between brokers. If this is unset, the listener name is defined by security.inter.broker.protocolIt is an error to set this and security.inter.broker.protocol properties at the same time."\'  configs.234:\'kafka2.DescribeConfigsResourceResult32a  name:alter.config.policy.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The alter configs policy class that should be used for validation. The class should implement the <code>org.apache.kafka.server.policy.AlterConfigPolicy</code> interface."\'  configs.235:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.expiry.check.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.expiry.check.interval.ms  value:3600000  source:5"  config_type:5  documentation:"Scan interval to remove expired delegation tokens."\'  configs.236:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.scheduler.interval.ms  value:9223372036854775807  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.scheduler.interval.ms  value:9223372036854775807  source:5"  config_type:5  documentation:"The frequency in ms that the log flusher checks whether any log needs to be flushed to disk"\'  configs.237:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.max.in.flight.requests  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.max.in.flight.requests  value:10  source:5"  config_type:3  documentation:"The maximum number of unacknowledged requests the client will send to ZooKeeper before blocking."\'  configs.238:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.expiration.thread.pool.size  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.expiration.thread.pool.size  value:-1  source:5"  config_type:3  documentation:"Size of the thread pool used in scheduling tasks to clean up remote log segments. The default value of -1 means that this will be set to the configured value of remote.log.manager.thread.pool.size, if available; otherwise, it defaults to 10."\'  configs.239:\'kafka2.DescribeConfigsResourceResult32a  name:log.index.size.max.bytes  value:10485760  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.size.max.bytes  value:10485760  source:5"  config_type:3  documentation:"The maximum size in bytes of the offset index"\'  configs.240:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keymanager.algorithm  value:SunX509  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:ssl.keymanager.algorithm  value:SunX509  source:5"  config_type:2  documentation:"The algorithm used by key manager factory for SSL connections. Default value is the key manager factory algorithm configured for the Java Virtual Machine."\'  configs.241:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL login callback handler class that implements the AuthenticateCallbackHandler interface. For brokers, login callback handler config must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.callback.handler.class=com.example.CustomScramLoginCallbackHandler"\'  configs.242:\'kafka2.DescribeConfigsResourceResult32a  name:replica.fetch.max.bytes  value:10485760  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.max.bytes  value:10485760  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:replica.fetch.max.bytes  value:1048576  source:5"  config_type:3  documentation:"The number of bytes of messages to attempt to fetch for each partition. This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. The maximum record batch size accepted by the broker is defined via <code>message.max.bytes</code> (broker config) or <code>max.message.bytes</code> (topic config)."\'  configs.243:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.crl.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.crl.enable  value:false  source:5"  config_type:1  documentation:"Specifies whether to enable Certificate Revocation List in the ZooKeeper TLS protocols. Overrides any explicit value set via the <code>zookeeper.ssl.crl</code> system property (note the shorter name)."\'  configs.244:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.server.callback.handler.class  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The fully qualified name of a SASL server callback handler class that implements the AuthenticateCallbackHandler interface. Server callback handlers must be prefixed with listener prefix and SASL mechanism name in lower-case. For example, listener.name.sasl_ssl.plain.sasl.server.callback.handler.class=com.example.CustomPlainCallbackHandler."\'  configs.245:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.groups  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.groups  value:10  source:5"  config_type:4  documentation:"The maximum number of share groups."\'  configs.246:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.dedupe.buffer.size  value:134217728  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.dedupe.buffer.size  value:134217728  source:5"  config_type:5  documentation:"The total memory used for log deduplication across all cleaner threads"\'  configs.247:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.buffer.size  value:524288  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.buffer.size  value:524288  source:5"  config_type:3  documentation:"The total memory used for log cleaner I/O buffers across all cleaner threads"\'  configs.248:\'kafka2.DescribeConfigsResourceResult32a  name:create.topic.policy.class.name  read_only:Y  config_source:5  is_sensitive:N  config_type:8  documentation:"The create topic policy class that should be used for validation. The class should implement the <code>org.apache.kafka.server.policy.CreateTopicPolicy</code> interface."\'  configs.249:"kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.certificates  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"Trusted certificates in the format specified by \'ssl.truststore.type\'. Default SSL engine factory supports only PEM format with X.509 certificates.\\""  configs.250:\'kafka2.DescribeConfigsResourceResult32a  name:socket.listen.backlog.size  value:50  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:socket.listen.backlog.size  value:50  source:5"  config_type:3  documentation:"The maximum number of pending connections on the socket. In Linux, you may also need to configure <code>somaxconn</code> and <code>tcp_max_syn_backlog</code> kernel parameters accordingly to make the configuration takes effect."\'  configs.251:\'kafka2.DescribeConfigsResourceResult32a  name:controlled.shutdown.retry.backoff.ms  value:5000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controlled.shutdown.retry.backoff.ms  value:5000  source:5"  config_type:5  documentation:"Before each retry, the system needs time to recover from the state that caused the previous failure (Controller fail over, replica lag etc). This config determines the amount of time to wait before retrying."\'  configs.252:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.server.max.receive.size  value:524288  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.server.max.receive.size  value:524288  source:5"  config_type:3  documentation:"The maximum receive size allowed before and during initial SASL authentication. Default receive size is 512KB. GSSAPI limits requests to 64K, but we allow upto 512KB by default for custom SASL mechanisms. In practice, PLAIN, SCRAM and OAUTH mechanisms can use much smaller limits."\'  configs.253:\'kafka2.DescribeConfigsResourceResult32a  name:security.providers  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"A list of configurable creator classes each returning a provider implementing security algorithms. These classes should implement the <code>org.apache.kafka.common.security.auth.SecurityProviderCreator</code> interface."\'  configs.254:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.max.snapshot.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.max.snapshot.interval.ms  value:3600000  source:5"  config_type:5  documentation:"This is the maximum number of milliseconds to wait to generate a snapshot if there are committed records in the log that are not included in the latest snapshot. A value of zero disables time based snapshot generation. The default value is 3600000. To generate snapshots based on the number of metadata bytes, see the <code>metadata.log.max.record.bytes.between.snapshots</code> configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached."\'  configs.255:\'kafka2.DescribeConfigsResourceResult32a  name:compression.lz4.level  value:9  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:compression.lz4.level  value:9  source:5"  config_type:3  documentation:"The compression level to use if compression.type is set to \\\'lz4\\\'."\'  configs.256:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.hours  value:168  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.roll.hours  value:168  source:5"  config_type:3  documentation:"The maximum time before a new log segment is rolled out (in hours), secondary to log.roll.ms property"\'  configs.257:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleanup.policy  value:delete  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleanup.policy  value:delete  source:5"  config_type:7  documentation:\\\'The default cleanup policy for segments beyond the retention window. A comma separated list of valid policies. Valid policies are: "delete" and "compact"\\\'\'  configs.258:\'kafka2.DescribeConfigsResourceResult32a  name:initial.broker.registration.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:initial.broker.registration.timeout.ms  value:60000  source:5"  config_type:3  documentation:"When initially registering with the controller quorum, the number of milliseconds to wait before declaring failure and exiting the broker process."\'  configs.259:\'kafka2.DescribeConfigsResourceResult32a  name:log.flush.start.offset.checkpoint.interval.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.flush.start.offset.checkpoint.interval.ms  value:60000  source:5"  config_type:3  documentation:"The frequency with which we update the persistent record of log start offset"\'  configs.260:\'kafka2.DescribeConfigsResourceResult32a  name:log.roll.jitter.ms  read_only:N  config_source:5  is_sensitive:N  config_type:5  documentation:"The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used"\'  configs.261:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.segment.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.segment.bytes  value:104857600  source:5"  config_type:3  documentation:"The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads"\'  configs.262:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.segment.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.segment.bytes  value:104857600  source:5"  config_type:3  documentation:"The offsets topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads."\'  configs.263:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.idle.interval.ms  value:500  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.idle.interval.ms  value:500  source:5"  config_type:3  documentation:"This configuration controls how often the active controller should write no-op records to the metadata partition. If the value is 0, no-op records are not appended to the metadata partition. The default value is 500"\'  configs.264:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.class.name  value:org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.metadata.manager.class.name  value:org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager  source:5"  config_type:2  documentation:"Fully qualified class name of `RemoteLogMetadataManager` implementation."\'  configs.265:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.retry.backoff.max.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.retry.backoff.max.ms  value:10000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the maximum wait between login attempts to the external authentication provider. Login uses an exponential backoff algorithm with an initial wait based on the sasl.login.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.login.retry.backoff.max.ms setting. Currently applies only to OAUTHBEARER."\'  configs.266:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.manager.task.interval.ms  value:30000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:remote.log.manager.task.interval.ms  value:30000  source:5"  config_type:5  documentation:"Interval at which remote log manager runs the scheduled tasks like copy segments, and clean up remote log segments."\'  configs.267:\'kafka2.DescribeConfigsResourceResult32a  name:group.initial.rebalance.delay.ms  value:3000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.initial.rebalance.delay.ms  value:3000  source:5"  config_type:3  documentation:"The amount of time the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins."\'  configs.268:\'kafka2.DescribeConfigsResourceResult32a  name:log.index.interval.bytes  value:4096  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.index.interval.bytes  value:4096  source:5"  config_type:3  documentation:"The interval with which we add an entry to the offset index."\'  configs.269:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.backoff.ms  value:15000  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.backoff.ms  value:15000  source:5"  config_type:5  documentation:"The amount of time to sleep when there are no logs to clean"\'  configs.270:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.truststore.location  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The location of the trust store file."\'  configs.271:\'kafka2.DescribeConfigsResourceResult32a  name:offset.metadata.max.bytes  value:4096  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offset.metadata.max.bytes  value:4096  source:5"  config_type:3  documentation:"The maximum size for a metadata entry associated with an offset commit."\'  configs.272:"kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"The store password for the key store file. This is optional for client and only needed if \'ssl.keystore.location\' is configured. Key store password is not supported for PEM format.\\""  configs.273:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.metadata.migration.enable  value:false  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.metadata.migration.enable  value:false  source:5"  config_type:1  documentation:"Enable ZK to KRaft migration"\'  configs.274:\'kafka2.DescribeConfigsResourceResult32a  name:fetch.max.bytes  value:57671680  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:fetch.max.bytes  value:57671680  source:5"  config_type:3  documentation:"The maximum number of bytes we will return for a fetch request. Must be at least 1024."\'  configs.275:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.retention.bytes  value:104857600  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.retention.bytes  value:104857600  source:5"  config_type:5  documentation:"The maximum combined size of the metadata log and snapshots before deleting old snapshots and log files. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit."\'  configs.276:"kafka2.DescribeConfigsResourceResult32a  name:compression.type  value:producer  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:compression.type  value:producer  source:5\\"  config_type:2  documentation:\\"Specify the final compression type for a given topic. This configuration accepts the standard compression codecs (\'gzip\', \'snappy\', \'lz4\', \'zstd\'). It additionally accepts \'uncompressed\' which is equivalent to no compression; and \'producer\' which means retain the original compression codec set by the producer.\\""  configs.277:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.connect.timeout.ms  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The (optional) value in milliseconds for the external authentication provider connection timeout. Currently applies only to OAUTHBEARER."\'  configs.278:\'kafka2.DescribeConfigsResourceResult32a  name:max.connections.per.ip.overrides  value:""  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\\'kafka2.DescribeConfigsSynonym32a  name:max.connections.per.ip.overrides  value:""  source:5\\\'  config_type:2  documentation:\\\'A comma-separated list of per-ip or hostname overrides to the default maximum number of connections. An example value is "hostName:100,127.0.0.1:200"\\\'\'  configs.279:\'kafka2.DescribeConfigsResourceResult32a  name:group.consumer.max.heartbeat.interval.ms  value:15000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.consumer.max.heartbeat.interval.ms  value:15000  source:5"  config_type:3  documentation:"The maximum heartbeat interval for registered consumers."\'  configs.280:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.login.refresh.window.factor  value:0.8  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.login.refresh.window.factor  value:0.8  source:5"  config_type:6  documentation:"Login refresh thread will sleep until the specified window factor relative to the credential\\\'s lifetime has been reached, at which time it will try to refresh the credential. Legal values are between 0.5 (50%) and 1.0 (100%) inclusive; a default value of 0.8 (80%) is used if no value is specified. Currently applies only to OAUTHBEARER."\'  configs.281:\'kafka2.DescribeConfigsResourceResult32a  name:remote.log.metadata.manager.class.path  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"Class path of the `RemoteLogMetadataManager` implementation. If specified, the RemoteLogMetadataManager implementation and its dependent libraries will be loaded by a dedicated classloader which searches this class path before the Kafka broker class path. The syntax of this parameter is same as the standard Java class path string."\'  configs.282:\'kafka2.DescribeConfigsResourceResult32a  name:kafka.metrics.polling.interval.secs  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:kafka.metrics.polling.interval.secs  value:10  source:5"  config_type:3  documentation:"The metrics polling interval (in seconds) which can be used in kafka.metrics.reporters implementations."\'  configs.283:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.max.record.bytes.between.snapshots  value:20971520  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.max.record.bytes.between.snapshots  value:20971520  source:5"  config_type:5  documentation:"This is the maximum number of bytes in the log between the latest snapshot and the high-watermark needed before generating a new snapshot. The default value is 20971520. To generate snapshots based on the time elapsed, see the <code>metadata.log.max.snapshot.interval.ms</code> configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached."\'  configs.284:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.max.retention.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.max.retention.ms  value:604800000  source:5"  config_type:5  documentation:"The number of milliseconds to keep a metadata log file or snapshot before deleting it. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit."\'  configs.285:\'kafka2.DescribeConfigsResourceResult32a  name:controller.quorum.election.backoff.max.ms  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:controller.quorum.election.backoff.max.ms  value:1000  source:5"  config_type:3  documentation:"Maximum time in milliseconds before starting new elections. This is used in the binary exponential backoff mechanism that helps prevent gridlocked elections"\'  configs.286:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.size  value:200  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.size  value:200  source:5"  config_type:4  documentation:"The maximum number of members that a single share group can accommodate."\'  configs.287:\'kafka2.DescribeConfigsResourceResult32a  name:max.incremental.fetch.session.cache.slots  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.incremental.fetch.session.cache.slots  value:1000  source:5"  config_type:3  documentation:"The maximum number of total incremental fetch sessions that we will maintain. FetchSessionCache is sharded into 8 shards and the limit is equally divided among all shards. Sessions are allocated to each shard in round-robin. Only entries within a shard are considered eligible for eviction."\'  configs.288:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.master.key  read_only:Y  config_source:5  is_sensitive:Y  config_type:9  documentation:"DEPRECATED: An alias for delegation.token.secret.key, which should be used instead of this config."\'  configs.289:"kafka2.DescribeConfigsResourceResult32a  name:ssl.key.password  read_only:N  config_source:5  is_sensitive:Y  config_type:9  documentation:\\"The password of the private key in the key store file or the PEM key specified in \'ssl.keystore.key\'.\\""  configs.290:\'kafka2.DescribeConfigsResourceResult32a  name:reserved.broker.max.id  value:1000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:reserved.broker.max.id  value:1000  source:5"  config_type:3  documentation:"Max number that can be used for a broker.id"\'  configs.291:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.remove.expired.transaction.cleanup.interval.ms  value:3600000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.remove.expired.transaction.cleanup.interval.ms  value:3600000  source:5"  config_type:3  documentation:"The interval at which to remove transactions that have expired due to <code>transactional.id.expiration.ms</code> passing"\'  configs.292:\'kafka2.DescribeConfigsResourceResult32a  name:log.message.downconversion.enable  value:true  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.message.downconversion.enable  value:true  source:5"  config_type:1  documentation:"This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. When set to <code>false</code>, broker will not perform down-conversion for consumers expecting an older message format. The broker responds with <code>UNSUPPORTED_VERSION</code> error for consume requests from such older clients. This configurationdoes not apply to any message format conversion that might be required for replication to followers."\'  configs.293:"kafka2.DescribeConfigsResourceResult32a  name:ssl.protocol  value:TLSv1.3  read_only:N  config_source:5  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:ssl.protocol  value:TLSv1.3  source:5\\"  config_type:2  documentation:\\"The SSL protocol used to generate the SSLContext. The default is \'TLSv1.3\' when running with Java 11 or newer, \'TLSv1.2\' otherwise. This value should be fine for most use cases. Allowed values in recent JVMs are \'TLSv1.2\' and \'TLSv1.3\'. \'TLS\', \'TLSv1.1\', \'SSL\', \'SSLv2\' and \'SSLv3\' may be supported in older JVMs, but their usage is discouraged due to known security vulnerabilities. With the default value for this config and \'ssl.enabled.protocols\', clients will downgrade to \'TLSv1.2\' if the server does not support \'TLSv1.3\'. If this config is set to \'TLSv1.2\', clients will not use \'TLSv1.3\' even if it is one of the values in ssl.enabled.protocols and the server only supports \'TLSv1.3\'.\\""  configs.294:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.segment.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:metadata.log.segment.ms  value:604800000  source:5"  config_type:5  documentation:"The maximum time before a new metadata log file is rolled out (in milliseconds)."\'  configs.295:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.state.log.load.buffer.size  value:5242880  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.state.log.load.buffer.size  value:5242880  source:5"  config_type:3  documentation:"Batch size for reading from the transaction log segments when loading producer ids and transactions into the cache (soft-limit, overridden if records are too large)."\'  configs.296:\'kafka2.DescribeConfigsResourceResult32a  name:ssl.keystore.location  read_only:N  config_source:5  is_sensitive:N  config_type:2  documentation:"The location of the key store file. This is optional for client and can be used for two-way authentication for client."\'  configs.297:\'kafka2.DescribeConfigsResourceResult32a  name:group.coordinator.append.linger.ms  value:10  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.coordinator.append.linger.ms  value:10  source:5"  config_type:3  documentation:"The duration in milliseconds that the coordinator will wait for writes to accumulate before flushing them to disk. Transactional writes are not accumulated."\'  configs.298:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.enabled.mechanisms  value:GSSAPI  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.enabled.mechanisms  value:GSSAPI  source:5"  config_type:7  documentation:"The list of SASL mechanisms enabled in the Kafka server. The list may contain any mechanism for which a security provider is available. Only GSSAPI is enabled by default."\'  configs.299:\'kafka2.DescribeConfigsResourceResult32a  name:num.replica.alter.log.dirs.threads  read_only:Y  config_source:5  is_sensitive:N  config_type:3  documentation:"The number of threads that can move replicas between log directories, which may include disk I/O"\'  configs.300:\'kafka2.DescribeConfigsResourceResult32a  name:group.share.max.session.timeout.ms  value:60000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.share.max.session.timeout.ms  value:60000  source:5"  config_type:3  documentation:"The maximum allowed session timeout for share group members."\'  configs.301:"kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.cipher.suites  read_only:Y  config_source:5  is_sensitive:N  config_type:7  documentation:\'Specifies the enabled cipher suites to be used in ZooKeeper TLS negotiation (csv). Overrides any explicit value set via the <code>zookeeper.ssl.ciphersuites</code> system property (note the single word \\"ciphersuites\\"). The default value of <code>null</code> means the list of enabled cipher suites is determined by the Java runtime being used.\'"  configs.302:\'kafka2.DescribeConfigsResourceResult32a  name:group.min.session.timeout.ms  value:6000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.min.session.timeout.ms  value:6000  source:5"  config_type:3  documentation:"The minimum allowed session timeout for registered consumers. Shorter timeouts result in quicker failure detection at the cost of more frequent consumer heartbeating, which can overwhelm broker resources."\'  configs.303:\'kafka2.DescribeConfigsResourceResult32a  name:log.cleaner.io.buffer.load.factor  value:0.9  read_only:N  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:log.cleaner.io.buffer.load.factor  value:0.9  source:5"  config_type:6  documentation:"Log cleaner dedupe buffer load factor. The percentage full the dedupe buffer can become. A higher value will allow more log to be cleaned at once but will lead to more hash collisions"\'  configs.304:\'kafka2.DescribeConfigsResourceResult32a  name:transaction.max.timeout.ms  value:900000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:transaction.max.timeout.ms  value:900000  source:5"  config_type:3  documentation:"The maximum allowed timeout for transactions. If a client\\\\342\\\\200\\\\231s requested transaction time exceed this, then the broker will return an error in InitProducerIdRequest. This prevents a client from too large of a timeout, which can stall consumers reading from topics included in the transaction."\'  configs.305:\'kafka2.DescribeConfigsResourceResult32a  name:metadata.log.dir  read_only:Y  config_source:5  is_sensitive:N  config_type:2  documentation:"This configuration determines where we put the metadata log for clusters in KRaft mode. If it is not set, the metadata log is placed in the first log directory from log.dirs."\'  configs.306:"kafka2.DescribeConfigsResourceResult32a  name:process.roles  value:broker,controller  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:\\"kafka2.DescribeConfigsSynonym32a  name:process.roles  value:broker,controller  source:4\\"  synonyms.1:\'kafka2.DescribeConfigsSynonym32a  name:process.roles  value:\\"\\"  source:5\'  config_type:7  documentation:\\"The roles that this process plays: \'broker\', \'controller\', or \'broker,controller\' if it is both. This configuration is only applicable for clusters in KRaft (Kafka Raft) mode (instead of ZooKeeper). Leave this config undefined or empty for ZooKeeper clusters.\\""  configs.307:\'kafka2.DescribeConfigsResourceResult32a  name:group.max.size  value:2147483647  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:group.max.size  value:2147483647  source:5"  config_type:3  documentation:"The maximum number of consumers that a single consumer group can accommodate."\'  configs.308:\'kafka2.DescribeConfigsResourceResult32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms  value:10000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms  value:10000  source:5"  config_type:5  documentation:"The (optional) value in milliseconds for the maximum wait between attempts to retrieve the JWKS (JSON Web Key Set) from the external authentication provider. JWKS retrieval uses an exponential backoff algorithm with an initial wait based on the sasl.oauthbearer.jwks.endpoint.retry.backoff.ms setting and will double in wait length between attempts up to a maximum wait length specified by the sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms setting."\'  configs.309:\'kafka2.DescribeConfigsResourceResult32a  name:delegation.token.max.lifetime.ms  value:604800000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:delegation.token.max.lifetime.ms  value:604800000  source:5"  config_type:5  documentation:"The token has a maximum lifetime beyond which it cannot be renewed anymore. Default value 7 days."\'  configs.310:\'kafka2.DescribeConfigsResourceResult32a  name:max.request.partition.size.limit  value:2000  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:max.request.partition.size.limit  value:2000  source:5"  config_type:3  documentation:"The maximum number of partitions can be served in one request."\'  configs.311:\'kafka2.DescribeConfigsResourceResult32a  name:broker.id  value:4  read_only:Y  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:broker.id  value:4  source:4"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:broker.id  value:-1  source:5"  config_type:3  documentation:"The broker id for this server. If unset, a unique broker id will be generated.To avoid conflicts between ZooKeeper generated broker id\\\'s and user configured broker id\\\'s, generated broker ids start from reserved.broker.max.id + 1."\'  configs.312:\'kafka2.DescribeConfigsResourceResult32a  name:offsets.topic.compression.codec  value:0  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:offsets.topic.compression.codec  value:0  source:5"  config_type:3  documentation:\\\'Compression codec for the offsets topic - compression may be used to achieve "atomic" commits.\\\'\'  configs.313:\'kafka2.DescribeConfigsResourceResult32a  name:zookeeper.ssl.endpoint.identification.algorithm  value:HTTPS  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:zookeeper.ssl.endpoint.identification.algorithm  value:HTTPS  source:5"  config_type:2  documentation:\\\'Specifies whether to enable hostname verification in the ZooKeeper TLS negotiation process, with (case-insensitively) "https" meaning ZooKeeper hostname verification is enabled and an explicit blank value meaning it is disabled (disabling it is only recommended for testing purposes). An explicit value overrides any "true" or "false" value set via the <code>zookeeper.ssl.hostnameVerification</code> system property (note the different name and values; true implies https and false implies blank).\\\'\'  configs.314:\'kafka2.DescribeConfigsResourceResult32a  name:replication.quota.window.num  value:11  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:replication.quota.window.num  value:11  source:5"  config_type:3  documentation:"The number of samples to retain in memory for replication quotas"\'  configs.315:\'kafka2.DescribeConfigsResourceResult32a  name:advertised.listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107  read_only:N  config_source:4  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:advertised.listeners  value:PLAINTEXT://dev.ak-8.kafka-4.ext-0:1047,SSL://dev.ak-8.kafka-4.ext-0:1048,INTERNAL://dev.ak-8.kafka-4.int-0:1107  source:4"  config_type:2  documentation:"Listeners to publish to ZooKeeper for clients to use, if different than the <code>listeners</code> config property. In IaaS environments, this may need to be different from the interface to which the broker binds. If this is not set, the value for <code>listeners</code> will be used. Unlike <code>listeners</code>, it is not valid to advertise the 0.0.0.0 meta-address.\\\\n Also unlike <code>listeners</code>, there can be duplicated ports in this property, so that one listener can be configured to advertise another listener\\\'s address. This can be useful in some cases where external load balancers are used."\'  configs.316:\'kafka2.DescribeConfigsResourceResult32a  name:queued.max.request.bytes  value:-1  read_only:Y  config_source:5  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:queued.max.request.bytes  value:-1  source:5"  config_type:5  documentation:"The number of queued bytes allowed before no more requests are read"\''
iframe:000000000428  ts_ns:1633449886757606  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:49  client_id:redpanda-console
iframe:000000000501  ts_ns:1633449896841190  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:49  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000503  ts_ns:1633452060368563  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:50  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000510  ts_ns:1633452062616857  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:50  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000506  ts_ns:1633452060832908  c_port:55134 kafka2.DescribeAclsRequest  request_api_version:2  correlation_id:51  client_id:redpanda-console  resource_type_filter:1  pattern_type_filter:1  operation:1  permission_type:1
iframe:000000000517  ts_ns:1633452063491155  c_port:55134 kafka2.DescribeAclsResponse  request_api_version:2  correlation_id:51  throttle_time_ms:0  error_code:0  error_message:""
iframe:000000000507  ts_ns:1633452060874694  c_port:55134 kafka2.ApiVersionsRequest  request_api_version:3  correlation_id:52  client_id:redpanda-console  client_software_name:RPConsole  client_software_version:v2.8.2
iframe:000000000519  ts_ns:1633452064364550  c_port:55134 kafka2.ApiVersionsResponse  request_api_version:3  correlation_id:52  error_code:0  api_keys.0:"kafka2.ApiVersion18a  api_key:0  min_version:0  max_version:11"  api_keys.1:"kafka2.ApiVersion18a  api_key:1  min_version:0  max_version:17"  api_keys.2:"kafka2.ApiVersion18a  api_key:2  min_version:0  max_version:9"  api_keys.3:"kafka2.ApiVersion18a  api_key:3  min_version:0  max_version:12"  api_keys.4:"kafka2.ApiVersion18a  api_key:8  min_version:0  max_version:9"  api_keys.5:"kafka2.ApiVersion18a  api_key:9  min_version:0  max_version:9"  api_keys.6:"kafka2.ApiVersion18a  api_key:10  min_version:0  max_version:6"  api_keys.7:"kafka2.ApiVersion18a  api_key:11  min_version:0  max_version:9"  api_keys.8:"kafka2.ApiVersion18a  api_key:12  min_version:0  max_version:4"  api_keys.9:"kafka2.ApiVersion18a  api_key:13  min_version:0  max_version:5"  api_keys.10:"kafka2.ApiVersion18a  api_key:14  min_version:0  max_version:5"  api_keys.11:"kafka2.ApiVersion18a  api_key:15  min_version:0  max_version:5"  api_keys.12:"kafka2.ApiVersion18a  api_key:16  min_version:0  max_version:5"  api_keys.13:"kafka2.ApiVersion18a  api_key:17  min_version:0  max_version:1"  api_keys.14:"kafka2.ApiVersion18a  api_key:18  min_version:0  max_version:4"  api_keys.15:"kafka2.ApiVersion18a  api_key:19  min_version:0  max_version:7"  api_keys.16:"kafka2.ApiVersion18a  api_key:20  min_version:0  max_version:6"  api_keys.17:"kafka2.ApiVersion18a  api_key:21  min_version:0  max_version:2"  api_keys.18:"kafka2.ApiVersion18a  api_key:22  min_version:0  max_version:5"  api_keys.19:"kafka2.ApiVersion18a  api_key:23  min_version:0  max_version:4"  api_keys.20:"kafka2.ApiVersion18a  api_key:24  min_version:0  max_version:5"  api_keys.21:"kafka2.ApiVersion18a  api_key:25  min_version:0  max_version:4"  api_keys.22:"kafka2.ApiVersion18a  api_key:26  min_version:0  max_version:4"  api_keys.23:"kafka2.ApiVersion18a  api_key:27  min_version:0  max_version:1"  api_keys.24:"kafka2.ApiVersion18a  api_key:28  min_version:0  max_version:4"  api_keys.25:"kafka2.ApiVersion18a  api_key:29  min_version:0  max_version:3"  api_keys.26:"kafka2.ApiVersion18a  api_key:30  min_version:0  max_version:3"  api_keys.27:"kafka2.ApiVersion18a  api_key:31  min_version:0  max_version:3"  api_keys.28:"kafka2.ApiVersion18a  api_key:32  min_version:0  max_version:4"  api_keys.29:"kafka2.ApiVersion18a  api_key:33  min_version:0  max_version:2"  api_keys.30:"kafka2.ApiVersion18a  api_key:34  min_version:0  max_version:2"  api_keys.31:"kafka2.ApiVersion18a  api_key:35  min_version:0  max_version:4"  api_keys.32:"kafka2.ApiVersion18a  api_key:36  min_version:0  max_version:2"  api_keys.33:"kafka2.ApiVersion18a  api_key:37  min_version:0  max_version:3"  api_keys.34:"kafka2.ApiVersion18a  api_key:38  min_version:0  max_version:3"  api_keys.35:"kafka2.ApiVersion18a  api_key:39  min_version:0  max_version:2"  api_keys.36:"kafka2.ApiVersion18a  api_key:40  min_version:0  max_version:2"  api_keys.37:"kafka2.ApiVersion18a  api_key:41  min_version:0  max_version:3"  api_keys.38:"kafka2.ApiVersion18a  api_key:42  min_version:0  max_version:2"  api_keys.39:"kafka2.ApiVersion18a  api_key:43  min_version:0  max_version:2"  api_keys.40:"kafka2.ApiVersion18a  api_key:44  min_version:0  max_version:1"  api_keys.41:"kafka2.ApiVersion18a  api_key:45  min_version:0  max_version:0"  api_keys.42:"kafka2.ApiVersion18a  api_key:46  min_version:0  max_version:0"  api_keys.43:"kafka2.ApiVersion18a  api_key:47  min_version:0  max_version:0"  api_keys.44:"kafka2.ApiVersion18a  api_key:48  min_version:0  max_version:1"  api_keys.45:"kafka2.ApiVersion18a  api_key:49  min_version:0  max_version:1"  api_keys.46:"kafka2.ApiVersion18a  api_key:50  min_version:0  max_version:0"  api_keys.47:"kafka2.ApiVersion18a  api_key:51  min_version:0  max_version:0"  api_keys.48:"kafka2.ApiVersion18a  api_key:55  min_version:0  max_version:2"  api_keys.49:"kafka2.ApiVersion18a  api_key:57  min_version:0  max_version:1"  api_keys.50:"kafka2.ApiVersion18a  api_key:60  min_version:0  max_version:1"  api_keys.51:"kafka2.ApiVersion18a  api_key:61  min_version:0  max_version:0"  api_keys.52:"kafka2.ApiVersion18a  api_key:64  min_version:0  max_version:0"  api_keys.53:"kafka2.ApiVersion18a  api_key:65  min_version:0  max_version:0"  api_keys.54:"kafka2.ApiVersion18a  api_key:66  min_version:0  max_version:1"  api_keys.55:"kafka2.ApiVersion18a  api_key:68  min_version:0  max_version:0"  api_keys.56:"kafka2.ApiVersion18a  api_key:69  min_version:0  max_version:0"  api_keys.57:"kafka2.ApiVersion18a  api_key:74  min_version:0  max_version:0"  api_keys.58:"kafka2.ApiVersion18a  api_key:75  min_version:0  max_version:0"  api_keys.59:"kafka2.ApiVersion18a  api_key:80  min_version:0  max_version:0"  api_keys.60:"kafka2.ApiVersion18a  api_key:81  min_version:0  max_version:0"  throttle_time_ms:0
iframe:000000000512  ts_ns:1633452062915334  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:53  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000521  ts_ns:1633452065408025  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:53  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000513  ts_ns:1633452062958361  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:54  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000533  ts_ns:1633452066972140  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:54  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000515  ts_ns:1633452062989523  c_port:55134 kafka2.DescribeConfigsRequest  request_api_version:3  correlation_id:55  client_id:redpanda-console  resources.0:"kafka2.DescribeConfigsResource32q  resource_type:2  resource_name:ap1  configuration_keys.0:cleanup.policy"  include_synonyms:Y  include_documentation:Y
iframe:000000000538  ts_ns:1633452068697132  c_port:55134 kafka2.DescribeConfigsResponse  request_api_version:3  correlation_id:55  throttle_time_ms:0  results.0:'kafka2.DescribeConfigsResult32a  error_code:0  error_message:""  resource_type:2  resource_name:ap1  configs.0:\'kafka2.DescribeConfigsResourceResult32a  name:cleanup.policy  value:delete  read_only:N  config_source:1  is_sensitive:N  synonyms.0:"kafka2.DescribeConfigsSynonym32a  name:cleanup.policy  value:delete  source:1"  synonyms.1:"kafka2.DescribeConfigsSynonym32a  name:log.cleanup.policy  value:delete  source:5"  config_type:7  documentation:\\\'This config designates the retention policy to use on log segments. The "delete" policy (which is the default) will discard old segments when their retention time or size limit has been reached. The "compact" policy will enable <a href="#compaction">log compaction</a>, which retains the latest value for each key. It is also possible to specify both policies in a comma-separated list (e.g. "delete,compact"). In this case, old segments will be discarded per the retention time and size configuration, while retained segments will be compacted.\\\'\''
iframe:000000000522  ts_ns:1633452065711244  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:56  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-1"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-1"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-1"'  timeout_ms:0
iframe:000000000542  ts_ns:1633452069643750  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:56  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:1  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000535  ts_ns:1633452067220921  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:57  client_id:redpanda-console  topics.0:"kafka2.DescribableLogDirTopic35q  topic:ap1  partitions.0:2  partitions.1:1  partitions.2:0"
iframe:000000000543  ts_ns:1633452071528044  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:57  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000537  ts_ns:1633452068273350  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:58  client_id:redpanda-console  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000545  ts_ns:1633452072497868  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:58  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000541  ts_ns:1633452069513881  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:59  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-2"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-2"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-2"'  timeout_ms:0
iframe:000000000547  ts_ns:1633452073459564  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:59  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000546  ts_ns:1633452072670528  c_port:55134 kafka2.DescribeLogDirsRequest  request_api_version:2  correlation_id:60  client_id:redpanda-console
iframe:000000000548  ts_ns:1633452075243667  c_port:55134 kafka2.DescribeLogDirsResponse  request_api_version:2  correlation_id:60  throttle_time_ms:0  error_code:0  results.0:'kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-1/dev.ak-8  topics.0:\'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:"kafka2.DescribeLogDirsPartition35a  partition_index:2  partition_size:82  offset_lag:0  is_future_key:N"  partitions.1:"kafka2.DescribeLogDirsPartition35a  partition_index:1  partition_size:0  offset_lag:0  is_future_key:N"\'  total_bytes:-1  usable_bytes:-1'  results.1:"kafka2.DescribeLogDirsResult35a  error_code:0  log_dir:/mnt/data-2/dev.ak-8  topics.0:'kafka2.DescribeLogDirsTopic35a  name:ap1  partitions.0:\"kafka2.DescribeLogDirsPartition35a  partition_index:0  partition_size:0  offset_lag:0  is_future_key:N\"'  total_bytes:-1  usable_bytes:-1"
iframe:000000000552  ts_ns:1633454056509920  c_port:55134 kafka2.MetadataRequest  request_api_version:9  correlation_id:61  client_id:redpanda-console  topics.0:"kafka2.MetadataRequestTopic3q  topic_id:00000000-0000-0000-0000-000000000000  name:ap1"  allow_auto_topic_creation:N  include_cluster_authorized_operations:N  include_topic_authorized_operations:N
iframe:000000000554  ts_ns:1633454057854073  c_port:55134 kafka2.MetadataResponse  request_api_version:9  correlation_id:61  throttle_time_ms:0  brokers.0:"kafka2.MetadataResponseBroker3a  node_id:4  host:dev.ak-8.kafka-4.ext-0  port:1047"  cluster_id:dev.ak-8  controller_id:4  topics.0:'kafka2.MetadataResponseTopic3a  error_code:0  name:ap1  topic_id:00000000-0000-0000-0000-000000000000  is_internal:N  partitions.0:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:2  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.1:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:1  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  partitions.2:"kafka2.MetadataResponsePartition3a  error_code:0  partition_index:0  leader_id:4  leader_epoch:0  replica_nodes.0:4  isr_nodes.0:4"  topic_authorized_operations:OMITTED'  cluster_authorized_operations:OMITTED  error_code:0
iframe:000000000555  ts_ns:1633454058121049  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:62  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-1"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-1"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-1"'  timeout_ms:0
iframe:000000000558  ts_ns:1633454059196524  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:62  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:1  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
iframe:000000000557  ts_ns:1633454058417228  c_port:55134 kafka2.ListOffsetsRequest  request_api_version:5  correlation_id:63  client_id:redpanda-console  replica_id:0  isolation_level:0  topics.0:'kafka2.ListOffsetsTopic2q  name:ap1  partitions.0:"kafka2.ListOffsetsPartition2q  partition_index:2  current_leader_epoch:-1  timestamp:-2"  partitions.1:"kafka2.ListOffsetsPartition2q  partition_index:1  current_leader_epoch:-1  timestamp:-2"  partitions.2:"kafka2.ListOffsetsPartition2q  partition_index:0  current_leader_epoch:-1  timestamp:-2"'  timeout_ms:0
iframe:000000000559  ts_ns:1633454060227462  c_port:55134 kafka2.ListOffsetsResponse  request_api_version:5  correlation_id:63  throttle_time_ms:0  topics.0:'kafka2.ListOffsetsTopicResponse2a  name:ap1  partitions.0:"kafka2.ListOffsetsPartitionResponse2a  partition_index:2  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.1:"kafka2.ListOffsetsPartitionResponse2a  partition_index:1  error_code:0  timestamp:-1  offset:0  leader_epoch:0"  partitions.2:"kafka2.ListOffsetsPartitionResponse2a  partition_index:0  error_code:0  timestamp:-1  offset:0  leader_epoch:0"'
