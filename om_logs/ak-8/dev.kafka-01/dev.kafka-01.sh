#
# Generated by omcli
# Cluster:dev.ak-8 Node:dev.ak-8.kafka-1
#
cat << 'HOSTS' > omhosts
# Generated by omcli

192.168.10.21  dev.kafka-01
192.168.10.21  dev.ak-8.kafka-1.ctrl
192.168.108.2  dev.ak-8.kafka-1.ext
192.168.218.2  dev.ak-8.kafka-1.ib
192.168.208.2  dev.ak-8.kafka-1.int
192.168.10.31  dev.kafka-02
192.168.10.31  dev.ak-8.kafka-2.ctrl
192.168.108.3  dev.ak-8.kafka-2.ext
192.168.218.3  dev.ak-8.kafka-2.ib
192.168.208.3  dev.ak-8.kafka-2.int
192.168.10.41  dev.kafka-03
192.168.10.41  dev.ak-8.kafka-3.ctrl
192.168.108.4  dev.ak-8.kafka-3.ext
192.168.218.4  dev.ak-8.kafka-3.ib
192.168.208.4  dev.ak-8.kafka-3.int
192.168.10.51  dev.kafka-04
192.168.10.51  dev.ak-8.kafka-4.ctrl
192.168.108.5  dev.ak-8.kafka-4.ext
192.168.218.5  dev.ak-8.kafka-4.ib
192.168.208.5  dev.ak-8.kafka-4.int
192.168.10.11  dev.kafkaui-1
192.168.10.11  dev.ak-8.kafkaui-1.ctrl
192.168.108.1  dev.ak-8.kafkaui-1.ext
192.168.10.61  dev.kafkaw-08
192.168.10.61  dev.ak-8.kafkaw-1.ctrl
192.168.108.6  dev.ak-8.kafkaw-1.ext
192.168.10.71  dev.kafkaw-16
192.168.10.71  dev.ak-8.kafkaw-2.ctrl
192.168.108.7  dev.ak-8.kafkaw-2.ext
192.168.10.11  dev.rdpui-1
192.168.10.11  dev.ak-8.rdpui-1.ctrl
192.168.108.1  dev.ak-8.rdpui-1.ext
192.168.10.11  dev.x2w-01
192.168.10.11  dev.ak-8.x2w-1.ctrl
192.168.108.1  dev.ak-8.x2w-1.ext
HOSTS
cat omhosts | sudo tee /etc/hosts &> /dev/null
#!/usr/bin/env bash
#
function copy_server_properties {
cat << 'EOF' >dev.kafka-01.properties
#
# Generated by omcli
# Cluster:dev.ak-8 Node:dev.ak-8.kafka-1
#
advertised.listeners=PLAINTEXT://dev.ak-8.kafka-1.ext:1031,SSL://dev.ak-8.kafka-1.ext:1034,INTERNAL://dev.ak-8.kafka-1.int:1104
controller.listener.names=CONTROLLER
controller.quorum.election.timeout.ms=20000
controller.quorum.fetch.timeout.ms=10000
controller.quorum.voters=1@dev.ak-8.kafka-1.int:1049,2@dev.ak-8.kafka-2.int:1051,3@dev.ak-8.kafka-3.int:1053
inter.broker.listener.name=INTERNAL
listener.security.protocol.map=CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
listeners=PLAINTEXT://dev.ak-8.kafka-1.ext:1031,SSL://dev.ak-8.kafka-1.ext:1034,INTERNAL://dev.ak-8.kafka-1.int:1104,CONTROLLER://dev.ak-8.kafka-1.int:1049
log.dirs=dev.ak-8
log.retention.check.interval.ms=300000
log.retention.hours=168
log.segment.bytes=1073741824
message.max.bytes=10485760
node.id=1
num.io.threads=8
num.network.threads=8
num.partitions=3
num.recovery.threads.per.data.dir=1
num.replica.fetchers=8
offsets.topic.replication.factor=1
process.roles=broker,controller
replica.fetch.max.bytes=10485760
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
socket.send.buffer.bytes=102400
transaction.state.log.min.isr=1
transaction.state.log.replication.factor=1
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
super.users=User:CN=dev.ak-8;User:CN=dev.ak-8.kafkaui-1;User:CN=dev.ak-8.x2w-1;User:ANONYMOUS
allow.everyone.if.no.acl.found=false
audit.log.enabled=true
EOF
# Format log.dirs record
export log=$(lsblk -o NAME,MOUNTPOINT | grep "/mnt/data-" | sort -k2 | awk '{print $2"/dev.ak-8"}' | paste -sd,)
sed -i "s/^log\.dirs=.*/log.dirs=${log//\//\\/}/" dev.kafka-01.properties
ln -sfr dev.kafka-01.properties server.properties
}
#
#
function copy_prometheus_properties {
cat << 'EOF' >jmx_prometheus.yaml
lowercaseOutputName: true

rules:
# Special cases and very specific rules
- pattern : kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
  name: kafka_server_$1_$2
  type: GAUGE
  labels:
    clientId: "$3"
    topic: "$4"
    partition: "$5"
- pattern : kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
  name: kafka_server_$1_$2
  type: GAUGE
  labels:
    clientId: "$3"
    broker: "$4:$5"
- pattern : kafka.coordinator.(\w+)<type=(.+), name=(.+)><>Value
  name: kafka_coordinator_$1_$2_$3
  type: GAUGE
# Kraft current state info metric rule
- pattern: "kafka.server<type=raft-metrics><>current-state: ([a-z]+)"
  name: kafka_server_raft_metrics_current_state_info
  type: GAUGE
  value: 1
  labels:
    "state": "$1"
# Kraft specific rules for raft-metrics, raft-channel-metrics, broker-metadata-metrics
- pattern: kafka.server<type=(.+)><>([a-z-]+)-total
  name: kafka_server_$1_$2_total
  type: COUNTER
- pattern: kafka.server<type=(.+)><>([a-z-]+)
  name: kafka_server_$1_$2
  type: GAUGE

# Generic per-second counters with 0-2 key/value pairs
- pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)><>Count
  name: kafka_$1_$2_$3_total
  type: COUNTER
  labels:
    "$4": "$5"
    "$6": "$7"
- pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+)><>Count
  name: kafka_$1_$2_$3_total
  type: COUNTER
  labels:
    "$4": "$5"
- pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*><>Count
  name: kafka_$1_$2_$3_total
  type: COUNTER

# Quota specific rules
- pattern: kafka.server<type=(.+), user=(.+), client-id=(.+)><>([a-z-]+)
  name: kafka_server_quota_$4
  type: GAUGE
  labels:
    resource: "$1"
    user: "$2"
    clientId: "$3"
- pattern: kafka.server<type=(.+), client-id=(.+)><>([a-z-]+)
  name: kafka_server_quota_$3
  type: GAUGE
  labels:
    resource: "$1"
    clientId: "$2"
- pattern: kafka.server<type=(.+), user=(.+)><>([a-z-]+)
  name: kafka_server_quota_$3
  type: GAUGE
  labels:
    resource: "$1"
    user: "$2"

# Generic gauges with 0-2 key/value pairs
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Value
  name: kafka_$1_$2_$3
  type: GAUGE
  labels:
    "$4": "$5"
    "$6": "$7"
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Value
  name: kafka_$1_$2_$3
  type: GAUGE
  labels:
    "$4": "$5"
- pattern: kafka.(\w+)<type=(.+), name=(.+)><>Value
  name: kafka_$1_$2_$3
  type: GAUGE

# Emulate Prometheus 'Summary' metrics for the exported 'Histogram's.
#
# Note that these are missing the '_sum' metric!
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Count
  name: kafka_$1_$2_$3_count
  type: COUNTER
  labels:
    "$4": "$5"
    "$6": "$7"
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile
  name: kafka_$1_$2_$3
  type: GAUGE
  labels:
    "$4": "$5"
    "$6": "$7"
    quantile: "0.$8"
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Count
  name: kafka_$1_$2_$3_count
  type: COUNTER
  labels:
    "$4": "$5"
- pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile
  name: kafka_$1_$2_$3
  type: GAUGE
  labels:
    "$4": "$5"
    quantile: "0.$6"
- pattern: kafka.(\w+)<type=(.+), name=(.+)><>Count
  name: kafka_$1_$2_$3_count
  type: COUNTER
- pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
  name: kafka_$1_$2_$3
  type: GAUGE
  labels:
    quantile: "0.$4"

# Generic gauges for MeanRate Percent
# Ex) kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>MeanRate
- pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>MeanRate
  name: kafka_$1_$2_$3_percent
  type: GAUGE
- pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>Value
  name: kafka_$1_$2_$3_percent
  type: GAUGE
- pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*, (.+)=(.+)><>Value
  name: kafka_$1_$2_$3_percent
  type: GAUGE
  labels:
    "$4": "$5"
EOF
}
#
#
function start_broker {
export KAFKA_OPTS="-javaagent:/home/kafkausr/jmx_prometheus_javaagent.jar=dev.ak-8.kafka-1.ext:1050:/home/kafkausr/jmx_prometheus.yaml -Djava.net.preferIPv4Stack=true"
export JMX_PORT=1072
export KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote.host=dev.ak-8.kafka-1.ext \
                      -Djava.rmi.server.hostname=dev.ak-8.kafka-1.ext \
                      -Dcom.sun.management.jmxremote.port=1072 \
                      -Dcom.sun.management.jmxremote.ssl=false \
                      -Dcom.sun.management.jmxremote.registry.ssl=false  \
                      -Dcom.sun.management.jmxremote.authenticate=false"
kafka/bin/kafka-server-start.sh -daemon server.properties
}
#
function start_kafka_broker {
for i in {1..6}; do pgrep java >/dev/null && break; start_broker; done;
for i in {1..10}; do lsof -i :1072 >/dev/null && { echo; echo $(hostname):success; exit 0; }; echo -n .; sleep 1; done;
echo; echo $(hostname):failed, retry;
for i in {1..6}; do pgrep java >/dev/null && break; start_broker; done;
for i in {1..10}; do lsof -i :1072 >/dev/null && { echo; echo $(hostname):success; exit 0; }; echo -n .; sleep 1; done;
echo; echo $(hostname):failed, retry;
for i in {1..6}; do pgrep java >/dev/null && break; start_broker; done;
for i in {1..10}; do lsof -i :1072 >/dev/null && { echo; echo $(hostname):success; exit 0; }; echo -n .; sleep 1; done;
echo; echo $(hostname):failed; exit 1
}
#
#
function format_kafka_broker {
# Check mounted dirs and remove old logs
export log=$(lsblk -o NAME,MOUNTPOINT | grep "/mnt/data-" | sort -k2 | awk '{print $2"/dev.ak-8"}' | paste -sd,)
sudo chmod ugo+rwx -R /mnt/
for dir in ${log//,/ }; do
  rm -fr "$dir"
done
# Format new logs
kafka/bin/kafka-storage.sh format -t dev.ak-8 -c server.properties
}
#
function stop_kafka_broker {
kill -9 $(pidof java) 1>/dev/null 2>/dev/null || { echo "====Was not running"; }
}
function status_kafka_broker {
 lsof -P -i :1072 || { echo "====Not running"; }
}
function metrics_kafka_broker {
curl http://dev.ak-8.kafka-1.ext:1050/metrics
}
#
     copy_server_properties
     copy_prometheus_properties
echo "script:info  node:dev.kafka-01 omnode:dev.ak-8.kafka-1 option:$1 "
case $1 in
     start)
     stop_kafka_broker
     start_kafka_broker
     ;;
     start_clean)
     stop_kafka_broker
     format_kafka_broker
     start_kafka_broker
     ;;
     stop)
     stop_kafka_broker
     ;;
     status)
     status_kafka_broker
     ;;
     metrics)
     metrics_kafka_broker
     ;;
     *)
     ;;
esac
